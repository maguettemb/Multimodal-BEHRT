{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8fc3a3-f5cb-45eb-bac8-2c29eb774917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2024-05-16 09:47:11.793013: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 09:47:12.843526: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-16 09:47:12.843651: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-16 09:47:12.843662: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/work/Workdir/Utils')\n",
    "sys.path.append('/home/jovyan/work/Workdir/Models/Multimodal_BEHRT/Early_integration')\n",
    "sys.path.append('/home/jovyan/work/Workdir/Models/Multimodal_BEHRT/Early_integration/models')\n",
    "\n",
    "from handle_file import handle_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel#ForMaskedLM\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "from models.BertForClassification import BertForClassification\n",
    "#from BEHRTForClassification import *\n",
    "from models.utils import age_vocab, input_vocab, mod_vocab, delay_vocab\n",
    "from sklearn.decomposition import PCA\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sn\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "#import matplotlib.cm as cm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')  # pylint: disable=multiple-statements\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import widgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "hf = handle_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1628cc-10f9-4e1d-a2dd-df02a0f10f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa030ac-0ed2-423b-a6f2-6989e6d2eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "# Dictionary that contains lemma as key and the synonyms as values \n",
    "syno_dico = {'':['']}\n",
    "             \n",
    "            \n",
    "            \n",
    "def get_keys_from_value(d, val):\n",
    "    # find the key from a given value when the dictionary contains list as values\n",
    "    for value in d.values():\n",
    "        if val in value:\n",
    "            index = list(d.values()).index(value)\n",
    "            key = list(d.keys())[index]\n",
    "            break\n",
    "    return key\n",
    "\n",
    "            \n",
    "           \n",
    "def synonym_merging(token_to_change, synonym_dico = syno_dico ):\n",
    "    \"\"\" Function that will merge synonym into a same word\n",
    "    params: synonym_dico: dictionary that contain as key the main token with as values all the synonyms\n",
    "            token_to_change: initial sequence that contains different synonyms \n",
    "    return: new token with the synonyms merged into on main token \"\"\"\n",
    "   \n",
    "    if any(token_to_change in val for val in synonym_dico.values()):\n",
    "       \n",
    "        key = get_keys_from_value(synonym_dico, token_to_change)\n",
    "        return key\n",
    "    else:\n",
    "        return token_to_change\n",
    "    \n",
    "    \n",
    "def normalize(text):\n",
    "    \n",
    "    ## remove accents\n",
    "    text = str(text)\n",
    "    normalized = unicodedata.normalize(\"NFKD\", text)\n",
    "    normalized = \"\".join([c for c in normalized if not unicodedata.combining(c)])\n",
    "        \n",
    "    ## remove white space\n",
    "    \n",
    "    normalized = normalized.strip()\n",
    "    normalized = normalized.lower()\n",
    "    return normalized \n",
    "\n",
    "\n",
    "\n",
    "def clean_text(seq):\n",
    "    \n",
    "    if isinstance(seq, list):\n",
    "        for i in range(len(seq)): \n",
    "            seq[i] = normalize(seq[i])\n",
    "           \n",
    "            if ('a©' in seq[i]) or ('a ' in seq[i]):\n",
    "               \n",
    "                seq[i] = seq[i].replace('a©', 'e')\n",
    "                seq[i] = seq[i].replace('ã¨', 'e')\n",
    "                seq[i] = seq[i].replace('a p', 'op')\n",
    "                seq[i] = seq[i].replace('a r', 'er')\n",
    "                seq[i] = seq[i].replace('ã©', 'e')\n",
    "\n",
    "    elif isinstance(seq, str):\n",
    "        seq = normalize(seq)\n",
    "        if ('a©' in seq) or ('a ' in seq):\n",
    "           \n",
    "            seq= seq.replace('a©', 'e')\n",
    "            seq = seq.replace('ã¨', 'e')\n",
    "            seq = seq.replace('ha pital', 'hopital')  ## not working§\n",
    "            seq = seq.replace('premia r', 'premier')\n",
    "            seq = seq.replace('ã©', 'e')\n",
    "      \n",
    "    return seq\n",
    "\n",
    "def lower_categories(categories):\n",
    "    \n",
    "    cat = list()\n",
    "    \n",
    "    for x in categories:\n",
    "        try:\n",
    "            cat.append(x.lower())\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return cat\n",
    "\n",
    "def get_categorie_and_service_index(seq):\n",
    "    services, categories = list(), list()\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] == 'service':\n",
    "            services.append(i)\n",
    "        elif seq[i] == 'category':\n",
    "            categories.append(i)\n",
    "    return services, categories\n",
    "\n",
    "\n",
    "def plot_PCA(n_components, pca_obj, df, figname):\n",
    "    fig= plt.figure(figsize=(10,7))\n",
    "    ax = sn.barplot(\n",
    "        y=[\"PCA component {0}\".format(i) for i in np.arange(n_components)],\n",
    "        x = 100.*pca_obj.explained_variance_ratio_, \n",
    "        orient = \"h\",\n",
    "        #color = my_colors\n",
    "        \n",
    "    )\n",
    "    ax.set_xlim(0,100)\n",
    "    plt.xlabel(\"% of explained variance\")\n",
    "    plt.title(\"PCA with {0} components,(out of {1} features). \\nTotal explained {2:.2f}%\".format(n_components, df.shape[1], 100*pca_obj.explained_variance_ratio_.sum()))\n",
    "    \n",
    "    for i in ax.patches:\n",
    "        ax.text(i.get_width(), i.get_y()+0.5, '{0:.2f}'.format(i.get_width()))\n",
    "    \n",
    "    plt.savefig(figname+'.png')\n",
    "    return\n",
    "\n",
    "def reduce_dimension(data, standardize=True, plot_pca_comp=True, n_pca=50, n_tsne=2, PCA_first=True, seed=2):\n",
    "    #1. PCA \n",
    "    if standardize:\n",
    "        data = StandardScaler().fit_transform(data)\n",
    "    \n",
    "    pca = PCA(n_components=n_pca)\n",
    "    X_PCA = pca.fit_transform(data)\n",
    "    hf._dump_pkl(X_PCA, 'CLS_embeddings_PCA')\n",
    "    \n",
    "    if plot_pca_comp:\n",
    "        plot_PCA(n_pca, pca, X_PCA, 'PCA_components')\n",
    "      \n",
    "    if PCA_first:\n",
    "        X_tsne = TSNE(n_components=n_tsne, perplexity=30, early_exaggeration=30, n_iter=1000, random_state=seed).fit_transform(X_PCA)\n",
    "    else:\n",
    "        X_tsne = TSNE(n_components=n_tsne, perplexity=30, early_exaggeration=30, n_iter=1000, random_state=seed).fit_transform(data)\n",
    "        \n",
    "    df_tsne = pd.DataFrame(X_tsne)\n",
    "    \n",
    "    return df_tsne\n",
    "\n",
    "def scatter_plot_tsne(df, title, figsize = (25, 10), color='cluster', size=5, show_legend=True):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    colors = px.colors.qualitative.Set3+px.colors.qualitative.Light24+px.colors.qualitative.Dark24+px.colors.qualitative.Alphabet+px.colors.qualitative.Prism+px.colors.qualitative.Antique+px.colors.qualitative.Bold+px.colors.qualitative.Vivid\n",
    "   \n",
    "    if show_legend:\n",
    "        fig = px.scatter(df, x=0, y=1, text='text', color=color, opacity=0.9, width=1500, height=1000)\n",
    "    else:\n",
    "        fig = px.scatter(df, x=0, y=1, color=color, width=1500, height=1000, opacity=0.9, color_discrete_sequence=colors, labels = color)\n",
    "        \n",
    "    fig.update_traces(textposition='top center', textfont_size=12)\n",
    "    fig.update_traces(marker_size=size)\n",
    "    fig.update_layout(plot_bgcolor='white')\n",
    "    fig.update_xaxes(showgrid=False)#, gridwidth=1, gridcolor='Gray')\n",
    "    fig.update_yaxes(showgrid=False)#, gridwidth=1, gridcolor='#E2E3DE')\n",
    "    \n",
    "    fig.update_layout(legend_font_size=9)\n",
    "   \n",
    "    fig.show()\n",
    " \n",
    "def flatten_nested_list(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_nested_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def flatten_dict(dict_with_nested_values):\n",
    "    flat_dict = dict()\n",
    "    for k , v in dict_with_nested_values.items():\n",
    "        if isinstance(v, list):\n",
    "            flat_dict[k] = flatten_nested_list(v)\n",
    "        else:\n",
    "            flat_dict[k] = flatten_nested_list(v)\n",
    "    return flat_dict\n",
    "\n",
    "def flatten_list(list_of_list):\n",
    "    return [x for y in list_of_list for x in y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4976c-8a59-4e0a-801a-b8bb5db4e382",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07211b72-227d-4761-8d18-38124f1d5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54be0c3-38db-45e0-8e34-94e0caab2d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_embeddings = hf._load_pkl('/home/jovyan/work/Workdir/Models/Text model/records_embeddins_cpu_sum.pkl')\n",
    "len(patients_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4833e-1824-4d9b-93ff-1c070af803bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get reports names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbeb82f-8073-4c15-8cae-759a267c1bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_dossier</th>\n",
       "      <th>inputs_normal_range_age</th>\n",
       "      <th>inputs_normal_range_age_and_delays</th>\n",
       "      <th>inputs_normal_range_and_delta_age</th>\n",
       "      <th>inputs_normal_range_and_delta_age_and_delays</th>\n",
       "      <th>inputs_bins_and_delta_age</th>\n",
       "      <th>inputs_bins_and_delta_age_and_delays</th>\n",
       "      <th>delays_basic_and_age</th>\n",
       "      <th>delays_for_twos_and_age</th>\n",
       "      <th>delays_categorized_basic_and_age</th>\n",
       "      <th>...</th>\n",
       "      <th>modalities_basic_and_age_and_delays_preprocessed</th>\n",
       "      <th>modalities_for_twos_and_age_and_delays_preprocessed</th>\n",
       "      <th>delays_basic_and_age_without_st_preprocessed</th>\n",
       "      <th>delays_categorized_basic_and_age_without_st_preprocessed</th>\n",
       "      <th>modalities_basic_and_age_without_st_preprocessed</th>\n",
       "      <th>delays_for_twos_and_age_without_st_preprocessed</th>\n",
       "      <th>delays_categorized_for_twos_and_age_without_st_preprocessed</th>\n",
       "      <th>modalities_for_twos_and_age_without_st_preprocessed</th>\n",
       "      <th>modalities_basic_and_age_and_delays_without_st_preprocessed</th>\n",
       "      <th>modalities_for_twos_and_age_and_delays_without_st_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>028c6922c695871b15102c2d5edc76ab</td>\n",
       "      <td>[CLS, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[CLS, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[CLS, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[CLS, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[CLS, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[CLS, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W...</td>\n",
       "      <td>...</td>\n",
       "      <td>[DEB, age, age, age, grade, grade, grade, node...</td>\n",
       "      <td>[DEB, CA153, CA153, CA153, MONO, MONO, MONO, L...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W...</td>\n",
       "      <td>[DEB, age, age, age, grade, grade, grade, node...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W...</td>\n",
       "      <td>[DEB, CA153, CA153, CA153, MONO, MONO, MONO, L...</td>\n",
       "      <td>[DEB, age, age, age, grade, grade, grade, node...</td>\n",
       "      <td>[DEB, CA153, CA153, CA153, MONO, MONO, MONO, L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Num_dossier  \\\n",
       "0  028c6922c695871b15102c2d5edc76ab   \n",
       "\n",
       "                             inputs_normal_range_age  \\\n",
       "0  [CLS, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                  inputs_normal_range_age_and_delays  \\\n",
       "0  [CLS, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                   inputs_normal_range_and_delta_age  \\\n",
       "0  [CLS, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "        inputs_normal_range_and_delta_age_and_delays  \\\n",
       "0  [CLS, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                           inputs_bins_and_delta_age  \\\n",
       "0  [CLS, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                inputs_bins_and_delta_age_and_delays  \\\n",
       "0  [CLS, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                                delays_basic_and_age  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                             delays_for_twos_and_age  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                    delays_categorized_basic_and_age  ...  \\\n",
       "0  [W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W...  ...   \n",
       "\n",
       "    modalities_basic_and_age_and_delays_preprocessed  \\\n",
       "0  [DEB, age, age, age, grade, grade, grade, node...   \n",
       "\n",
       "  modalities_for_twos_and_age_and_delays_preprocessed  \\\n",
       "0  [DEB, CA153, CA153, CA153, MONO, MONO, MONO, L...    \n",
       "\n",
       "        delays_basic_and_age_without_st_preprocessed  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "  delays_categorized_basic_and_age_without_st_preprocessed  \\\n",
       "0  [W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W...         \n",
       "\n",
       "    modalities_basic_and_age_without_st_preprocessed  \\\n",
       "0  [DEB, age, age, age, grade, grade, grade, node...   \n",
       "\n",
       "     delays_for_twos_and_age_without_st_preprocessed  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "  delays_categorized_for_twos_and_age_without_st_preprocessed  \\\n",
       "0  [W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W0, W...            \n",
       "\n",
       "  modalities_for_twos_and_age_without_st_preprocessed  \\\n",
       "0  [DEB, CA153, CA153, CA153, MONO, MONO, MONO, L...    \n",
       "\n",
       "  modalities_basic_and_age_and_delays_without_st_preprocessed  \\\n",
       "0  [DEB, age, age, age, grade, grade, grade, node...            \n",
       "\n",
       "  modalities_for_twos_and_age_and_delays_without_st_preprocessed  \n",
       "0  [DEB, CA153, CA153, CA153, MONO, MONO, MONO, L...              \n",
       "\n",
       "[1 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = hf._load_pkl('/home/jovyan/work/Workdir/Models/Multimodal_BEHRT/Early_integration/tasks/data_preprocessed_completed_for_fine_tune.pkl')\n",
    "sequences.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2daa8d3-c8cb-4fad-8ddf-4f095fd396db",
   "metadata": {},
   "outputs": [],
   "source": [
    "services = hf._load_csv('/home/jovyan/work/Workdir/Models/Multimodal_BEHRT/Early_integration/data extraction/Plots/df_categories_for_services.csv')\n",
    "categories= list()\n",
    "for service in services.columns.to_list():\n",
    "    categories+=list(services[service].unique())\n",
    "    \n",
    "categories = lower_categories(categories)\n",
    "\n",
    "services = [x.lower() for x in services.columns.tolist()] \n",
    "del services[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65bb331-8788-46d2-93a4-ca7a8f0ef852",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = clean_text(categories)\n",
    "services = clean_text(services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae992fb3-803d-43bb-bf53-84f162de6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [synonym_merging(x) for x in categories]\n",
    "services = [synonym_merging(x) for x in services]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3536902b-b7ec-42b9-a0d9-fb979b0a1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = dict()\n",
    "\n",
    "for i, row in sequences.iterrows():\n",
    "    indexes[row['Num_dossier']] = get_categorie_and_service_index(row['modalities_basic_and_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb2c0e6-1c8e-401f-9eea-8612c9f53403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_services_in_seq = dict()\n",
    "for k, v in indexes.items():\n",
    "    idxs = list()\n",
    "    seq = sequences.loc[sequences['Num_dossier']==k]['inputs_normal_range_age'].values[0]\n",
    "   \n",
    "    for serv, cat in zip(v[0], v[1]):\n",
    "        idxs.append([seq[serv], seq[cat]])\n",
    "    cat_services_in_seq[k] = idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d481be7-27f7-421e-b388-f019b2958e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "810c1037-33d5-4ccf-8858-598e6dbf55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_CLS_embeddings = flatten_nested_list(list(patients_embeddings.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd1a100-2569-464f-9809-316ca3ef6f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511620"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten_CLS_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76cbd729-ded1-4e67-804e-42eca428ae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten_CLS_embeddings[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b142a93b-d186-43c8-bf20-1e30d895dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([511620, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate along a new dimension (n+1)\n",
    "flatten_values = torch.stack(flatten_CLS_embeddings, dim=0)#.cpu()  # Assuming n is the last dimension\n",
    "flatten_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eb81594-4626-495e-9353-515077bcab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511620"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = list()\n",
    "patients = patients_embeddings.keys()\n",
    "for p in patients:\n",
    "    text+=cat_services_in_seq[p]\n",
    "    \n",
    "len(text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "093c2e29-875f-44c2-b9cf-05f55575e74c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been saved in pkl format in /home/jovyan/work/Workdir/Models/Text model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.470345</td>\n",
       "      <td>36.308090</td>\n",
       "      <td>[radio. interv., echographie et mammographie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.458714</td>\n",
       "      <td>21.501181</td>\n",
       "      <td>[consultations, premiere consultation adulte]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-46.332790</td>\n",
       "      <td>27.481298</td>\n",
       "      <td>[radiodiagnostic, examen radiologique]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-33.896614</td>\n",
       "      <td>57.311214</td>\n",
       "      <td>[radio-immuno, scintigraphie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.638086</td>\n",
       "      <td>57.303661</td>\n",
       "      <td>[imagerie, echographie]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1                                           text\n",
       "0  86.470345  36.308090  [radio. interv., echographie et mammographie]\n",
       "1  32.458714  21.501181  [consultations, premiere consultation adulte]\n",
       "2 -46.332790  27.481298         [radiodiagnostic, examen radiologique]\n",
       "3 -33.896614  57.311214                  [radio-immuno, scintigraphie]\n",
       "4   5.638086  57.303661                        [imagerie, echographie]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df_tsne = reduce_dimension(flatten_values, standardize=True, plot_pca_comp=False, n_pca=100, n_tsne=2, PCA_first=True, seed=3)\n",
    "df_tsne['text'] = text\n",
    "df_tsne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21401a92-012e-4524-9b0e-9d3ad1f05850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been saved in pkl format in /home/jovyan/work/Workdir/Models/Text model\n"
     ]
    }
   ],
   "source": [
    "hf._dump_pkl(text, 'text_drbertsum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
