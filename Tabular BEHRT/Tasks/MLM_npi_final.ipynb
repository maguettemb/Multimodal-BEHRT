{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86672ff5-7420-4070-b1aa-35e344186b20",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assumed-entity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('BEHRT/Early_integration')\n",
    "sys.path.append('BEHRT/')\n",
    "#sys.path.append(cwd+'/Early_integration')\n",
    "#sys.path.append(cwd)\n",
    "\n",
    "import random\n",
    "from Utils.common import *\n",
    "from Utils.pytorch import load_model\n",
    "from Utils.utils import age_vocab, input_vocab, mod_vocab, delay_vocab\n",
    "from Utils.optimiser import adam\n",
    "from Models.MLM_v2 import MLMLoader\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from Models.MLM_v2 import MLMLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from Models.MLM import BertForMaskedLM\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from Utils.dataLoader_utils import seq_padding,position_idx,index_seg,random_mask\n",
    "from Utils.add_endpoints import add_endp\n",
    "from Utils.handle_file import handle_file\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertEncoder, BertPooler, BertOnlyMLMHead\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from Utils.handle_file import handle_file\n",
    "hf = handle_file()\n",
    "from Utils.preprocessing import cal_age, cal_therapies, spark_init, cal_subtherapies, int_to_list, flatten_list, int_to_str, cal_therapies_fr, divide_frame\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions, MaskedLMOutput\n",
    "\n",
    "import torch.nn as nn\n",
    "import pytorch_pretrained_bert as Bert\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Optional, Tuple, Union\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e30e726-28e5-4f07-b9fa-0e54acc045f3",
   "metadata": {},
   "source": [
    "#### Perform Masked Language Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94a96b-2939-407c-b838-2bd414a9c60a",
   "metadata": {},
   "source": [
    "1. Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2753b87-69fc-4695-a520-d4829506637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_delim_for_chunks(sequence, n):\n",
    "    \"\"\"Compute chunks of sequence that will be use to predict delay\n",
    "    Take as input the sequence and the number of visits we want to consider for the chunk\n",
    "    return the chunked sequence for the task and the real delay following that sequence \"\"\"\n",
    "    np.random.seed(seed=2)\n",
    "    \n",
    "    num_of_visits=0\n",
    "    sep_index = [0]  ## start with the first CLS so that when we will choose random start, the first vist can be part of the choices\n",
    "\n",
    "    for i in range(len(sequence)): \n",
    "        if sequence[i] == 'SEP': \n",
    "            num_of_visits+=1\n",
    "            sep_index.append(i+1)\n",
    "            \n",
    "    if n >= num_of_visits:\n",
    "        n = num_of_visits -1 \n",
    "\n",
    "    start = np.random.choice(sep_index[:len(sep_index)-1-(n)], 1)[0]  ### Start for the chunk must be from 0 to n step before the end of the sep_sequence (in order to have n visits at least from the start) and - 1 is for the last SEP which is the end of the sequence that can't be taken into account to predict delay (bc it's the last visit)\n",
    "    stop = sep_index[sep_index.index(start) + n]\n",
    "    \n",
    "    return start, stop\n",
    "\n",
    "def get_visits_for_delay_prediction(sequence, n, token2idx):\n",
    "    start, stop = get_delim_for_chunks(sequence, n)\n",
    "    \n",
    "    chunk = sequence[start+1:stop]\n",
    "    delay = sequence[stop]\n",
    "    \n",
    "    output_token = []\n",
    "    for i, token in enumerate(chunk):\n",
    "        output_token.append(token2idx.get(token, token2idx['UNK']))\n",
    "        \n",
    "    return chunk, output_token, delay\n",
    "    \n",
    "def get_other_subsequences(sequence, other_sequence, n):\n",
    "   \n",
    "    start, stop = get_delim_for_chunks(sequence, n)\n",
    "    chunk = other_sequence[start+1:stop]\n",
    "    return chunk\n",
    "      \n",
    "    \n",
    "class PretrainLoader(Dataset):\n",
    "    def __init__(self,  token2idx, mod2idx, max_len, dataframe, mlb=None, code='inputs', age='age', mod = 'modalities', delay = 'delays_in_months',  age2idx = None, del2idx=None, age_in_inputs = False, delays_in_inputs = False, right_percentage = 1, split = False, baseline=False, seed = 42, pretrain='NDP', n = 5):\n",
    "        self.baseline= baseline\n",
    "        self.vocab = token2idx\n",
    "        self.mod2idx = mod2idx\n",
    "        self.max_len = max_len\n",
    "        self.split = split\n",
    "        self.r_percentage = right_percentage\n",
    "        self.seed = seed\n",
    "        self.code = dataframe[code]\n",
    "        self.modalities = dataframe[mod]\n",
    "        self.age_in_inputs = age_in_inputs\n",
    "        self.delays_in_inputs = delays_in_inputs\n",
    "        self.n = n\n",
    "        self.pretrain = pretrain\n",
    "        self.del2idx = del2idx\n",
    "        self.age2idx = age2idx\n",
    "        self.mlb = mlb\n",
    "        if age2idx is not None: \n",
    "            self.age = dataframe[age]\n",
    "            \n",
    "        if del2idx is not None:\n",
    "            self.delay = dataframe[delay]\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        return: age, code, position, segmentation, mask, label\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.pretrain == 'MLM':\n",
    "\n",
    "            # extract data\n",
    "            code = self.code[index][(-self.max_len+1):]\n",
    "            modalities = self.modalities[index][(-self.max_len+1):]\n",
    "        \n",
    "            mask = np.ones(self.max_len)\n",
    "            mask[len(code):] = 0\n",
    "        \n",
    "            # pad age sequence and code sequence\n",
    "            modalities = seq_padding(modalities, self.max_len, self.split, self.r_percentage, token2idx=self.mod2idx)\n",
    "\n",
    "            # put mask in input sequence\n",
    "            # token : unchanged sequence, code :  index of sequence with masked token = 3, label: -1 for unmasked token and label index for masked token \n",
    "            tokens, code, label = random_mask(code, self.vocab, self.seed)\n",
    "    \n",
    "           # get position code and segment code\n",
    "            tokens = seq_padding(tokens, self.max_len, self.split, self.r_percentage)\n",
    "            position = position_idx(tokens)\n",
    "            segment = index_seg(tokens)\n",
    "\n",
    "           # pad code and label\n",
    "            code = seq_padding(code, self.max_len, self.split, self.r_percentage, symbol=self.vocab['PAD'])\n",
    "            label = seq_padding(label, self.max_len, self.split, self.r_percentage, symbol=-1)\n",
    "            \n",
    "            if self.del2idx is not None:\n",
    "                delay = self.delay[index][(-self.max_len+1):]\n",
    "                delay = seq_padding(delay, self.max_len, self.split, self.r_percentage, token2idx=self.del2idx)\n",
    "            \n",
    "            if self.age2idx is not None: \n",
    "                age = self.age[index][(-self.max_len+1):]\n",
    "                age = seq_padding(age, self.max_len, self.split, self.r_percentage, token2idx=self.age2idx)\n",
    "              \n",
    "            \n",
    "            if self.delays_in_inputs: \n",
    "                if self.baseline:\n",
    "                    for col in [code, modalities, segment, mask, label]:\n",
    "                        random.Random(42).shuffle(col)\n",
    "\n",
    "                return torch.LongTensor(code), torch.LongTensor(modalities), torch.LongTensor(segment), torch.LongTensor(position), torch.LongTensor(mask), torch.LongTensor(label)\n",
    "            \n",
    "            elif self.age_in_inputs:  \n",
    "                if self.baseline:\n",
    "                    for col in [code, modalities, delay, segment, mask, label]:\n",
    "                        random.Random(42).shuffle(col)\n",
    "                return torch.LongTensor(code), torch.LongTensor(modalities), torch.LongTensor(delay), torch.LongTensor(segment), torch.LongTensor(position), torch.LongTensor(mask), torch.LongTensor(label)\n",
    "          \n",
    "            else:\n",
    "                return torch.LongTensor(code), torch.LongTensor(modalities), torch.LongTensor(age), torch.LongTensor(delay), torch.LongTensor(segment), torch.LongTensor(position), torch.LongTensor(mask), torch.LongTensor(label)\n",
    "\n",
    "        elif self.pretrain == 'NDP':\n",
    "            \n",
    "            code = self.code[index]\n",
    "        \n",
    "            modalities = self.modalities[index]\n",
    "            modalities = get_other_subsequences(code, modalities, n = self.n)\n",
    "            modalities = seq_padding(modalities, self.max_len, token2idx=self.mod2idx)\n",
    "            \n",
    "            NPI = self.NPI[index]\n",
    "            NPI = get_other_subsequences(code, NPI, n = self.n)\n",
    "            NPI = seq_padding(NPI, self.max_len, token2idx=self.NPI2idx)\n",
    "            \n",
    "            if self.del2idx is not None: \n",
    "                delay = self.delay[index]\n",
    "                delay = get_other_subsequences(code, delay, n=self.n)\n",
    "                delay = seq_padding(delay, self.max_len, token2idx=self.del2idx)\n",
    "                \n",
    "            if self.age2idx is not None:\n",
    "                age = self.age[index]\n",
    "                age = get_other_subsequences(code, age, n= self.n)\n",
    "                age = seq_padding(age, self.max_len, token2idx=self.age2idx)\n",
    "                \n",
    "            tokens, code, label = get_visits_for_delay_prediction(code, n=self.n, token2idx=self.vocab)\n",
    "            \n",
    "            mask = np.ones(self.max_len)\n",
    "            mask[len(code):] = 0\n",
    "            \n",
    "            # get position code and segment code\n",
    "            tokens = seq_padding(tokens, self.max_len, self.split, self.r_percentage)\n",
    "            position = position_idx(tokens)\n",
    "            segment = index_seg(tokens)\n",
    "            \n",
    "            code = seq_padding(code, self.max_len, self.split, self.r_percentage, symbol=self.vocab['PAD'])\n",
    "            \n",
    "            label = torch.LongTensor(self.mlb.transform([[label]]))\n",
    "            \n",
    "            if self.delays_in_inputs: \n",
    "                return torch.LongTensor(code), torch.LongTensor(modalities), torch.LongTensor(segment), torch.LongTensor(position), torch.LongTensor(NPI), torch.LongTensor(mask), label\n",
    "            \n",
    "            elif self.age_in_inputs:  \n",
    "                return torch.LongTensor(code), torch.LongTensor(modalities), torch.LongTensor(delay), torch.LongTensor(segment), torch.LongTensor(position), torch.LongTensor(NPI), torch.LongTensor(mask), label\n",
    "            \n",
    "            else:\n",
    "                return torch.LongTensor(code), torch.LongTensor(modalities), torch.LongTensor(age), torch.LongTensor(delay), torch.LongTensor(segment), torch.LongTensor(position), torch.LongTensor(NPI), torch.LongTensor(mask), label\n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.code)\n",
    "    \n",
    "## Datasets\n",
    "def import_datasets(config,  min_visit , inputs= \"inputs_normal_range_and_delta_age_and_deltas_preprocessed_tolist\"):\n",
    "    \n",
    "    \"\"\"Import train data \"\"\"\n",
    "        \n",
    "    data =  hf._load_pkl(config['data'])[0]\n",
    "\n",
    "    \n",
    "    \"\"\"Remove patients that have less visits than min visit\"\"\"\n",
    "    # Remove patients with visits less than min visit\n",
    "\n",
    "    previous_shape = data.shape[0]\n",
    "\n",
    "    data['length'] = data[inputs].apply(lambda x: len([i for i in range(len(x)) if x[i] == 'SEP']))\n",
    "    data = data[data['length'] >= min_visit]\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    print(\"We lost {} patient(s)\".format(previous_shape - data.shape[0]))\n",
    "    \n",
    "    \"\"\"split data into train and validation data\"\"\"\n",
    "    train, valid = np.split(data.sample(frac=1, random_state=42), [int(.9*len(data))])\n",
    "    train.index = range(len(train))\n",
    "    valid.index = range(len(valid))\n",
    "    \n",
    "    return train, valid\n",
    "\n",
    "## Scores\n",
    "\"\"\" Calculate precision for the NDP \"\"\"\n",
    "def compute_precision(logits, labels, training=True):\n",
    "    \"\"\"\n",
    "    Compute score for the pretraining task which represents precision:\n",
    "    Take as input logits in probabilities and labels in a 2D array\n",
    "    Return: precision score\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if training:\n",
    "        labels, logits = labels.detach().cpu().numpy(), logits.detach().cpu().numpy()\n",
    "        \n",
    "    logs = nn.LogSoftmax(dim = 1)\n",
    " \n",
    "    truepred = logs(torch.tensor(logits))\n",
    "    outs = np.zeros(labels.shape)\n",
    "    ind = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
    "\n",
    "    for i in range(len(ind)):\n",
    "        outs[i][ind[i]] = 1\n",
    "    \n",
    "    precision = precision_score(labels, outs, average='macro')\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "\"\"\" Calculate precision for the MLM \"\"\"\n",
    "\n",
    "def cal_acc(label, pred):\n",
    "    logs = nn.LogSoftmax(dim = 1)\n",
    "    label=label.cpu().numpy()\n",
    "    ind = np.where(label!=-1)[0]\n",
    "    truepred = pred.detach().cpu().numpy()\n",
    "    truepred = truepred[ind]\n",
    "    truelabel = label[ind]\n",
    "    truepred = logs(torch.tensor(truepred))\n",
    "    outs = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
    "    precision = precision_score(truelabel, outs, average='macro')\n",
    "    return precision\n",
    "\n",
    "## 3. MISC\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721bd63d-5851-4e4e-804c-06b9e3dfefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, segment, age\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "        self.config = config\n",
    "        self.activation = config.activation\n",
    "        self.position_embedding_type = getattr(config, 'position_embedding_type', 'bert_embedding')\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "        self.modalities_embeddings = nn.Embedding(config.modalities_vocab_size, config.hidden_size)\n",
    "        self.segment_embeddings = nn.Embedding(config.seg_vocab_size, config.hidden_size)\n",
    "        \n",
    "        if self.position_embedding_type == \"absolute\":\n",
    "            self.posi_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        else:\n",
    "            self.posi_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size). \\\n",
    "            from_pretrained(embeddings=self._init_posi_embedding(config.max_position_embeddings, config.hidden_size))\n",
    "\n",
    "        \n",
    "        if self.activation:\n",
    "            self.age_embeddings = SineActivation(config.age_vocab_size, config.hidden_size)\n",
    "            self.delays_embeddings = SineActivation(config.delay_vocab_size, config.hidden_size)\n",
    "            \n",
    "        else: \n",
    "            self.age_embeddings = nn.Embedding(config.age_vocab_size, config.hidden_size)\n",
    "            self.delays_embeddings = nn.Embedding(config.delay_vocab_size, config.hidden_size)\n",
    "            \n",
    "        self.LayerNorm = Bert.modeling.BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)  #eps default = 1e-12\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, word_ids, modalities_ids = None, age_ids=None, delays_ids = None, seg_ids=None, posi_ids=None, age_in_inputs=False, delays_in_inputs = False):\n",
    "        if seg_ids is None:\n",
    "            seg_ids = torch.zeros_like(word_ids)\n",
    "        if age_ids is None:\n",
    "            age_ids = torch.zeros_like(word_ids)\n",
    "        if posi_ids is None:\n",
    "            posi_ids = torch.zeros_like(word_ids)\n",
    "        if delays_ids is None:\n",
    "            delays_ids = torch.zeros_like(word_ids)\n",
    "        if modalities_ids is None:\n",
    "            modalities_ids = torch.zeros_like(word_ids)\n",
    "        \n",
    "        \n",
    "        word_embed = self.word_embeddings(word_ids)\n",
    "        segment_embed = self.segment_embeddings(seg_ids)\n",
    "        modalities_embed = self.modalities_embeddings(modalities_ids)\n",
    "        age_embed = self.age_embeddings(age_ids)\n",
    "        delays_embed = self.delays_embeddings(delays_ids)\n",
    "        posi_embeddings = self.posi_embeddings(posi_ids)\n",
    "        \n",
    "        if self.config.age_in_inputs:\n",
    "            embeddings = word_embed + segment_embed + delays_embed + modalities_embed + posi_embeddings\n",
    "        if self.config.delays_in_inputs:\n",
    "            embeddings = word_embed + segment_embed + modalities_embed + posi_embeddings\n",
    "            \n",
    "        else:\n",
    "            embeddings = word_embed + segment_embed + posi_embeddings + modalities_embed + delays_embed + age_embed\n",
    "\n",
    "            \n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    def _init_posi_embedding(self, max_position_embedding, hidden_size):\n",
    "        def even_code(pos, idx):\n",
    "            return np.sin(pos / (10000 ** (2 * idx / hidden_size)))\n",
    "\n",
    "        def odd_code(pos, idx):\n",
    "            return np.cos(pos / (10000 ** (2 * idx / hidden_size)))\n",
    "\n",
    "        # initialize position embedding table\n",
    "        lookup_table = np.zeros((max_position_embedding, hidden_size), dtype=np.float32)\n",
    "\n",
    "        # reset table parameters with hard encoding\n",
    "        # set even dimension\n",
    "        for pos in range(max_position_embedding):\n",
    "            for idx in np.arange(0, hidden_size, step=2):\n",
    "                lookup_table[pos, idx] = even_code(pos, idx)\n",
    "        # set odd dimension\n",
    "        for pos in range(max_position_embedding):\n",
    "            for idx in np.arange(1, hidden_size, step=2):\n",
    "                lookup_table[pos, idx] = odd_code(pos, idx)\n",
    "\n",
    "        return torch.tensor(lookup_table)\n",
    "\n",
    "\n",
    "def t2v(tau, f, out_features, w, b, w0, b0, arg=None):\n",
    "    if arg:\n",
    "        v1 = f(torch.matmul(tau, w) + b, arg)\n",
    "    else:\n",
    "        #print(w.shape, t1.shape, b.shape)\n",
    "        v1 = f(torch.matmul(tau, w) + b)\n",
    "    v2 = torch.matmul(tau, w0) + b0\n",
    "    #print(v1.shape)\n",
    "    return torch.cat([v1, v2], -1)\n",
    "\n",
    "class SineActivation(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SineActivation, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.w0 = nn.parameter.Parameter(torch.randn(in_features, 1))\n",
    "        self.b0 = nn.parameter.Parameter(torch.randn(1))\n",
    "        self.w = nn.parameter.Parameter(torch.randn(in_features, out_features-1))\n",
    "        self.b = nn.parameter.Parameter(torch.randn(out_features-1))\n",
    "        self.f = torch.sin\n",
    "\n",
    "    def forward(self, tau):\n",
    "        emb = list()\n",
    "        for batch in tau:\n",
    "            out_list = list()\n",
    "            for pos in batch: \n",
    "                out = t2v(pos.reshape(-1, 1), self.f, self.out_features, self.w, self.b, self.w0, self.b0)\n",
    "                out_list.append(torch.flatten(out))\n",
    "            emb.append(torch.stack(out_list, 0))\n",
    "        return torch.stack(emb, 0)\n",
    "    \n",
    "    \n",
    "class BertModel(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertModel, self).__init__(config)\n",
    "        self.age_in_inputs = config.age_in_inputs\n",
    "        self.delays_in_inputs = config.delays_in_inputs\n",
    "        self.embeddings = BertEmbeddings(config=config)\n",
    "        self.encoder = Bert.modeling.BertEncoder(config=config)\n",
    "        self.pooler = Bert.modeling.BertPooler(config)\n",
    "        self.post_init()\n",
    "\n",
    "\n",
    "    def forward(self, input_ids,  modalities_ids = None, age_ids=None, delays_ids = None, seg_ids=None, posi_ids=None, attention_mask=None,\n",
    "                output_all_encoded_layers=True)-> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        if age_ids is None:\n",
    "            age_ids = torch.zeros_like(input_ids)\n",
    "        if seg_ids is None:\n",
    "            seg_ids = torch.zeros_like(input_ids)\n",
    "        if posi_ids is None:\n",
    "            posi_ids = torch.zeros_like(input_ids)\n",
    "        if delays_ids is None:\n",
    "            delays_ids = torch.zeros_like(input_ids)\n",
    "        if modalities_ids is None:\n",
    "            modalities_ids = torch.zeros_like(input_ids)\n",
    "     \n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
    "        # this attention mask is more simple than the triangular masking of causal attention\n",
    "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(input_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids, age_in_inputs = self.age_in_inputs, delays_in_inputs = self.delays_in_inputs)\n",
    "        encoded_layers = self.encoder(embedding_output,\n",
    "                                      extended_attention_mask,\n",
    "                                      output_all_encoded_layers=output_all_encoded_layers)\n",
    "        sequence_output = encoded_layers[-1]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "        if not output_all_encoded_layers:\n",
    "            encoded_layers = encoded_layers[-1]\n",
    "        return encoded_layers, pooled_output\n",
    "\n",
    "\n",
    "class BertForMaskedLM(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForMaskedLM, self).__init__(config)\n",
    "        \n",
    "        if config.is_decoder:\n",
    "            raise ('To use BertForMaskedLM, config.is_decoder need to be set to False for bi-directional self-attention')\n",
    "            \n",
    "        self.bert = BertModel(config)\n",
    "        self.cls = BertOnlyMLMHead(config)#, self.bert.embeddings.word_embeddings.weight)\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_ids, modalities_ids = None, age_ids=None, delays_ids = None, seg_ids =None, posi_ids=None, attention_mask=None, masked_lm_labels=None)-> Union[Tuple[torch.Tensor], MaskedLMOutput]:\n",
    "        outputs = self.bert(input_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        sequence_output = outputs[0]\n",
    "        prediction_scores = self.cls(sequence_output)\n",
    "        \n",
    "        masked_lm_loss = None\n",
    "        if masked_lm_labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)  # -100 index = padding token\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), masked_lm_labels.view(-1))\n",
    "            return masked_lm_loss, prediction_scores.view(-1, self.config.vocab_size), masked_lm_labels.view(-1)\n",
    "            \n",
    "        else:\n",
    "            return prediction_scores\n",
    "            \n",
    "   #     return MaskedLMOutput(\n",
    "     #       loss=masked_lm_loss,\n",
    "     #       logits=prediction_scores,\n",
    "    #        hidden_states=outputs.hidden_states,\n",
    "    #        attentions=outputs.attentions,\n",
    "    #    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ec165-bf19-4d84-8cc3-e98e5a546fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Calculate precision for the MLM \"\"\"\n",
    "\n",
    "def cal_acc(label, pred):\n",
    "    logs = nn.LogSoftmax(dim = 1)\n",
    "    label=label.cpu().numpy()\n",
    "    ind = np.where(label!=-1)[0]\n",
    "    truepred = pred.detach().cpu().numpy()\n",
    "    truepred = truepred[ind]\n",
    "    truelabel = label[ind]\n",
    "    truepred = logs(torch.tensor(truepred))\n",
    "    outs = [np.argmax(pred_x) for pred_x in truepred.numpy()]\n",
    "    precision = skm.precision_score(truelabel, outs, average='macro')\n",
    "    return precision\n",
    "\n",
    "\"\"\" Function that allows to measure elapsed time for a function \"\"\"\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\"\"\" Set seed to allow reproducibility \"\"\"\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    \n",
    "\"\"\" Build loader for datasets \"\"\"\n",
    "\n",
    "def load_data(data, config, inputs='inputs_normal_range_and_delta_age_preprocessed_tolist', \n",
    "       mod='modalities_for_twos_and_age_preprocessed_tolist', delay= 'delays_categorized_for_twos_and_age_preprocessed_tolist',\n",
    "              shuffle=False, num_workers = 3, seed=42, baseline=False):\n",
    "  \n",
    "    Dset = PretrainLoader(token2idx = tokenVocab,  mod2idx = modalitiesVocab, del2idx=delayVocab, max_len=train_params['max_len_seq'], dataframe=data, code=inputs, \n",
    "               mod = mod, delay=delay, delays_in_inputs=False, age_in_inputs=True, pretrain='MLM', baseline=baseline)  \n",
    "    dataload = DataLoader(dataset=Dset, batch_size=config.batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "    return dataload\n",
    "\n",
    "\"\"\" Use the GPU if it's available \"\"\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are %d GPU(s) available. \" %torch.cuda.device_count())\n",
    "    print(\"We will use the GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
    "    \n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6aed74-d579-49ff-9aa2-6fc2db3a2711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f2e87-1c1d-4346-b7ce-e295c999810a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "compliant-agenda",
   "metadata": {},
   "source": [
    "2. Config  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f93b51d-ca83-4cbe-9b4b-4a48478f846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find BEHRT/Early_integration/Tasks/MLM_npi_final.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mndeyemaguettemb\u001b[0m (\u001b[33mehr\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "os.environ['https_proxy'] = \"\"\n",
    "os.environ['http_proxy'] = \"\"\n",
    "os.environ['no_proxy']= \"\"\n",
    "os.environ['HTTPS_PROXY']= \"\"\n",
    "os.environ['HTTP_PROXY']= \"\"\n",
    "os.environ['NO_PROXY']= \"\"\n",
    "\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'BEHRT/Early_integration/Tasks/MLM_npi_final.ipynb'\n",
    "os.environ['WANDB_API_KEY'] = \"4944e153a8b0f45a64d749b14d6916d253a54426\"\n",
    "os.environ['WANDB_NAME'] = \"MLM_final_run\"\n",
    "os.environ['WANDB_NOTES'] = \"Best hps for MLM\"\n",
    "\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c4a27e-5301-4713-9a03-b3b25387b761",
   "metadata": {},
   "source": [
    "3. Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5304c5f0-ba66-4c40-bd39-d0c3f8430851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_config = {'data': 'whole_data_preprocessed_v2_for_pretrain_exploded.pkl', \n",
    "    'model_path': 'BEHRT/Early_integration/Tasks/Output/Second_run', # where to save model\n",
    "    'model_name': 'MLM_embeddings_final', # model name\n",
    "    'file_name': 'MLM_embeddings_final',  # log path\n",
    "}\n",
    "create_folder(file_config['model_path'])  ## on crée un folder ou stocker le modele \n",
    "\n",
    "global_params = {\n",
    "    'max_seq_len': 512,\n",
    "    'max_age': 110,\n",
    "    'max_delay': 30, ## = 30years\n",
    "    'age_month': 12,\n",
    "    'delay_month': 0.25,\n",
    "    'age_symbol': None,\n",
    "    'min_visit': 1,\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'device': device,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faefd1b-cb80-4c9e-8e41-1400f1494845",
   "metadata": {},
   "source": [
    "#### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28431861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age_100_therap_removed_into_chunks_tolist</th>\n",
       "      <th>delays_100_therap_removed_into_chunks_tolist</th>\n",
       "      <th>modalities_100_therap_removed_into_chunks_tolist</th>\n",
       "      <th>inputs_quantiles_preprocessed_100_therap_removed_tolist</th>\n",
       "      <th>inputs_normal_range_preprocessed_100_therap_removed_tolist</th>\n",
       "      <th>inputs_curve_intersections_preprocessed_100_therap_removed_tolist</th>\n",
       "      <th>report</th>\n",
       "      <th>Num_dossier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['61', '61', '61', '61', '61', '61', '61', '61...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['DEB', 'biologique', 'biologique', 'biologiqu...</td>\n",
       "      <td>['CLS', '1.0', '1.0', '1.0', '1.0', '1.0', '1....</td>\n",
       "      <td>['CLS', '1.0', '1.0', '2.0', '2.0', '1.0', '1....</td>\n",
       "      <td>['CLS', '1.0', '1.0', '1.0', '1.0', '1.0', '1....</td>\n",
       "      <td>[\"\\nCorps du document\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n16/07...</td>\n",
       "      <td>00002f6df9cfcb97985c88f5787ba874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['42', '42', '42', '42', '42', '42', '42', '42...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['DEB', 'biologique', 'biologique', 'biologiqu...</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....</td>\n",
       "      <td>[\"\\nCorps du document\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n23/...</td>\n",
       "      <td>00013328b341eedd7d4d788140b765a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['45', '45', '45', '45', '45', '45', '45', '45...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['DEB', 'biologique', 'biologique', 'biologiqu...</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....</td>\n",
       "      <td>[\"\\nCorps du document\\n\\nours en cours.  Il s'...</td>\n",
       "      <td>000ad3d5781425daf543e1cf0e099ec6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['46', '46', '46', '46', '46', '46', '46', '46...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['DEB', 'biologique', 'biologique', 'biologiqu...</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'co...</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'co...</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'co...</td>\n",
       "      <td>[\"\\nCorps du document\\n\\nPatiente née le 20/07...</td>\n",
       "      <td>000c21bab84929a0029ade6db24d5b75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['49', '49', '49', '49', '49', '49', '49', '49...</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0', '0', ...</td>\n",
       "      <td>['DEB', 'biologique', 'biologique', 'biologiqu...</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'ra...</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'ra...</td>\n",
       "      <td>['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'ra...</td>\n",
       "      <td>['\\nCorps du document\\n\\nMammographie de ville...</td>\n",
       "      <td>00143b158e6cad759fddbd194f7ed284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          age_100_therap_removed_into_chunks_tolist  \\\n",
       "0           0  ['61', '61', '61', '61', '61', '61', '61', '61...   \n",
       "1           1  ['42', '42', '42', '42', '42', '42', '42', '42...   \n",
       "2           2  ['45', '45', '45', '45', '45', '45', '45', '45...   \n",
       "3           3  ['46', '46', '46', '46', '46', '46', '46', '46...   \n",
       "4           4  ['49', '49', '49', '49', '49', '49', '49', '49...   \n",
       "\n",
       "        delays_100_therap_removed_into_chunks_tolist  \\\n",
       "0  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "1  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "2  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "3  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "4  ['0', '0', '0', '0', '0', '0', '0', '0', '0', ...   \n",
       "\n",
       "    modalities_100_therap_removed_into_chunks_tolist  \\\n",
       "0  ['DEB', 'biologique', 'biologique', 'biologiqu...   \n",
       "1  ['DEB', 'biologique', 'biologique', 'biologiqu...   \n",
       "2  ['DEB', 'biologique', 'biologique', 'biologiqu...   \n",
       "3  ['DEB', 'biologique', 'biologique', 'biologiqu...   \n",
       "4  ['DEB', 'biologique', 'biologique', 'biologiqu...   \n",
       "\n",
       "  inputs_quantiles_preprocessed_100_therap_removed_tolist  \\\n",
       "0  ['CLS', '1.0', '1.0', '1.0', '1.0', '1.0', '1....        \n",
       "1  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....        \n",
       "2  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....        \n",
       "3  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'co...        \n",
       "4  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'ra...        \n",
       "\n",
       "  inputs_normal_range_preprocessed_100_therap_removed_tolist  \\\n",
       "0  ['CLS', '1.0', '1.0', '2.0', '2.0', '1.0', '1....           \n",
       "1  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....           \n",
       "2  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....           \n",
       "3  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'co...           \n",
       "4  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'ra...           \n",
       "\n",
       "  inputs_curve_intersections_preprocessed_100_therap_removed_tolist  \\\n",
       "0  ['CLS', '1.0', '1.0', '1.0', '1.0', '1.0', '1....                  \n",
       "1  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....                  \n",
       "2  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', '0....                  \n",
       "3  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'co...                  \n",
       "4  ['CLS', '0.0', '0.0', '0.0', '0.0', '0.0', 'ra...                  \n",
       "\n",
       "                                              report  \\\n",
       "0  [\"\\nCorps du document\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n16/07...   \n",
       "1  [\"\\nCorps du document\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n23/...   \n",
       "2  [\"\\nCorps du document\\n\\nours en cours.  Il s'...   \n",
       "3  [\"\\nCorps du document\\n\\nPatiente née le 20/07...   \n",
       "4  ['\\nCorps du document\\n\\nMammographie de ville...   \n",
       "\n",
       "                        Num_dossier  \n",
       "0  00002f6df9cfcb97985c88f5787ba874  \n",
       "1  00013328b341eedd7d4d788140b765a2  \n",
       "2  000ad3d5781425daf543e1cf0e099ec6  \n",
       "3  000c21bab84929a0029ade6db24d5b75  \n",
       "4  00143b158e6cad759fddbd194f7ed284  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = hf._load_pkl(file_config['data'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837af69-b915-464c-9515-3892822a8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = import_datasets(file_config, inputs = 'inputs_normal_range_and_delta_age_preprocessed_tolist', min_visit= global_params['min_visit'] )\n",
    "print(train.shape, valid.shape)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29857c22-cbb9-47fb-bdbd-6120ce44f5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We lost 0 patient\n"
     ]
    }
   ],
   "source": [
    "train.index = range(len(train))\n",
    "valid.index = range(len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61730174-1f57-45d2-a836-d40222a7a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf._dump_pkl(train.index, 'BEHRT/Early_integration/Files/MLM_train_idxs')\n",
    "hf._dump_pkl(valid.index, 'BEHRT/Early_integration/Files/MLM_valid_idxs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c902f-6c8c-47df-a804-b5fb8f86cc41",
   "metadata": {},
   "source": [
    "a. Compute vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cdd7ec-0e8b-490d-8b48-2e56a9c60e58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b1/jf_78yv56k71f696t4mbm2jw0000gn/T/ipykernel_24179/2879002705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenVocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_quantiles_preprocessed_100_therap_removed_tolist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age_symbol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mageVocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mage_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_age\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age_month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age_symbol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodalitiesVocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodalities_100_therap_removed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age_symbol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdelayVocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelay_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_delay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delay_month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age_symbol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Cluster/BEHRT /Utils/utils.py\u001b[0m in \u001b[0;36minput_vocab\u001b[0;34m(inputs, symbol)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minputs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m## the unique values in different lists from data.input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minputs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0minputs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SEP'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0minputs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CLS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "inputs = \"inputs_normal_range_and_delta_age_preprocessed_tolist\"\n",
    "modalities = \"modalities_for_twos_and_age_preprocessed_tolist\"\n",
    "\n",
    "data = pd.concat([train, valid])\n",
    "categorized = True\n",
    "\n",
    "tokenVocab, _ = input_vocab(inputs = data[inputs], symbol=global_params['age_symbol'])\n",
    "modalitiesVocab, _ = mod_vocab(data[modalities], symbol=global_params['age_symbol'])\n",
    "delayVocab = {'PAD':0, 'UNK':1, 'W0':2, 'W1':3, 'W2':4, 'W3':5, 'M1':6, 'M2':7, 'M3':8, 'M4':9, 'M5':10, 'M6':11, 'M7':12, 'M8':13, 'M9':14, 'M10':15, 'M11':16, 'M12':17, 'LT':18}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaaa4a8-d9a3-4499-9b0f-78dc8cbd69f4",
   "metadata": {},
   "source": [
    "b. Remove patients with less visits than minimum visit (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db61e71-fc3b-4bb0-8cd5-17dbc1b86579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove patients with visits less than min visit\n",
    "\n",
    "previous_shape = data.shape[0]\n",
    "\n",
    "data['length'] = data[inputs].apply(lambda x: len([i for i in range(len(x)) if x[i] == 'SEP']))\n",
    "data = data[data['length'] >= global_params['min_visit']]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(\"We lost {} patient(s)\".format(previous_shape - data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d375fef-474a-40be-b273-08cff4037a92",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3603d7a4-1d81-42f9-92af-ecb968cebbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import optimiser\n",
    "\n",
    "def define_model(config):\n",
    "    conf = BertConfig(config)\n",
    "    model = BertForMaskedLM(conf)\n",
    "    model = model.to(train_params['device'])\n",
    "    optim = optimiser.adam(params=list(model.named_parameters()), config=config)\n",
    "    \n",
    "    return model,optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af110443-0fe4-4bf0-8b8a-9cf25717eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Config for MLM with sweep (wandb)\n",
    "\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "        \n",
    "class BertConfig(PretrainedConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size=config.get('vocab_size'),\n",
    "            hidden_size=config.get('hidden_size'),\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embeddings'),\n",
    "            position_embedding_type = config.get('position_embedding_type'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "            layer_norm_eps = config.get('layer_norm_eps'),\n",
    "            output_hidden_states=config.get('output_hidden_states'),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.delay_vocab_size = config.get('delay_vocab_size')\n",
    "        self.output_hidden_states=config.get('output_hidden_states')\n",
    "        self.modalities_vocab_size = config.get('modalities_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.delay_vocab_size= config.get('delay_vocab_size')\n",
    "        self.activation = config.get('activation')\n",
    "        self.output_attentions = config.get('output_attentions')\n",
    "        self.chunk_size_feed_forward = config.get('chunk_size_feed_forward')\n",
    "        self.is_decoder = config.get('is_decoder')\n",
    "        self.layer_norm_eps = config.get('layer_norm_eps')\n",
    "        self.add_cross_attention = config.get('add_cross_attention')\n",
    "        self.age_in_inputs = config.get('age_in_inputs')\n",
    "        self.delays_in_inputs = config.get('delays_in_inputs')\n",
    "        self.batch_size = config.get('batch_size')\n",
    "       \n",
    "        \n",
    "class TrainConfig(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e924162-da42-48b5-9e93-0a70a9972f3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenVocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b1/jf_78yv56k71f696t4mbm2jw0000gn/T/ipykernel_35584/1068215359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;34m'attention_probs_dropout_prob'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;34m'hidden_act'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'gelu'\u001b[0m\u001b[0;34m,\u001b[0m                                                 \u001b[0;31m# The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0;34m'vocab_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenVocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                                  \u001b[0;31m# number of disease + symbols for word embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0;34m'seg_vocab_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m                                                             \u001b[0;31m# number of vocab for seg embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;34m'modalities_vocab_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodalitiesVocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenVocab' is not defined"
     ]
    }
   ],
   "source": [
    "## Config for MLM with sweep (wandb)\n",
    "\n",
    "config = {'hidden_size':  144,       # word embedding and seg embedding hidden size\n",
    "                'intermediate_size': 133,                # the size of the \"intermediate\" layer in the transformer encoder\n",
    "                'hidden_dropout_prob': 0.2,                    # dropout rate\n",
    "                'num_hidden_layers': 5,                   # number of multi-head attention layers required\n",
    "                'num_attention_heads': 12,                  # number of attention heads\n",
    "                'attention_probs_dropout_prob':0.2,\n",
    "                'hidden_act': 'gelu',                                                 # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "                'vocab_size': len(tokenVocab),                                                  # number of disease + symbols for word embedding\n",
    "                'seg_vocab_size': 2,                                                             # number of vocab for seg embedding\n",
    "                'modalities_vocab_size': len(modalitiesVocab), \n",
    "                'age_vocab_size': 1,                                                 # number of vocab for age embedding\n",
    "                'delay_vocab_size': len(delayVocab),\n",
    "                'epochs': 120, \n",
    "                'max_position_embeddings': train_params['max_len_seq'],                          # maximum number of tokens\n",
    "                'initializer_range':0.02,                                                     # parameter weight initializer range\n",
    "                'lr' : 0.001,                     # a flat distribution between 0 and 0.1\n",
    "                'warmup_proportion': 0.01, \n",
    "                'weight_decay' : 0.01, \n",
    "                'batch_size': 64,   # integers between 8 and 32 # with evenly-distributed logarithm\n",
    "                'gradient_accumulation_steps': 4,    \n",
    "                'layer_norm_eps': 0.00001,\n",
    "                'position_embedding_type': 'bert_embedding', \n",
    "                'age_in_inputs': True,\n",
    "                'delays_in_inputs':False,\n",
    "                'activation': False,\n",
    "                'counts': 5}\n",
    "                #'early_terminate': {'type': 'hyperband', 's': 2, 'eta': 3, 'max_iter': 27},\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404da3da-7e1f-44f1-b33e-c99ebb7c35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initiate model with new parameters (useful for new runs)\n",
    "\n",
    "def initiate_model(config):\n",
    "    conf = BertConfig(config)\n",
    "    model = BertForMaskedLM(conf)\n",
    "    model = model.to(train_params['device'])\n",
    "    optim = adam(params=list(model.named_parameters()), config=config)\n",
    "    \n",
    "    return model, optim\n",
    "\n",
    "# save\n",
    "def save(model, optimizer, count):\n",
    "    # save\n",
    "    torch.save({\n",
    "        f'model_state_dict_{count}': model.state_dict(),\n",
    "        f'optimizer_state_dict_{count}': optimizer.state_dict()\n",
    "    }, output_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9bf990-ed5d-4d0f-b9b6-930841a2608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME\n",
    "\n",
    "def empty_cuda():\n",
    "    \"\"\" Empty the cache to enable the use of the gpu \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "    \n",
    "\n",
    "def training_per_epoch(e, model, optim, config, loader, train_params):\n",
    "        \n",
    "        output_dir = \"./pretrained_models/\"\n",
    "        create_folder(output_dir)  ## on crée un folder ou stocker le modele \n",
    "        \n",
    "        tr_loss, temp_loss = [], []\n",
    "        precision, temp_precision = [], []\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        cnt= 0\n",
    "        start = time.time()\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        for step, batch in enumerate(loader):\n",
    "\n",
    "            cnt +=1\n",
    "                \n",
    "            batch = tuple(t.to(train_params['device']) for t in batch)\n",
    "            \n",
    "            if config.age_in_inputs:\n",
    "                input_ids, mod_ids, del_ids, segment_ids, posi_ids, attMask, masked_label = batch\n",
    "                age_ids = None\n",
    "        \n",
    "             #   age_ids = age_ids.to(train_params['device'])\n",
    "                \n",
    "            elif config.delays_in_inputs:\n",
    "                input_ids, mod_ids, segment_ids, posi_ids, attMask, masked_label = batch\n",
    "                age_ids = None\n",
    "              #  age_ids = age_ids.to(train_params['device'])\n",
    "                \n",
    "                del_ids = None\n",
    "               # del_ids = del_ids.to(train_params['device'])\n",
    "                \n",
    "            else:\n",
    "                input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids, attMask, masked_label = batch\n",
    "\n",
    "\n",
    "            loss, pred, label = model(input_ids=input_ids, modalities_ids=mod_ids, delays_ids=del_ids, seg_ids=segment_ids, posi_ids=posi_ids, attention_mask=attMask, masked_lm_labels=masked_label)\n",
    "\n",
    "            if config.gradient_accumulation_steps >1:\n",
    "                loss = loss/config.gradient_accumulation_steps\n",
    "\n",
    "            loss.backward()\n",
    "            temp_loss.append(loss.item())\n",
    "            tr_loss.append(loss.item())\n",
    "\n",
    "            nb_tr_examples += input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                with open(\"mydocument.txt\", mode = \"a\") as f:\n",
    "                    print(\"epoch: {}\\t| cnt: {}\\t|Loss: {}\\t| precision: {:.4f}\\t| time: {:.2f}\".format(e, cnt, np.mean(temp_loss), cal_acc(label, pred), time.time()-start))\n",
    "                    temp_loss = []\n",
    "                    start = time.time()\n",
    "\n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "\n",
    "        # print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        create_folder(file_config['model_path'])\n",
    "        \n",
    "        output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        \n",
    "        cost = time.time() - start\n",
    "\n",
    "        return np.mean(tr_loss), cost, cal_acc(label, pred), model_to_save\n",
    "    \n",
    "def evaluate_per_epoch(model, loader, config, train_params):\n",
    "    \n",
    "    temp_loss, val_loss = [], []\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    start = time.time()\n",
    " \n",
    "    model.eval()\n",
    "    \n",
    "    for step, batch in enumerate(loader):\n",
    "        \n",
    "        \n",
    "        batch = tuple(t.to(train_params['device']) for t in batch)\n",
    "\n",
    "        if config.age_in_inputs:\n",
    "            input_ids, mod_ids, del_ids, segment_ids, posi_ids, attMask, masked_label = batch\n",
    "            age_ids = None\n",
    "\n",
    "        elif config.delays_in_inputs:\n",
    "            input_ids, mod_ids, segment_ids, posi_ids, attMask, masked_label = batch\n",
    "            age_ids = None\n",
    "            del_ids = None\n",
    "\n",
    "        else:\n",
    "            input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids, attMask, masked_label = batch\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss, pred, label = model(input_ids = input_ids, modalities_ids = mod_ids, age_ids=age_ids,delays_ids=del_ids, seg_ids=segment_ids, posi_ids=posi_ids, attention_mask=attMask, masked_lm_labels=masked_label)\n",
    "            loss = loss.cpu()\n",
    "            val_loss.append(loss)\n",
    "            \n",
    "        temp_loss.append(loss)\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            print(\"Validation:\")\n",
    "            print(\"|Val Loss: {}\\t| Val precision: {:.4f}\\t| time: {:.2f}\".format(np.mean(temp_loss), cal_acc(label, pred), time.time()-start))\n",
    "            temp_loss = []\n",
    "            start = time.time() \n",
    "            \n",
    "    return cal_acc(label, pred), val_loss, np.mean(val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dea60-458e-461c-a345-b54fec481943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(config):\n",
    "    counter_dict, valid_counter_dict, embedding_dict, models_dict = dict(), dict(), dict(), dict()\n",
    "    temp_loss = 1\n",
    "    with wandb.init(config=config, project=\"MLM_final_run\") as run:\n",
    "        config = wandb.config\n",
    "        \n",
    "        for count in [0, 1, 2, 3, 'baseline', 'baseline_2']:\n",
    "\n",
    "             # Copy your config \n",
    "            run.name = f\"MLM_final_run_{count}\"\n",
    "            \n",
    "            if isinstance(count, int):\n",
    "                seed = count\n",
    "            else:\n",
    "                seed = random.randrange(0, 100)\n",
    "\n",
    "            results_dict = {'epochs': range(config.epochs), 'loss': [] , 'precision':[]}\n",
    "            valid_results_dict = {'epochs': range(config.epochs), 'loss': [] , 'precision':[]}\n",
    "\n",
    "\n",
    "            if count in ['baseline', 'baseline_2']:\n",
    "                train_loader = load_data(train, config, seed=seed, baseline=True)\n",
    "                valid_loader = load_data(valid, config, seed=seed, baseline= True)\n",
    "            else: \n",
    "                train_loader = load_data(train, config, seed=seed)\n",
    "                valid_loader = load_data(valid, config, seed=seed)\n",
    "\n",
    "            temp_prec, val_temp_prec = [], []\n",
    "\n",
    "            model, optim = define_model(config)\n",
    "\n",
    "            for epoch in range(config.epochs):\n",
    "                loss, time_cost, precision, model_to_save = training_per_epoch(e=epoch, loader=train_loader, model=model, optim=optim, config=config, train_params= train_params)\n",
    "                val_precision, val_loss_tot, val_loss = evaluate_per_epoch(model= model, loader = valid_loader, config= config, train_params=train_params)\n",
    "\n",
    "                results_dict['loss'].append(loss)\n",
    "                results_dict['precision'].append(precision)\n",
    "\n",
    "                valid_results_dict['loss'].append(val_loss)\n",
    "                valid_results_dict['precision'].append(val_precision)\n",
    "\n",
    "                if epoch >= config.epochs - 20:\n",
    "                    temp_prec.append(precision)\n",
    "                    val_temp_prec.append(val_precision)\n",
    "\n",
    "\n",
    "                wandb.log({\"epoch\" : epoch,\n",
    "                           \"prec\": precision,\n",
    "                            \"loss\" : loss,\n",
    "                           \"val_prec\" : val_precision,\n",
    "                           \"val_loss\": val_loss})\n",
    "\n",
    "            torch.save(model_to_save, f\"MLM_model_{count}_{run.id}\")\n",
    "\n",
    "            wandb.log({\"20_last_prec\": np.mean(temp_prec),\n",
    "                \"20_val_last_prec\": np.mean(val_temp_prec)})\n",
    "            \n",
    "            if epoch%5 == 0:\n",
    "       #     temp_f1, temp_auc, temp_aps, temp_recall, temp_precision, temp_loss, temp_time, tem_hidden_states, temp_masks = evaluating(model, config, testload, global_params, mlb)\n",
    "                if temp_loss > loss: \n",
    "          #      wandb.alert(title= \"Temp auc is high\", text=f\"Temp auc is : {temp_auc}\")\n",
    "                    torch.save(model_to_save, f'BEHRT/Early_integration/Outs_bis/pretrained_for_{count}_{temp_loss}')\n",
    "                    temp_loss = loss  \n",
    "                    wandb.log({'temp_loss': temp_loss, 'temp_epoch':epoch})\n",
    "                    \n",
    "\n",
    "\n",
    "        #    if (np.mean(temp_prec) >= 0.5) | (np.mean(val_temp_prec) >=0.5):\n",
    "            hf._dump_pkl(results_dict, f\"BEHRT/Early_integration/Outs/results_dict_{count}_{run.id}\")\n",
    "            hf._dump_pkl(valid_results_dict, f\"BEHRT/Early_integration/Outs/valid_results_dict_{count}_{run.id}\")\n",
    "\n",
    "\n",
    "            wandb.alert(\n",
    "                title=f\"Terminate run\", \n",
    "                text=f\"Run finished with val : {val_precision}\",\n",
    "                )\n",
    "\n",
    "            counter_dict[count] = results_dict\n",
    "            valid_counter_dict[count] = valid_results_dict\n",
    "            embedding_dict[count] = model_to_save.state_dict()['bert.embeddings.word_embeddings.weight'].cpu()  \n",
    "            models_dict[count] = model_to_save\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "    return counter_dict, valid_counter_dict, embedding_dict, models_dict\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544af680-1bd3-491a-ba40-bf0e1e7062c3",
   "metadata": {},
   "source": [
    "##### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6c035-c1bd-49b9-be4e-da81a1d8ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    print(\"Running Masked Language Model\")  \n",
    "    print(\"*\"*15+\" Run n° \"+str(1)+\" \"+\"*\"*15)\n",
    "    print()\n",
    "    \n",
    "    start = time.time()   \n",
    "    \n",
    "   # training(config = config)\n",
    "    counter_dict, valid_counter_dict, embedding_dict, models_dict = training(config = config)\n",
    "    \n",
    "    print()\n",
    "    print('Elapsed time for sweep hyperparameters tuning = {}\"'.format(time.time() - start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dceed1a6-2972-4981-9b0e-60afa5829caa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been saved in pkl format in /home/jovyan/work/Workdir/Secondment_1/Secondment 1/tasks/Early integration/BEHRT Final version\n",
      "The file has been saved in pkl format in /home/jovyan/work/Workdir/Secondment_1/Secondment 1/tasks/Early integration/BEHRT Final version\n"
     ]
    }
   ],
   "source": [
    "hf._dump_pkl(counter_dict, 'BEHRT/Early_integration/Tasks/Output/counter_dict_completed_3')\n",
    "hf._dump_pkl(valid_counter_dict, 'BEHRT/Early_integration/Tasks/Output/valid_counter_dict_completed_3')\n",
    "hf._dump_pkl(embedding_dict, 'BEHRT/Early_integration/Tasks/Output/embedding_dict_completed_3')\n",
    "hf._dump_pkl(models_dict, 'Model_pretraineds_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814aefd-a4c9-4787-9dbf-d8a42bac3410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
