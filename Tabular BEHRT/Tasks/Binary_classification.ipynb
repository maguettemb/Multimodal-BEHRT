{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78498f0b-e7b4-4fbe-9e40-827fdf2025eb",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a24a8dd-3d4b-47fd-b884-6924e46f061a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 14:47:06.774350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('BEHRT/Early_integration/')\n",
    "sys.path.append('BEHRT/')\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_pretrained_bert as Bert\n",
    "import sklearn\n",
    "\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import tune\n",
    "\n",
    "from Utils import optimiser\n",
    "from Utils.common import create_folder\n",
    "import sklearn.metrics as skm\n",
    "import math\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from Utils.utils import age_vocab, input_vocab, mod_vocab, delay_vocab\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from Utils.dataLoader_utils import ImbSampler, OverSampler, StratifiedSampler\n",
    "from Utils.NextXVisit_v2 import NextVisit\n",
    "from Models.BertForClassification import BertForClassification\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#### ## ROC \n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "## Plot results\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from Utils.add_endpoints import add_endp\n",
    "from Utils.handle_file import handle_file\n",
    "\n",
    "hf = handle_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd337188-4d02-4014-9ca2-7ac4c670566c",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89488d8a-aee0-4ef7-8876-b078312f00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_valid_idx(dataset):\n",
    "    patient_idx = dataset.index\n",
    "    \n",
    "    train_idx = hf._load_pkl(file_config['train_idx'])\n",
    "    train_idx = [idx for idx in train_idx if idx in patient_idx]\n",
    "\n",
    "    test_idx = hf._load_pkl(file_config['test_idx'])\n",
    "    test_idx = [idx for idx in test_idx if idx in patient_idx]\n",
    "\n",
    "    valid_idx = hf._load_pkl(file_config['valid_idx'])\n",
    "    valid_idx = [idx for idx in valid_idx if idx in patient_idx]\n",
    "    \n",
    "    return train_idx, test_idx, valid_idx\n",
    "\n",
    "def split_data(dataset):\n",
    "    train_idx, test_idx, valid_idx = get_train_test_valid_idx(dataset)\n",
    "    \n",
    "    \n",
    "    train = dataset.loc[train_idx ,:]\n",
    "    valid = dataset.loc[valid_idx ,:]\n",
    "    test = dataset.loc[test_idx ,:]\n",
    "\n",
    "    train = train.rename_axis('patid')\n",
    "    valid = valid.rename_axis('patid')\n",
    "    test = test.rename_axis('patid')\n",
    "\n",
    "    train.reset_index(inplace=True)\n",
    "    valid.reset_index(inplace=True)\n",
    "    test.reset_index(inplace=True)\n",
    "\n",
    "    train['patid'] = train['patid'].replace(train.patid.values,range(len(train.patid.values)))\n",
    "    valid['patid'] = valid['patid'].replace(valid.patid.values,range(len(valid.patid.values)))\n",
    "    test['patid'] = test['patid'].replace(test.patid.values,range(len(test.patid.values)))\n",
    "\n",
    "    return train, test, valid \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e82e60-8092-4381-b351-af72bde3905b",
   "metadata": {},
   "source": [
    "#### Performing checks for the resources available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff028d4d-d7da-48d4-81f4-33f8e04ecb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a gpu available \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are %d GPU(s) available. \" %torch.cuda.device_count())\n",
    "    print(\"We will use the GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
    "    \n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "\"\"\" Empty the cache to enable the use of the gpu \"\"\"\n",
    "\n",
    "def empty_cuda():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a691f96-f00a-4748-9f42-2cb9d22a8033",
   "metadata": {},
   "source": [
    "#### Run Binary Classification \n",
    "1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5adc5959-e763-4719-8d36-25c616420c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embeddings used for the classification \n",
    "\n",
    "pretrain_model_path =  'BEHRT/Early_integration/Tasks/Output/MLM_mean.pkl'   # pretrained MLM path\n",
    "\n",
    "file_config = { 'data':'BEHRT/Early_integration/Files/data_preprocessed_in_512_chunks_notherap_100.pkl',\n",
    "                'labels' : 'BEHRT/Late_integration/Files/relapses.csv', \n",
    "                'train_idx' : 'BEHRT/Late_integration/Files/train_ids.pkl',\n",
    "                'valid_idx' : 'BEHRT/Late_integration/Files/valid_ids.pkl',\n",
    "                'test_idx' : 'BEHRT/Late_integration/Files/test_ids.pkl', \n",
    "                }\n",
    "\n",
    "optim_config = {\n",
    "    'lr': 5e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}\n",
    "\n",
    "global_params = {\n",
    "    'batch_size': 32,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'device': device ,\n",
    "    'output_dir': 'BEHRT/Early_integration/Tasks/Output', # output folder\n",
    "    'best_name': 'CLF_model',  # output model name\n",
    "    'max_len_seq': 512, #100,\n",
    "    'max_age': 110,\n",
    "    'max_delay': 30, ## = 30years\n",
    "    'age_month': 12,\n",
    "    'delay_month': 0.25,\n",
    "    'age_year': False,\n",
    "    'age_symbol': None,\n",
    "    'min_visit': 2,\n",
    "}\n",
    "\n",
    "feature_dict = {\n",
    "            'word':True,\n",
    "            'seg':True,\n",
    "            'age':True,\n",
    "            'modalities': True,\n",
    "            'delays': True,\n",
    "            'position': True\n",
    "                }\n",
    "\n",
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embedding'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.delays_vocab_size = config.get('delays_vocab_size')\n",
    "        self.modalities_vocab_size = config.get('modalities_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.output_attentions = config.get('output_attentions')\n",
    "        self.chunk_size_feed_forward = config.get('chunk_size_feed_forward')\n",
    "        self.is_decoder = config.get('is_decoder')\n",
    "        self.layer_norm_eps = config.get('layer_norm_eps')\n",
    "        self.add_cross_attention = config.get('add_cross_attention')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294488fe-1f32-4538-9bfc-759d10af5a9a",
   "metadata": {},
   "source": [
    "2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4155f7bd-c876-45c7-a8ec-037820362032",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/Users/maguette/opt/anaconda3/lib/python3.7/site-packages/pandas/_libs/internals.cpython-37m-darwin.so'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b1/jf_78yv56k71f696t4mbm2jw0000gn/T/ipykernel_4976/537303923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Import train data \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\"\"\"Import labels \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Cluster/BEHRT/Early_integration/Utils/handle_file.py\u001b[0m in \u001b[0;36m_load_pkl\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/Users/maguette/opt/anaconda3/lib/python3.7/site-packages/pandas/_libs/internals.cpython-37m-darwin.so'>"
     ]
    }
   ],
   "source": [
    "\"\"\"Import train data \"\"\"\n",
    "data =  hf._load_pkl(file_config['data'])\n",
    "\n",
    "\n",
    "\"\"\"Import labels \"\"\"\n",
    "labels = hf._load_csv(file_config['labels'])\n",
    "labels.drop(['Unnamed: 0', 'status_drfs_5y'], axis='columns', inplace = True)\n",
    "labels.rename(columns={'status_rfs_surg_5y': 'label'}, inplace=True)\n",
    "\n",
    "\"\"\"Merge label and data \"\"\"\n",
    "data = pd.merge(data, labels, on=['Num_dossier'])\n",
    "data.set_index('Num_dossier', inplace=True)\n",
    "\n",
    "# Display 3 first rows\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78566f80-bdd7-4676-8526-ea41e4f81076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove patients with visits less than min visit\n",
    "previous_shape = data.shape[0]\n",
    "\n",
    "data['length'] = data['inputs_quantiles_preprocessed_100_therap_removed_tolist'].apply(lambda x: len([i for i in range(len(x)) if x[i] == 'SEP']))\n",
    "data = data[data['length'] >= global_params['min_visit']]\n",
    "#data = data.reset_index(drop=True)\n",
    "\n",
    "print(\"We lost {} patient\".format(previous_shape - data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea25fbf-a06e-48be-91fd-95154426e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_seq = hf._load_pkl('/home/jovyan/work/Workdir/Secondment_1/Secondment 1/tasks/Early integration/BEHRT Final version/whole_seq_preprocessed.pkl')\n",
    "\n",
    "tokenVocab, _ = input_vocab(inputs = data.inputs_normal_range_preprocessed_100_therap_removed, symbol=global_params['age_symbol'])\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], mon = global_params['age_month'], symbol=global_params['age_symbol'])\n",
    "modalitiesVocab, _ = mod_vocab(data.modalities_100_therap_removed, symbol=global_params['age_symbol'])\n",
    "delayVocab, _ = delay_vocab(max_delay=global_params['max_delay'], mon = global_params['delay_month'], symbol=global_params['age_symbol'])\n",
    "\n",
    "# Binary classification \n",
    "labelVocab = {0:0, 1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8555749-2489-4391-8d79-e49d95cead84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'vocab_size': len(tokenVocab), # number of disease + symbols for word embedding\n",
    "    'hidden_size': 288, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'modalities_vocab_size': len(modalitiesVocab), \n",
    "    'age_vocab_size': len(ageVocab), # number of vocab for age embedding\n",
    "    'delays_vocab_size': len(delayVocab), \n",
    "    'max_position_embedding':global_params['max_len_seq'],  # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.3, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 12, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.2, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "    'chunk_size_feed_forward' : 0,\n",
    "    'use_return_dict': True,\n",
    "    'output_attentions': True,\n",
    "    'output_hidden_states':True,\n",
    "    'is_decoder': False,\n",
    "    'layer_norm_eps' : 1e-12,  #1e-5\n",
    "    'add_cross_attention' : False\n",
    "}\n",
    "\n",
    "feature_dict = {\n",
    "    'word':True,\n",
    "    'seg':True,\n",
    "    'age':True,\n",
    "    'modalities': True,\n",
    "    'delays': True,\n",
    "    'position': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4740134a-9c2e-46b3-90f8-5ac1679fe422",
   "metadata": {},
   "source": [
    "3. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b491ef3-6c1c-4e33-861e-316113f5db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, valid = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9ce80-339f-429e-ac8d-78ceb6e3112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda:0' else {'num_workers': 5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32f20a3c-dd46-448b-ad4b-560d8c5fc5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['inputs_curve_intersections_preprocessed_100_therap_removed_tolist']\n",
    "y_train = train['label']\n",
    "\n",
    "Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=train, max_len=global_params['max_len_seq'],  code='inputs_curve_intersections_preprocessed_100_therap_removed_tolist', delay ='delays_100_therap_removed_into_chunks_tolist'\n",
    "                              , age = \"age_100_therap_removed_into_chunks_tolist\", mod='modalities_100_therap_removed_into_chunks_tolist' )\n",
    "hp_generator = {'batch_size': global_params['batch_size'], 'balanced': 'balanced', 'shuffle':True}\n",
    "trainload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  sampler = StratifiedSampler(X_train, y_train, batch_size=global_params['batch_size']) , **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d60f4a-2d04-446e-bb91-70d9cb0cec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=valid, max_len=global_params['max_len_seq'],  code='inputs_curve_intersections_preprocessed_100_therap_removed_tolist', delay ='delays_100_therap_removed_into_chunks_tolist'\n",
    "                              , age = \"age_100_therap_removed_into_chunks_tolist\", mod='modalities_100_therap_removed_into_chunks_tolist' )\n",
    "validload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  shuffle = True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5045c-9b2c-4d6f-9378-267b39351135",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=test, max_len=global_params['max_len_seq'], code='inputs_curve_intersections_preprocessed_100_therap_removed_tolist', delay ='delays_100_therap_removed_into_chunks_tolist'\n",
    "                              , age = \"age_100_therap_removed_into_chunks_tolist\", mod='modalities_100_therap_removed_into_chunks_tolist' )\n",
    "testload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  shuffle = False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ed32d-08af-404b-8c4b-7735a076dbfa",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d467b-5f86-4d26-b739-0ff3799ac042",
   "metadata": {},
   "source": [
    "1. Model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54f911d-c46d-48db-829a-a06113bc316f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(path, model):\n",
    "    # load pretrained model and update weights\n",
    "    pretrained_dict = torch.load(path)\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    \n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    \n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c5654-01b7-478a-bce7-77e80da53b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(model_config):\n",
    "    # del model\n",
    "    \n",
    "    class_weights = torch.tensor(config['class_weights'])\n",
    "    conf = BertConfig(model_config)\n",
    "    model = BertForClassification(conf, num_labels=len(labelVocab.keys()), feature_dict=feature_dict, class_weights = class_weights)\n",
    "    model = load_model(pretrain_model_path, model)                          \n",
    "    model = model.to(global_params['device'])\n",
    "    optim = optimiser.adam(params=list(model.named_parameters()), config=model_config)\n",
    "    \n",
    "    return model, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac5f34-2937-4ea6-81e0-afdf1aeedd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=list(labelVocab.values()))\n",
    "mlb.fit([[each] for each in list(labelVocab.values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e32dac-2b8e-40a4-87a5-e3d4ec25ea90",
   "metadata": {},
   "source": [
    "2. Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8ef24-42d6-45dc-a879-e20328d6aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_for_train(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output = sig(logits)\n",
    "    label, output = label.cpu(), output.detach().cpu()\n",
    "    label = np.argmax(label, axis=1)\n",
    "    output = np.argmax(output, axis=1)\n",
    "    \n",
    "    f1 =  sklearn.metrics.f1_score(label.numpy(), output.numpy(), average=\"macro\")\n",
    "    \n",
    "    return f1, output, label\n",
    "\n",
    "def scoring_for_valid(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output = sig(logits)\n",
    "    label = np.argmax(label, axis=1)\n",
    "    output = np.argmax(output, axis=1)  \n",
    "    \n",
    "    f1 =  sklearn.metrics.f1_score(label.numpy(), output.numpy(), average=\"macro\")\n",
    "    roc = sklearn.metrics.roc_auc_score(label.numpy(),output.numpy(), average='samples')\n",
    "\n",
    "    return f1, roc, output, label\n",
    "\n",
    "def scoring_for_test(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output = sig(logits)\n",
    "    label = np.argmax(label, axis=1)\n",
    "    output = np.argmax(output, axis=1)\n",
    "    \n",
    "    roc = sklearn.metrics.roc_auc_score(label.numpy(),output.numpy(), average='samples')\n",
    "    f1 =  sklearn.metrics.f1_score(label.numpy(), output.numpy(), average=\"macro\")\n",
    "    recall = sklearn.metrics.recall_score(label.numpy(), output.numpy(), average=\"macro\")\n",
    "    precision = sklearn.metrics.precision_score(label.numpy(), output.numpy(), average=\"macro\")\n",
    " \n",
    "    return f1, roc, recall, precision, output, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef59cb-b33b-4867-9da4-f4285ed91dde",
   "metadata": {},
   "source": [
    "3. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217f36d-4dfb-430f-9c7d-08a5eaaa49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9f06d-10e8-471d-b99e-2d6117ef8abf",
   "metadata": {},
   "source": [
    "4. Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "429e6394-9904-4c6e-b9d9-ec2c755c823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stats = []\n",
    "       \n",
    "def training(e, train_dataloader, valid_dataloader):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Reset the loss at each epoch\n",
    "    temp_loss, temp_f1 = [], []\n",
    "    train_f1, train_loss = [], []\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt = 0\n",
    "    count = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        cnt +=1\n",
    "        age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
    "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "    \n",
    "        ## Load batch to gpu \n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        mod_ids = mod_ids.to(global_params['device'])\n",
    "        del_ids = del_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "        \n",
    "        \n",
    "        ## Compute output (loss, logits and attentions scores) \n",
    "        output = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets, output_attentions = True)\n",
    "  \n",
    "        loss = output.loss\n",
    "        logits  = output.logits\n",
    "        attentions = output.attentions\n",
    "        \n",
    "        if global_params['gradient_accumulation_steps'] >1:\n",
    "            loss = loss/global_params['gradient_accumulation_steps']\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        temp_loss.append(loss.item())\n",
    "        train_loss.append(loss.item())\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        f1, a, b = scoring_for_train(logits, targets)\n",
    "       \n",
    "        temp_f1.append(f1)\n",
    "   \n",
    "        # Progress update every 500 batches\n",
    "        if step % 40 == 0:\n",
    "            print(\"epoch: {}\\t| Cnt: {}\\t| Loss: {}\\t| f1 score: {}\".format(e, cnt, np.mean(temp_loss), np.mean(temp_f1)))\n",
    "            temp_loss, temp_f1 = [], []\n",
    "             \n",
    "        \n",
    "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
    "  \n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            \n",
    "        train_f1.append(f1)\n",
    "        count+=1\n",
    " \n",
    "\n",
    "        \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - start)\n",
    "                   \n",
    "    print(\"\")\n",
    "    print(\"Average training loss: {0:.2f}\".format(np.mean(train_loss)))\n",
    "    print(\"Average training score: {0:.2f}\".format(np.mean(train_f1)))\n",
    "    print(\"Training epoch took: {:}\".format(training_time))\n",
    "    \n",
    "          \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    valid_f1, valid_roc, valid_loss, valid_time = evaluation(valid_dataloader)\n",
    "    \n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append({'epoch': e+1, \n",
    "                               'Training Loss': np.mean(train_loss) ,\n",
    "                               'Training Time' : training_time,\n",
    "                               'Average Train f1 score' : np.mean(train_f1),\n",
    "                               'Validation Loss': np.mean(valid_loss), \n",
    "                               'Validating Time' : valid_time, \n",
    "                               'Average Valid f1 score' : np.mean(valid_f1),\n",
    "                               'Average Valid ROC' : np.mean(valid_roc)\n",
    "                                })  \n",
    "        \n",
    "    return valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats\n",
    "    \n",
    "\n",
    "def evaluation(data):\n",
    "                               \n",
    "    start = time.time()\n",
    "                               \n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    val_loss, total_f1, total_roc = [], [], []\n",
    "    val_loss_tot, tot_f1, tot_roc = [], [], []\n",
    "    \n",
    "    for step, batch in enumerate(data):\n",
    "        \n",
    "        age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
    "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "     \n",
    "        \n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        mod_ids = mod_ids.to(global_params['device'])\n",
    "        del_ids = del_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "      \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets, output_attentions=True)\n",
    "        \n",
    "        val_loss.append(outputs.loss.item())\n",
    "        \n",
    "        logits = outputs.logits.cpu()\n",
    "        targets = targets.cpu()\n",
    "        \n",
    "        y_label.append(targets)\n",
    "        y.append(logits)\n",
    "        \n",
    "\n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0) \n",
    "    \n",
    "    tot_f1, tot_roc, output, label = precision_valid(y, y_label)\n",
    "   \n",
    "    # Measure how long this epoch took.\n",
    "    validation_time = format_time(time.time() - start)\n",
    "    \n",
    "    print(\"Validation Loss: {0:.2f}\".format(np.mean(val_loss)))\n",
    "    print(\"Validation took: {:}\".format(validation_time))\n",
    "    print()\n",
    "    \n",
    "    #output_path = 'BEHRT/Early_integration/Tasks/Output/binary_clf'\n",
    "    #os.makedirs(output_path, exist_ok=True)\n",
    "    #torch.save(model.state_dict(), optim.state_dict()), output_path+'/checkpoint.pt')\n",
    "    #session.report({'loss':np.mean(val_loss), 'f1_score':np.mean(tot_f1)}, checkpoint=checkpoint)\n",
    "    \n",
    "    return tot_f1, tot_roc, val_loss, validation_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b76f5e0b-f4a4-4dbb-978b-194f56d42bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_BEHRT(config, epochs=range(2), inputs='inputs_quantiles_preprocessed_100_therap_removed_tolist', age = \"age_100_therap_removed_into_chunks_tolist\", \n",
    "         modalities = 'modalities_100_therap_removed_into_chunks_tolist', delay ='delays_100_therap_removed_into_chunks_tolist'):\n",
    "    \n",
    "    set_seed()\n",
    "    train_skf = pd.concat([train, valid])\n",
    "    X_train_skf = train_skf['inputs_quantiles_preprocessed_100_therap_removed_tolist']\n",
    "    y_train_skf = train_skf['label']\n",
    "    \n",
    "    n = 5\n",
    "    skf = StratifiedKFold(n_splits = n)\n",
    "    \n",
    "    \n",
    "    for i, (train_idx, cross_val_idx) in enumerate(skf.split(X_train_skf, y_train_skf)):\n",
    "        train_df = train_skf.iloc[train_idx]\n",
    "        train_df.index = range(train_df.shape[0])\n",
    "        train_df.patid = range(train_df.shape[0])\n",
    "        \n",
    "        cv_df = train_skf.iloc[cross_val_idx]\n",
    "        cv_df.index = range(cv_df.shape[0])\n",
    "        cv_df.patid = range(cv_df.shape[0])\n",
    "        \n",
    "        ## Load train and valid data \n",
    "        \n",
    "        X_tr = train_df[inputs]\n",
    "        y_tr = train_df['label']\n",
    "        \n",
    "        Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=train_df, max_len=global_params['max_len_seq'], code= inputs, delay = delay, age = age, mod=modalities)\n",
    "        hp_generator = {'batch_size': config['batch_size'], 'balanced': 'balanced', 'shuffle':True}\n",
    "        train_data = DataLoader(dataset=Dset, batch_size=config['batch_size'],  sampler = StratifiedSampler(X_tr, y_tr, batch_size=config['batch_size']) , **kwargs)\n",
    "        \n",
    "        Dset = NextVisit(token2idx = tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=cv_df, max_len=global_params['max_len_seq'], code= inputs, delay = delay, age = age, mod=modalities)\n",
    "        valid_data = DataLoader(dataset = Dset, batch_size=config['batch_size'],  shuffle = True, **kwargs)\n",
    "        \n",
    "        model, optimizer = define_model(config)\n",
    "        model.to(global_params['device'])\n",
    "         \n",
    "    ## To restore checkpoint, use 'checkpoint.get_checkpoint()'\n",
    "        loaded_checkpoint = session.get_checkpoint()\n",
    "        if loaded_checkpoint:\n",
    "            with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "                model_state, optimizer_state = torch.load(os.pathe.join(loaded_checkpoint_dir, \"checkpoint_test.pt\"))\n",
    "            \n",
    "        model.load_state_dict(model_state)\n",
    "        optim.load_state_dict(optimizer_state)\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats = training(e, train_data, valid_data)\n",
    "            mean_f1 = np.mean(valid_f1)\n",
    "            \n",
    "            if mean_f1 > best_pre:\n",
    "                ## Save a trained model \n",
    "                model_to_save = model.module if hasattr(model, 'module') else model\n",
    "                output_module_file = os.path.join(global_params['output_dir'])\n",
    "                create_folder(global_params['output_dir'])\n",
    "                torch.save(model_to_save.state_dict(), output_model_file)\n",
    "                best_pre = mean_f1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db18ce-52a2-45f2-84ea-e0e1179166c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_BEHRT(best_result, inputs='inputs_curve_intersections_preprocessed_100_therap_removed_tolist', age= \"age_100_therap_removed_into_chunks_tolist\",\n",
    "              delay='delays_100_therap_removed_into_chunks_tolist', mod = 'modalities_100_therap_removed_into_chunks_tolist'):\n",
    "    \n",
    "    Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=test, max_len=global_params['max_len_seq'],\n",
    "                     code = inputs, delay = delay, age = age, mod=mod )\n",
    "    testload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  shuffle = False, **kwargs)\n",
    "\n",
    "    model = define_model(best_result)\n",
    "    model.to(global_params['device'])\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), 'checkpoint_test.pt')\n",
    "    \n",
    "    model_state, optimizer_state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(model_state)\n",
    "    \n",
    "    y, y_label = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(testload):\n",
    "            model.eval()\n",
    "\n",
    "            age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
    "            targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "\n",
    "            age_ids = age_ids.to(global_params['device'])\n",
    "            mod_ids = mod_ids.to(global_params['device'])\n",
    "            del_ids = del_ids.to(global_params['device'])\n",
    "            input_ids = input_ids.to(global_params['device'])\n",
    "            posi_ids = posi_ids.to(global_params['device'])\n",
    "            segment_ids = segment_ids.to(global_params['device'])\n",
    "            attMask = attMask.to(global_params['device'])\n",
    "            targets = targets.to(global_params['device'])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets, output_attentions=True)\n",
    "\n",
    "            logits = outputs.logits.cpu()\n",
    "            targets = targets.cpu()\n",
    "\n",
    "            y_label.append(targets)\n",
    "            y.append(logits)\n",
    "\n",
    "     \n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "  \n",
    "     # Compute ROC curve and ROC area for each class\n",
    "    f1, roc, recall, precision, output, label, = precision_test(y, y_label)\n",
    "    \n",
    "    print(\"Best trial test set scores: f1: {}, roc: {}, recall: {} and precision: {}.\".format(f1, roc, recall, precision))\n",
    "    \n",
    "    return y, y_label\n",
    "    \n",
    "def plot_test(model, test_data):\n",
    "    y, y_label = test_BEHRT(model, test_data)\n",
    "    label = np.argmax(y_label, axis=1)\n",
    "    \n",
    "    sig = nn.Sigmoid()\n",
    "    output = sig(y)\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(label, output[:,1])\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "   \n",
    "    ## Plot ##  \n",
    "    target_names = ['Non relapse', 'Relapse']\n",
    "\n",
    "    print(\"f1 score is {:.4f}, Precision is {:.4f}, Recall is {:.4f}\".format(f1, precision, recall))\n",
    "    print(classification_report(label, np.argmax(output, axis=1), target_names=target_names))\n",
    "    cm(label, np.argmax(output, axis=1), 'cm')\n",
    "    plot_roc_auc(fpr, tpr, roc_auc)\n",
    "    \n",
    "    return y_label, y, fpr, tpr, roc_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "081b3909-818a-4df8-a3ba-9fc0ca99fbf5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b1/jf_78yv56k71f696t4mbm2jw0000gn/T/ipykernel_4976/2844594431.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLIReporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedulers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mASHAScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    \n",
    "    balanced_cw = sklearn.utils.compute_class_weight(class_weight = 'balanced', classes = np.unique(data.label), y = data.label)\n",
    "\n",
    "    balanced_cw = dict(zip(np.unique(data.label), balanced_cw))\n",
    "\n",
    "    model_config = {\n",
    "    'batch_size': tune.choice([8, 16, 32, 64]),\n",
    "    'class_weights': tune.choice([balanced_cw, np.array([1, 25]), np.array([1, 35]), np.array([1, 50])]),\n",
    "    'vocab_size': len(tokenVocab), # number of disease + symbols for word embedding\n",
    "    'hidden_size': 288, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'modalities_vocab_size': len(modalitiesVocab), \n",
    "    'age_vocab_size': len(ageVocab), # number of vocab for age embedding\n",
    "    'delays_vocab_size': len(delayVocab), \n",
    "    'max_position_embedding':global_params['max_len_seq'],  # maximum number of tokens\n",
    "    'hidden_dropout_prob': tune.uniform(0,0.9), # dropout rate\n",
    "    'num_hidden_layers': tune.choice([3, 6, 12]), # number of multi-head attention layers required\n",
    "    'num_attention_heads': tune.choice([3, 6, 12, 24]), # number of attention heads\n",
    "    'attention_probs_dropout_prob': tune.uniform(0, 0.9), # multi-head attention dropout rate\n",
    "    'intermediate_size': tune.choice([256, 512, 768]), # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': tune.choice(['gelu','relu', 'swish']), # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': tune.choice([0.01, 0.02]), # parameter weight initializer range\n",
    "    'chunk_size_feed_forward' : 0,\n",
    "    'use_return_dict': True,\n",
    "    'output_attentions': True,\n",
    "    'output_hidden_states':True,\n",
    "    'is_decoder': False,\n",
    "    'layer_norm_eps' : tune.choice([1e-12,  1e-5]),\n",
    "    'add_cross_attention' : False,\n",
    "    'lr': tune.choice([1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3]),\n",
    "    'warmup_proportion': tune.uniform(0.1, 0.5),\n",
    "    'weight_decay': tune.choice([0.005, 0.01, 0.05, 0.1, 0.5])\n",
    "\n",
    "}\n",
    "    scheduler = ASHAScheduler(max_t = max_num_epochs, grace_period=1, reduction_factor=2)\n",
    "    \n",
    "    tuner = tune.Tuner(tune.with_resources(tune.with_parameters(train_BEHRT), \n",
    "                                          resources = {'cpu':3, \"gpu\": gpus_per_trial}),\n",
    "                       \n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "        ),\n",
    "                      param_space = model_config,\n",
    "                      )\n",
    "    \n",
    "    results = tuner.fit()\n",
    "    best_results = results.get_best_results(\"f1\", \"max\")\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"loss\"]))\n",
    "    print(\"Best trial final validation f1 score: {}\".format(best_result.metrics[\"f1\"]))\n",
    "    \n",
    "    test_BEHRT(best_result)\n",
    "    \n",
    "main(num_samples=2, max_num_epochs=2, gpus_per_trial=0)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0f8f2-54c3-44c0-b119-d9185898c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training with best config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529ce6e-2f76-4315-a4fa-683cca69709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = best_result.config\n",
    "hf._dump_pkl(best_config, 'best_config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b06887ce-2df1-4e89-880b-8e69fbfd4b46",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating Inputs for fold 0\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| Cnt: 1\t| Loss: 0.1737854778766632\t| f1 score: 0.5844155844155844\n",
      "epoch: 0\t| Cnt: 41\t| Loss: 0.15901452172547578\t| f1 score: 0.6177494428544216\n",
      "epoch: 0\t| Cnt: 81\t| Loss: 0.11556752566248178\t| f1 score: 0.7947555179884922\n",
      "epoch: 0\t| Cnt: 121\t| Loss: 0.11486855605617166\t| f1 score: 0.7910052163360064\n",
      "epoch: 0\t| Cnt: 161\t| Loss: 0.1013754797168076\t| f1 score: 0.8284525325452066\n",
      "epoch: 0\t| Cnt: 201\t| Loss: 0.10122865634039044\t| f1 score: 0.8372725148053333\n",
      "epoch: 0\t| Cnt: 241\t| Loss: 0.08832060117274523\t| f1 score: 0.8564316148687878\n",
      "\n",
      "Average training loss: 0.11\n",
      "Average training score: 0.80\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.30\n",
      "Validation took: 0:00:16\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.6556818181818181\n",
      "\n",
      "epoch: 1\t| Cnt: 1\t| Loss: 0.06098473072052002\t| f1 score: 0.9372549019607843\n",
      "epoch: 1\t| Cnt: 41\t| Loss: 0.07418443919159472\t| f1 score: 0.8869125171574993\n",
      "epoch: 1\t| Cnt: 81\t| Loss: 0.07386575150303543\t| f1 score: 0.8846724294068565\n",
      "epoch: 1\t| Cnt: 121\t| Loss: 0.06334008174017072\t| f1 score: 0.9049157323368252\n",
      "epoch: 1\t| Cnt: 161\t| Loss: 0.07049072296358645\t| f1 score: 0.8928876076960549\n",
      "epoch: 1\t| Cnt: 201\t| Loss: 0.06817240882664918\t| f1 score: 0.8898673703971667\n",
      "epoch: 1\t| Cnt: 241\t| Loss: 0.0664209860842675\t| f1 score: 0.8952895764048598\n",
      "\n",
      "Average training loss: 0.07\n",
      "Average training score: 0.89\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.30\n",
      "Validation took: 0:00:16\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.6584553156303964\n",
      "\n",
      "epoch: 2\t| Cnt: 1\t| Loss: 0.05056744068861008\t| f1 score: 0.906158357771261\n",
      "epoch: 2\t| Cnt: 41\t| Loss: 0.047201320878230035\t| f1 score: 0.9300387770869272\n",
      "epoch: 2\t| Cnt: 81\t| Loss: 0.03907805907074362\t| f1 score: 0.945168096880273\n",
      "epoch: 2\t| Cnt: 121\t| Loss: 0.0447546886978671\t| f1 score: 0.9371434149082107\n",
      "epoch: 2\t| Cnt: 161\t| Loss: 0.043640522146597506\t| f1 score: 0.9388593115137315\n",
      "epoch: 2\t| Cnt: 201\t| Loss: 0.04149127730634063\t| f1 score: 0.9521463926750439\n",
      "epoch: 2\t| Cnt: 241\t| Loss: 0.046138294017873706\t| f1 score: 0.9340084357108175\n",
      "\n",
      "Average training loss: 0.04\n",
      "Average training score: 0.94\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.27\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.6887841549402048\n",
      "\n",
      "epoch: 3\t| Cnt: 1\t| Loss: 0.03751026839017868\t| f1 score: 0.906158357771261\n",
      "epoch: 3\t| Cnt: 41\t| Loss: 0.03807493806816638\t| f1 score: 0.9490189934722668\n",
      "epoch: 3\t| Cnt: 81\t| Loss: 0.03155179450986907\t| f1 score: 0.9616027295486909\n",
      "epoch: 3\t| Cnt: 121\t| Loss: 0.03712550919735804\t| f1 score: 0.9451310564717005\n",
      "epoch: 3\t| Cnt: 161\t| Loss: 0.03542033793637529\t| f1 score: 0.9521275793957656\n",
      "epoch: 3\t| Cnt: 201\t| Loss: 0.03470048118615523\t| f1 score: 0.9521954742813297\n",
      "epoch: 3\t| Cnt: 241\t| Loss: 0.03174283526604995\t| f1 score: 0.9544735118404393\n",
      "\n",
      "Average training loss: 0.03\n",
      "Average training score: 0.95\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.30\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.6738318471108554\n",
      "\n",
      "epoch: 4\t| Cnt: 1\t| Loss: 0.037710368633270264\t| f1 score: 0.9372549019607843\n",
      "epoch: 4\t| Cnt: 41\t| Loss: 0.03445082845864818\t| f1 score: 0.9482697118984784\n",
      "epoch: 4\t| Cnt: 81\t| Loss: 0.032819464313797654\t| f1 score: 0.955328328355814\n",
      "epoch: 4\t| Cnt: 121\t| Loss: 0.02467094254679978\t| f1 score: 0.9718367618308321\n",
      "epoch: 4\t| Cnt: 161\t| Loss: 0.021712886221939696\t| f1 score: 0.972598847823587\n",
      "epoch: 4\t| Cnt: 201\t| Loss: 0.024834045208990574\t| f1 score: 0.9702276954281224\n",
      "epoch: 4\t| Cnt: 241\t| Loss: 0.025918083399301396\t| f1 score: 0.9679021656316487\n",
      "\n",
      "Average training loss: 0.03\n",
      "Average training score: 0.96\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.13\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.8098157112738068\n",
      "\n",
      "epoch: 5\t| Cnt: 1\t| Loss: 0.010936887934803963\t| f1 score: 1.0\n",
      "epoch: 5\t| Cnt: 41\t| Loss: 0.02113882965641096\t| f1 score: 0.9718229615893279\n",
      "epoch: 5\t| Cnt: 81\t| Loss: 0.017273560317698868\t| f1 score: 0.9780760163302858\n",
      "epoch: 5\t| Cnt: 121\t| Loss: 0.017824013257632033\t| f1 score: 0.9741658392930436\n",
      "epoch: 5\t| Cnt: 161\t| Loss: 0.019950372370658442\t| f1 score: 0.9748982498036799\n",
      "epoch: 5\t| Cnt: 201\t| Loss: 0.01953466628328897\t| f1 score: 0.978092871312748\n",
      "epoch: 5\t| Cnt: 241\t| Loss: 0.01768150061252527\t| f1 score: 0.9780451618532944\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.13\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.8196428571428571\n",
      "\n",
      "epoch: 6\t| Cnt: 1\t| Loss: 0.011996705085039139\t| f1 score: 0.9687194525904204\n",
      "epoch: 6\t| Cnt: 41\t| Loss: 0.020209870685357602\t| f1 score: 0.9780882712322466\n",
      "epoch: 6\t| Cnt: 81\t| Loss: 0.02444001934491098\t| f1 score: 0.9702511707863447\n",
      "epoch: 6\t| Cnt: 121\t| Loss: 0.015777654462726786\t| f1 score: 0.9851232490164638\n",
      "epoch: 6\t| Cnt: 161\t| Loss: 0.020883691345807164\t| f1 score: 0.9764888072733392\n",
      "epoch: 6\t| Cnt: 201\t| Loss: 0.018866439152043314\t| f1 score: 0.9804358576275085\n",
      "epoch: 6\t| Cnt: 241\t| Loss: 0.015626114804763346\t| f1 score: 0.9812147986027255\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.15\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8001312534706446\n",
      "\n",
      "epoch: 7\t| Cnt: 1\t| Loss: 0.014290688559412956\t| f1 score: 0.9687194525904204\n",
      "epoch: 7\t| Cnt: 41\t| Loss: 0.014519436849514022\t| f1 score: 0.9851401946409062\n",
      "epoch: 7\t| Cnt: 81\t| Loss: 0.019696836051298305\t| f1 score: 0.9757252665830212\n",
      "epoch: 7\t| Cnt: 121\t| Loss: 0.015585745830321684\t| f1 score: 0.9796538439422691\n",
      "epoch: 7\t| Cnt: 161\t| Loss: 0.012381937424652278\t| f1 score: 0.9874785808751654\n",
      "epoch: 7\t| Cnt: 201\t| Loss: 0.015523729362757876\t| f1 score: 0.9843335625407004\n",
      "epoch: 7\t| Cnt: 241\t| Loss: 0.012902538548223675\t| f1 score: 0.9866965671899258\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.13\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.8210869875546674\n",
      "\n",
      "epoch: 8\t| Cnt: 1\t| Loss: 0.010059630498290062\t| f1 score: 1.0\n",
      "epoch: 8\t| Cnt: 41\t| Loss: 0.013045468367636204\t| f1 score: 0.9851432673509286\n",
      "epoch: 8\t| Cnt: 81\t| Loss: 0.012058301529032178\t| f1 score: 0.9859237536656892\n",
      "epoch: 8\t| Cnt: 121\t| Loss: 0.011412960782763548\t| f1 score: 0.9882528311279006\n",
      "epoch: 8\t| Cnt: 161\t| Loss: 0.012932428671047092\t| f1 score: 0.9843489807946639\n",
      "epoch: 8\t| Cnt: 201\t| Loss: 0.01661906109075062\t| f1 score: 0.9843535808751653\n",
      "epoch: 8\t| Cnt: 241\t| Loss: 0.016299005405744537\t| f1 score: 0.9820136852394917\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.09\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.8605163439674514\n",
      "\n",
      "epoch: 9\t| Cnt: 1\t| Loss: 0.006283922120928764\t| f1 score: 1.0\n",
      "epoch: 9\t| Cnt: 41\t| Loss: 0.012982575356727467\t| f1 score: 0.9874693807141626\n",
      "epoch: 9\t| Cnt: 81\t| Loss: 0.011123678481089883\t| f1 score: 0.9867026946409062\n",
      "epoch: 9\t| Cnt: 121\t| Loss: 0.01155781657435\t| f1 score: 0.9859206809556668\n",
      "epoch: 9\t| Cnt: 161\t| Loss: 0.01615923779318109\t| f1 score: 0.9804373849979875\n",
      "epoch: 9\t| Cnt: 201\t| Loss: 0.010907208334538154\t| f1 score: 0.9890487356966247\n",
      "epoch: 9\t| Cnt: 241\t| Loss: 0.012039867509156466\t| f1 score: 0.9827895535046863\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.11\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.84786697741241\n",
      "\n",
      "epoch: 10\t| Cnt: 1\t| Loss: 0.002883103210479021\t| f1 score: 1.0\n",
      "epoch: 10\t| Cnt: 41\t| Loss: 0.021117435846826994\t| f1 score: 0.9772816391320408\n",
      "epoch: 10\t| Cnt: 81\t| Loss: 0.018748978173243815\t| f1 score: 0.979658426053706\n",
      "epoch: 10\t| Cnt: 121\t| Loss: 0.016920375055633485\t| f1 score: 0.9812255261342073\n",
      "epoch: 10\t| Cnt: 161\t| Loss: 0.014462154993088916\t| f1 score: 0.9851279397389454\n",
      "epoch: 10\t| Cnt: 201\t| Loss: 0.013806924995151348\t| f1 score: 0.9866734761454385\n",
      "epoch: 10\t| Cnt: 241\t| Loss: 0.013244077100534924\t| f1 score: 0.9843367258927032\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.14\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8136191890928506\n",
      "\n",
      "epoch: 11\t| Cnt: 1\t| Loss: 0.06734278798103333\t| f1 score: 0.9372549019607843\n",
      "epoch: 11\t| Cnt: 41\t| Loss: 0.017252639689831994\t| f1 score: 0.9819875214849819\n",
      "epoch: 11\t| Cnt: 81\t| Loss: 0.011603003955679014\t| f1 score: 0.9874893084066472\n",
      "epoch: 11\t| Cnt: 121\t| Loss: 0.01470451383793261\t| f1 score: 0.9843381626212018\n",
      "epoch: 11\t| Cnt: 161\t| Loss: 0.006871271473937668\t| f1 score: 0.9945213041228221\n",
      "epoch: 11\t| Cnt: 201\t| Loss: 0.007913736451882869\t| f1 score: 0.9921752630671037\n",
      "epoch: 11\t| Cnt: 241\t| Loss: 0.011938265805656555\t| f1 score: 0.9874785808751654\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.15\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8185665519109312\n",
      "\n",
      "epoch: 12\t| Cnt: 1\t| Loss: 0.0030980652663856745\t| f1 score: 1.0\n",
      "epoch: 12\t| Cnt: 41\t| Loss: 0.011356578397681005\t| f1 score: 0.9882728494623656\n",
      "epoch: 12\t| Cnt: 81\t| Loss: 0.010717545539955608\t| f1 score: 0.9906066356161233\n",
      "epoch: 12\t| Cnt: 121\t| Loss: 0.00935357342241332\t| f1 score: 0.9898292220113852\n",
      "epoch: 12\t| Cnt: 161\t| Loss: 0.011269089611596428\t| f1 score: 0.9898168584983796\n",
      "epoch: 12\t| Cnt: 201\t| Loss: 0.009017628734000027\t| f1 score: 0.9905646872629795\n",
      "epoch: 12\t| Cnt: 241\t| Loss: 0.0063143055944237855\t| f1 score: 0.9937438905180841\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9055800770077946\n",
      "\n",
      "epoch: 13\t| Cnt: 1\t| Loss: 0.042849116027355194\t| f1 score: 0.9375\n",
      "epoch: 13\t| Cnt: 41\t| Loss: 0.013576833839761094\t| f1 score: 0.986687367028923\n",
      "epoch: 13\t| Cnt: 81\t| Loss: 0.014177407664828934\t| f1 score: 0.987473980794664\n",
      "epoch: 13\t| Cnt: 121\t| Loss: 0.011828006413998083\t| f1 score: 0.9874785808751654\n",
      "epoch: 13\t| Cnt: 161\t| Loss: 0.010941676638321952\t| f1 score: 0.9890441356161233\n",
      "epoch: 13\t| Cnt: 201\t| Loss: 0.0134131173719652\t| f1 score: 0.9851186489359623\n",
      "epoch: 13\t| Cnt: 241\t| Loss: 0.010103169607464223\t| f1 score: 0.9898261493013628\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9188187459607335\n",
      "\n",
      "epoch: 14\t| Cnt: 1\t| Loss: 0.041038867086172104\t| f1 score: 0.9687194525904204\n",
      "epoch: 14\t| Cnt: 41\t| Loss: 0.008604481929796747\t| f1 score: 0.9913978494623656\n",
      "epoch: 14\t| Cnt: 81\t| Loss: 0.008488575815863441\t| f1 score: 0.9921333147139599\n",
      "epoch: 14\t| Cnt: 121\t| Loss: 0.01158184930391144\t| f1 score: 0.9882651946409062\n",
      "epoch: 14\t| Cnt: 161\t| Loss: 0.009225808281917125\t| f1 score: 0.9913978494623656\n",
      "epoch: 14\t| Cnt: 201\t| Loss: 0.011462393720285036\t| f1 score: 0.9866980945604048\n",
      "epoch: 14\t| Cnt: 241\t| Loss: 0.004928658148855902\t| f1 score: 0.9953033178080617\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.918054392153817\n",
      "\n",
      "epoch: 15\t| Cnt: 1\t| Loss: 0.001188954571262002\t| f1 score: 1.0\n",
      "epoch: 15\t| Cnt: 41\t| Loss: 0.010117251102929003\t| f1 score: 0.9913932493818642\n",
      "epoch: 15\t| Cnt: 81\t| Loss: 0.011176847296883351\t| f1 score: 0.9890333174426612\n",
      "epoch: 15\t| Cnt: 121\t| Loss: 0.007492580790130887\t| f1 score: 0.9913978494623656\n",
      "epoch: 15\t| Cnt: 161\t| Loss: 0.007806619633629453\t| f1 score: 0.9921706629866023\n",
      "epoch: 15\t| Cnt: 201\t| Loss: 0.008979013431235217\t| f1 score: 0.9906158357771261\n",
      "epoch: 15\t| Cnt: 241\t| Loss: 0.00966833563434193\t| f1 score: 0.9890518084066471\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8987116284570289\n",
      "\n",
      "epoch: 16\t| Cnt: 1\t| Loss: 0.032956480979919434\t| f1 score: 0.9687194525904204\n",
      "epoch: 16\t| Cnt: 41\t| Loss: 0.009219336591195315\t| f1 score: 0.9898292220113852\n",
      "epoch: 16\t| Cnt: 81\t| Loss: 0.006077039045339916\t| f1 score: 0.9937392904375827\n",
      "epoch: 16\t| Cnt: 121\t| Loss: 0.0052958074869820845\t| f1 score: 0.9945259042033235\n",
      "epoch: 16\t| Cnt: 161\t| Loss: 0.00830406563836732\t| f1 score: 0.9890487356966247\n",
      "epoch: 16\t| Cnt: 201\t| Loss: 0.006578365821042098\t| f1 score: 0.9906112356966247\n",
      "epoch: 16\t| Cnt: 241\t| Loss: 0.006662974488426699\t| f1 score: 0.9913932493818642\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8910342261904762\n",
      "\n",
      "epoch: 17\t| Cnt: 1\t| Loss: 0.012070396915078163\t| f1 score: 0.9687194525904204\n",
      "epoch: 17\t| Cnt: 41\t| Loss: 0.005383373294898774\t| f1 score: 0.9921798631476051\n",
      "epoch: 17\t| Cnt: 81\t| Loss: 0.011570076999487356\t| f1 score: 0.9858556415580356\n",
      "epoch: 17\t| Cnt: 121\t| Loss: 0.007500215737672988\t| f1 score: 0.9937392904375827\n",
      "epoch: 17\t| Cnt: 161\t| Loss: 0.007575853305752389\t| f1 score: 0.9913932493818642\n",
      "epoch: 17\t| Cnt: 201\t| Loss: 0.006631410220870748\t| f1 score: 0.9921798631476051\n",
      "epoch: 17\t| Cnt: 241\t| Loss: 0.009525628589472035\t| f1 score: 0.9906158357771261\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:16\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9220581247267682\n",
      "\n",
      "epoch: 18\t| Cnt: 1\t| Loss: 0.0012768814340233803\t| f1 score: 1.0\n",
      "epoch: 18\t| Cnt: 41\t| Loss: 0.003811000060522929\t| f1 score: 0.996871945259042\n",
      "epoch: 18\t| Cnt: 81\t| Loss: 0.01622016853070818\t| f1 score: 0.9819982490164637\n",
      "epoch: 18\t| Cnt: 121\t| Loss: 0.009560660617717076\t| f1 score: 0.9906066356161233\n",
      "epoch: 18\t| Cnt: 161\t| Loss: 0.008527648162271362\t| f1 score: 0.9913932493818642\n",
      "epoch: 18\t| Cnt: 201\t| Loss: 0.005085278763726819\t| f1 score: 0.9937469452590421\n",
      "epoch: 18\t| Cnt: 241\t| Loss: 0.005447254453611094\t| f1 score: 0.9945259042033235\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9280747373176004\n",
      "\n",
      "epoch: 19\t| Cnt: 1\t| Loss: 0.0010089441202580929\t| f1 score: 1.0\n",
      "epoch: 19\t| Cnt: 41\t| Loss: 0.004554948287841398\t| f1 score: 0.9976539589442815\n",
      "epoch: 19\t| Cnt: 81\t| Loss: 0.004060880749602802\t| f1 score: 0.9960853314933011\n",
      "epoch: 19\t| Cnt: 121\t| Loss: 0.0063617128900659735\t| f1 score: 0.9953033178080617\n",
      "epoch: 19\t| Cnt: 161\t| Loss: 0.008083198837994132\t| f1 score: 0.9914009042033236\n",
      "epoch: 19\t| Cnt: 201\t| Loss: 0.007155078781943302\t| f1 score: 0.9929634042033235\n",
      "epoch: 19\t| Cnt: 241\t| Loss: 0.004976864636410028\t| f1 score: 0.9953033178080617\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:16\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9377004687885517\n",
      "\n",
      "epoch: 20\t| Cnt: 1\t| Loss: 0.0017544386209920049\t| f1 score: 1.0\n",
      "epoch: 20\t| Cnt: 41\t| Loss: 0.006727539928397164\t| f1 score: 0.9937438905180841\n",
      "epoch: 20\t| Cnt: 81\t| Loss: 0.004874735257908469\t| f1 score: 0.9960899315738025\n",
      "epoch: 20\t| Cnt: 121\t| Loss: 0.003973224395303987\t| f1 score: 0.9960899315738025\n",
      "epoch: 20\t| Cnt: 161\t| Loss: 0.005146894609788432\t| f1 score: 0.9937438905180841\n",
      "epoch: 20\t| Cnt: 201\t| Loss: 0.010815507541701663\t| f1 score: 0.9882667220113852\n",
      "epoch: 20\t| Cnt: 241\t| Loss: 0.007428284120396711\t| f1 score: 0.9921752630671037\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9414102848686645\n",
      "\n",
      "epoch: 21\t| Cnt: 1\t| Loss: 0.0016338629648089409\t| f1 score: 1.0\n",
      "epoch: 21\t| Cnt: 41\t| Loss: 0.0064898050521151164\t| f1 score: 0.9929634042033235\n",
      "epoch: 21\t| Cnt: 81\t| Loss: 0.007584059771033935\t| f1 score: 0.9929618768328445\n",
      "epoch: 21\t| Cnt: 121\t| Loss: 0.006540193093678681\t| f1 score: 0.9929618768328445\n",
      "epoch: 21\t| Cnt: 161\t| Loss: 0.007499318789632526\t| f1 score: 0.9913978494623656\n",
      "epoch: 21\t| Cnt: 201\t| Loss: 0.005705893777485471\t| f1 score: 0.9960899315738025\n",
      "epoch: 21\t| Cnt: 241\t| Loss: 0.007100394999724813\t| f1 score: 0.9929572767523431\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9334422210836502\n",
      "\n",
      "epoch: 22\t| Cnt: 1\t| Loss: 0.0009496726561337709\t| f1 score: 1.0\n",
      "epoch: 22\t| Cnt: 41\t| Loss: 0.008877424943784717\t| f1 score: 0.9906127630671037\n",
      "epoch: 22\t| Cnt: 81\t| Loss: 0.007285896410758141\t| f1 score: 0.9937408178080617\n",
      "epoch: 22\t| Cnt: 121\t| Loss: 0.002937709796970012\t| f1 score: 0.996871945259042\n",
      "epoch: 22\t| Cnt: 161\t| Loss: 0.003472630208125338\t| f1 score: 0.9960899315738025\n",
      "epoch: 22\t| Cnt: 201\t| Loss: 0.008445498855871847\t| f1 score: 0.9913886493013628\n",
      "epoch: 22\t| Cnt: 241\t| Loss: 0.004596760062122484\t| f1 score: 0.9976539589442815\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "epoch: 23\t| Cnt: 41\t| Loss: 0.0043768083989562\t| f1 score: 0.9960899315738025\n",
      "epoch: 23\t| Cnt: 81\t| Loss: 0.004113519732345594\t| f1 score: 0.9976539589442815\n",
      "epoch: 23\t| Cnt: 121\t| Loss: 0.0038441743861767465\t| f1 score: 0.9960899315738025\n",
      "epoch: 23\t| Cnt: 161\t| Loss: 0.00700598668991006\t| f1 score: 0.9945259042033235\n",
      "epoch: 23\t| Cnt: 201\t| Loss: 0.006289197888690978\t| f1 score: 0.9937438905180841\n",
      "epoch: 23\t| Cnt: 241\t| Loss: 0.005457229811872822\t| f1 score: 0.9953033178080617\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.936768989413914\n",
      "\n",
      "epoch: 24\t| Cnt: 1\t| Loss: 0.006445278879255056\t| f1 score: 1.0\n",
      "epoch: 24\t| Cnt: 41\t| Loss: 0.006745391681033652\t| f1 score: 0.9913978494623656\n",
      "epoch: 24\t| Cnt: 81\t| Loss: 0.005918943502911134\t| f1 score: 0.9929588041228221\n",
      "epoch: 24\t| Cnt: 121\t| Loss: 0.005159155211003963\t| f1 score: 0.9945259042033235\n",
      "epoch: 24\t| Cnt: 161\t| Loss: 0.012766873327927896\t| f1 score: 0.985911480794664\n",
      "epoch: 24\t| Cnt: 201\t| Loss: 0.010966324524633819\t| f1 score: 0.9898307493818642\n",
      "epoch: 24\t| Cnt: 241\t| Loss: 0.010303525323979556\t| f1 score: 0.9890472083261457\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9013291686050375\n",
      "\n",
      "epoch: 25\t| Cnt: 1\t| Loss: 0.0011492359917610884\t| f1 score: 1.0\n",
      "epoch: 25\t| Cnt: 41\t| Loss: 0.0042542469207546675\t| f1 score: 0.9960899315738025\n",
      "epoch: 25\t| Cnt: 81\t| Loss: 0.005237807206867728\t| f1 score: 0.9945259042033235\n",
      "epoch: 25\t| Cnt: 121\t| Loss: 0.003501149125077063\t| f1 score: 0.9960899315738025\n",
      "epoch: 25\t| Cnt: 161\t| Loss: 0.005997059788933256\t| f1 score: 0.9953033178080617\n",
      "epoch: 25\t| Cnt: 201\t| Loss: 0.009442577524168883\t| f1 score: 0.9882605945604048\n",
      "epoch: 25\t| Cnt: 241\t| Loss: 0.00617580972466385\t| f1 score: 0.9953079178885631\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9420340629687232\n",
      "\n",
      "epoch: 26\t| Cnt: 1\t| Loss: 0.0011115462984889746\t| f1 score: 1.0\n",
      "epoch: 26\t| Cnt: 41\t| Loss: 0.00281526885664789\t| f1 score: 0.9976539589442815\n",
      "epoch: 26\t| Cnt: 81\t| Loss: 0.004846651686966652\t| f1 score: 0.9945259042033235\n",
      "epoch: 26\t| Cnt: 121\t| Loss: 0.0007536168908700347\t| f1 score: 1.0\n",
      "epoch: 26\t| Cnt: 201\t| Loss: 0.0032083908226923086\t| f1 score: 0.9953079178885631\n",
      "epoch: 26\t| Cnt: 241\t| Loss: 0.0063864753999951064\t| f1 score: 0.9945259042033235\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9490013975925342\n",
      "\n",
      "epoch: 27\t| Cnt: 1\t| Loss: 0.0011999417329207063\t| f1 score: 1.0\n",
      "epoch: 27\t| Cnt: 41\t| Loss: 0.002652802399097709\t| f1 score: 0.996871945259042\n",
      "epoch: 27\t| Cnt: 81\t| Loss: 0.0017842255059804303\t| f1 score: 0.9976539589442815\n",
      "epoch: 27\t| Cnt: 121\t| Loss: 0.001887080340020475\t| f1 score: 0.998435972629521\n",
      "epoch: 27\t| Cnt: 161\t| Loss: 0.0021743090663221666\t| f1 score: 0.9992179863147606\n",
      "epoch: 27\t| Cnt: 201\t| Loss: 0.00713287831076741\t| f1 score: 0.9937438905180841\n",
      "epoch: 27\t| Cnt: 241\t| Loss: 0.004147777615435189\t| f1 score: 0.996871945259042\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9121060118753093\n",
      "\n",
      "epoch: 28\t| Cnt: 1\t| Loss: 0.0004790918901562691\t| f1 score: 1.0\n",
      "epoch: 28\t| Cnt: 41\t| Loss: 0.005814403117619804\t| f1 score: 0.9953079178885631\n",
      "epoch: 28\t| Cnt: 81\t| Loss: 0.004467885446138098\t| f1 score: 0.9913947767523432\n",
      "epoch: 28\t| Cnt: 121\t| Loss: 0.004101104238361586\t| f1 score: 0.9945213041228221\n",
      "epoch: 28\t| Cnt: 161\t| Loss: 0.00795409639395075\t| f1 score: 0.9921752630671037\n",
      "epoch: 28\t| Cnt: 201\t| Loss: 0.003962075954768806\t| f1 score: 0.9929618768328445\n",
      "epoch: 28\t| Cnt: 241\t| Loss: 0.0059071782143291784\t| f1 score: 0.9921752630671037\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9182520081305227\n",
      "\n",
      "epoch: 29\t| Cnt: 1\t| Loss: 0.000762811629101634\t| f1 score: 1.0\n",
      "epoch: 29\t| Cnt: 41\t| Loss: 0.008553456147637917\t| f1 score: 0.9913932493818642\n",
      "epoch: 29\t| Cnt: 81\t| Loss: 0.005949424417485716\t| f1 score: 0.9945074132393377\n",
      "epoch: 29\t| Cnt: 121\t| Loss: 0.00567231191234896\t| f1 score: 0.9960853314933011\n",
      "epoch: 29\t| Cnt: 161\t| Loss: 0.0054991099514154484\t| f1 score: 0.9945213041228221\n",
      "epoch: 29\t| Cnt: 201\t| Loss: 0.0049717378187779104\t| f1 score: 0.9945213041228221\n",
      "epoch: 29\t| Cnt: 241\t| Loss: 0.0070759512702352366\t| f1 score: 0.9945259042033235\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.08\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8783161502465662\n",
      "\n",
      "\n",
      "\n",
      "Generating Inputs for fold 1\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| Cnt: 1\t| Loss: 0.18460054695606232\t| f1 score: 0.36374269005847953\n",
      "epoch: 0\t| Cnt: 41\t| Loss: 0.1614008743315935\t| f1 score: 0.6122888931047934\n",
      "epoch: 0\t| Cnt: 81\t| Loss: 0.11993546094745397\t| f1 score: 0.7688326021676427\n",
      "epoch: 0\t| Cnt: 121\t| Loss: 0.10903937732800842\t| f1 score: 0.8167547689052752\n",
      "epoch: 0\t| Cnt: 161\t| Loss: 0.10552119398489594\t| f1 score: 0.805626262832242\n",
      "epoch: 0\t| Cnt: 201\t| Loss: 0.0872740475460887\t| f1 score: 0.8419461986559211\n",
      "epoch: 0\t| Cnt: 241\t| Loss: 0.09282863065600395\t| f1 score: 0.8452035383159018\n",
      "\n",
      "Average training loss: 0.11\n",
      "Average training score: 0.79\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.55\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.5454259745719146\n",
      "\n",
      "epoch: 1\t| Cnt: 1\t| Loss: 0.12095083296298981\t| f1 score: 0.8435972629521017\n",
      "epoch: 1\t| Cnt: 41\t| Loss: 0.07760655945166946\t| f1 score: 0.8661396756884703\n",
      "epoch: 1\t| Cnt: 81\t| Loss: 0.06483376952819526\t| f1 score: 0.8954991362567182\n",
      "epoch: 1\t| Cnt: 121\t| Loss: 0.05872737970203161\t| f1 score: 0.915244910640898\n",
      "epoch: 1\t| Cnt: 161\t| Loss: 0.057773901894688603\t| f1 score: 0.9088139244599649\n",
      "epoch: 1\t| Cnt: 201\t| Loss: 0.0596824792213738\t| f1 score: 0.9029205392505872\n",
      "epoch: 1\t| Cnt: 241\t| Loss: 0.046401268290355804\t| f1 score: 0.9238856507100431\n",
      "\n",
      "Average training loss: 0.06\n",
      "Average training score: 0.91\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.21\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7222721006149442\n",
      "\n",
      "epoch: 2\t| Cnt: 1\t| Loss: 0.02683442085981369\t| f1 score: 0.9375\n",
      "epoch: 2\t| Cnt: 41\t| Loss: 0.04545375313609838\t| f1 score: 0.933917847901643\n",
      "epoch: 2\t| Cnt: 81\t| Loss: 0.04256841158494353\t| f1 score: 0.9404020468705904\n",
      "epoch: 2\t| Cnt: 121\t| Loss: 0.042695833113975824\t| f1 score: 0.9427387971233256\n",
      "epoch: 2\t| Cnt: 161\t| Loss: 0.038540853350423274\t| f1 score: 0.9412363521267206\n",
      "epoch: 2\t| Cnt: 201\t| Loss: 0.03610589921008796\t| f1 score: 0.9488947809339319\n",
      "epoch: 2\t| Cnt: 241\t| Loss: 0.03420075750909746\t| f1 score: 0.9584794741412594\n",
      "\n",
      "Average training loss: 0.04\n",
      "Average training score: 0.95\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.23\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7171544768550888\n",
      "\n",
      "epoch: 3\t| Cnt: 1\t| Loss: 0.022221896797418594\t| f1 score: 0.9687194525904204\n",
      "epoch: 3\t| Cnt: 41\t| Loss: 0.03782830678392202\t| f1 score: 0.9442970813565591\n",
      "epoch: 3\t| Cnt: 81\t| Loss: 0.03763833725824952\t| f1 score: 0.9497687905133064\n",
      "epoch: 3\t| Cnt: 121\t| Loss: 0.030332482024095952\t| f1 score: 0.9568904620111436\n",
      "epoch: 3\t| Cnt: 161\t| Loss: 0.03630289101274684\t| f1 score: 0.9513211247961257\n",
      "epoch: 3\t| Cnt: 201\t| Loss: 0.0406123150489293\t| f1 score: 0.9322971721047606\n",
      "epoch: 3\t| Cnt: 241\t| Loss: 0.030417296674568207\t| f1 score: 0.960754257706386\n",
      "\n",
      "Average training loss: 0.04\n",
      "Average training score: 0.95\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.19\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7347363645431371\n",
      "\n",
      "epoch: 4\t| Cnt: 1\t| Loss: 0.010615427047014236\t| f1 score: 1.0\n",
      "epoch: 4\t| Cnt: 41\t| Loss: 0.026583580079022794\t| f1 score: 0.9662168932822397\n",
      "epoch: 4\t| Cnt: 81\t| Loss: 0.024497497384436427\t| f1 score: 0.9718245069288713\n",
      "epoch: 4\t| Cnt: 121\t| Loss: 0.02559370887465775\t| f1 score: 0.9725771935075983\n",
      "epoch: 4\t| Cnt: 161\t| Loss: 0.020716536440886557\t| f1 score: 0.9757160843910828\n",
      "epoch: 4\t| Cnt: 201\t| Loss: 0.023215274477843197\t| f1 score: 0.9717159738385529\n",
      "epoch: 4\t| Cnt: 241\t| Loss: 0.021761813171906397\t| f1 score: 0.975732939373545\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.97\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.18\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7785122563360616\n",
      "\n",
      "epoch: 5\t| Cnt: 1\t| Loss: 0.005713111720979214\t| f1 score: 1.0\n",
      "epoch: 5\t| Cnt: 41\t| Loss: 0.02582343070534989\t| f1 score: 0.9679036930021276\n",
      "epoch: 5\t| Cnt: 81\t| Loss: 0.026138411986175926\t| f1 score: 0.9678527115796264\n",
      "epoch: 5\t| Cnt: 121\t| Loss: 0.023109780956292524\t| f1 score: 0.9717937430938601\n",
      "epoch: 5\t| Cnt: 161\t| Loss: 0.02569580889539793\t| f1 score: 0.9701802796404234\n",
      "epoch: 5\t| Cnt: 201\t| Loss: 0.01988870750647038\t| f1 score: 0.9765319166522914\n",
      "epoch: 5\t| Cnt: 241\t| Loss: 0.02470943907974288\t| f1 score: 0.9702588256078041\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.97\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.14\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.793521550350776\n",
      "\n",
      "epoch: 6\t| Cnt: 1\t| Loss: 0.04155377298593521\t| f1 score: 0.9375\n",
      "epoch: 6\t| Cnt: 41\t| Loss: 0.023143210681155324\t| f1 score: 0.9694584295696235\n",
      "epoch: 6\t| Cnt: 81\t| Loss: 0.018688011658377947\t| f1 score: 0.9780139410316323\n",
      "epoch: 6\t| Cnt: 121\t| Loss: 0.02247410761192441\t| f1 score: 0.9764796977543166\n",
      "epoch: 6\t| Cnt: 161\t| Loss: 0.024339205812430008\t| f1 score: 0.9710040566180969\n",
      "epoch: 6\t| Cnt: 201\t| Loss: 0.015091065276646987\t| f1 score: 0.9804327849174861\n",
      "epoch: 6\t| Cnt: 241\t| Loss: 0.021688536513829605\t| f1 score: 0.976528843942269\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.10\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8564156324580607\n",
      "\n",
      "epoch: 7\t| Cnt: 1\t| Loss: 0.005008196923881769\t| f1 score: 1.0\n",
      "epoch: 7\t| Cnt: 41\t| Loss: 0.019884274597279726\t| f1 score: 0.9757391574665057\n",
      "epoch: 7\t| Cnt: 81\t| Loss: 0.02419265571224969\t| f1 score: 0.9694769205336093\n",
      "epoch: 7\t| Cnt: 121\t| Loss: 0.021544074936537073\t| f1 score: 0.9773123849979874\n",
      "epoch: 7\t| Cnt: 161\t| Loss: 0.016870469821151347\t| f1 score: 0.9819891394974413\n",
      "epoch: 7\t| Cnt: 201\t| Loss: 0.017286902698106132\t| f1 score: 0.9780713256078041\n",
      "epoch: 7\t| Cnt: 241\t| Loss: 0.017161323205800726\t| f1 score: 0.9773032028060491\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8862654311729523\n",
      "\n",
      "epoch: 8\t| Cnt: 1\t| Loss: 0.01552809402346611\t| f1 score: 1.0\n",
      "epoch: 8\t| Cnt: 41\t| Loss: 0.017016941047040747\t| f1 score: 0.9812086711517451\n",
      "epoch: 8\t| Cnt: 81\t| Loss: 0.02138619023608044\t| f1 score: 0.973365443254863\n",
      "epoch: 8\t| Cnt: 121\t| Loss: 0.017992467439034952\t| f1 score: 0.9773001300960267\n",
      "epoch: 8\t| Cnt: 161\t| Loss: 0.015372839412884786\t| f1 score: 0.9804404577080099\n",
      "epoch: 8\t| Cnt: 201\t| Loss: 0.015301853755954654\t| f1 score: 0.9819906848369847\n",
      "epoch: 8\t| Cnt: 241\t| Loss: 0.012708093065884895\t| f1 score: 0.9851340671899258\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.09\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8788956124435869\n",
      "\n",
      "epoch: 9\t| Cnt: 1\t| Loss: 0.009531819261610508\t| f1 score: 1.0\n",
      "epoch: 9\t| Cnt: 41\t| Loss: 0.01600890804838855\t| f1 score: 0.985909953424185\n",
      "epoch: 9\t| Cnt: 81\t| Loss: 0.015085207068477758\t| f1 score: 0.9811854894652775\n",
      "epoch: 9\t| Cnt: 121\t| Loss: 0.013430845754919573\t| f1 score: 0.9843597262952102\n",
      "epoch: 9\t| Cnt: 161\t| Loss: 0.017971500812564045\t| f1 score: 0.9788825577885113\n",
      "epoch: 9\t| Cnt: 201\t| Loss: 0.016091794171370567\t| f1 score: 0.9804266574665057\n",
      "epoch: 9\t| Cnt: 241\t| Loss: 0.01852166973403655\t| f1 score: 0.9757033365643423\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9155450875895086\n",
      "\n",
      "epoch: 10\t| Cnt: 1\t| Loss: 0.03798401355743408\t| f1 score: 0.9372549019607843\n",
      "epoch: 10\t| Cnt: 41\t| Loss: 0.017033489802270197\t| f1 score: 0.9796399530587845\n",
      "epoch: 10\t| Cnt: 81\t| Loss: 0.011669037124374882\t| f1 score: 0.9882713220918866\n",
      "epoch: 10\t| Cnt: 121\t| Loss: 0.017676529317395762\t| f1 score: 0.9804280941950043\n",
      "epoch: 10\t| Cnt: 161\t| Loss: 0.013192771474132314\t| f1 score: 0.9851401946409062\n",
      "epoch: 10\t| Cnt: 201\t| Loss: 0.009212166178622283\t| f1 score: 0.9890426082456443\n",
      "epoch: 10\t| Cnt: 241\t| Loss: 0.013863998430315405\t| f1 score: 0.9859176082456443\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8996422816892229\n",
      "\n",
      "epoch: 11\t| Cnt: 1\t| Loss: 0.0013902741484344006\t| f1 score: 1.0\n",
      "epoch: 11\t| Cnt: 41\t| Loss: 0.013028304310864769\t| f1 score: 0.9851325398194468\n",
      "epoch: 11\t| Cnt: 81\t| Loss: 0.017174085014266892\t| f1 score: 0.9788748849979875\n",
      "epoch: 11\t| Cnt: 121\t| Loss: 0.013032539197592997\t| f1 score: 0.9866919671094244\n",
      "epoch: 11\t| Cnt: 161\t| Loss: 0.013889173121424393\t| f1 score: 0.9843367258927032\n",
      "epoch: 11\t| Cnt: 201\t| Loss: 0.009826702342252247\t| f1 score: 0.9898307493818642\n",
      "epoch: 11\t| Cnt: 241\t| Loss: 0.012450401109526865\t| f1 score: 0.9851325398194468\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.09\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8760149843948727\n",
      "\n",
      "epoch: 12\t| Cnt: 1\t| Loss: 0.027097482234239578\t| f1 score: 0.9372549019607843\n",
      "epoch: 12\t| Cnt: 41\t| Loss: 0.01634645703015849\t| f1 score: 0.9812209260537059\n",
      "epoch: 12\t| Cnt: 81\t| Loss: 0.012087168663856573\t| f1 score: 0.9874831809556668\n",
      "epoch: 12\t| Cnt: 121\t| Loss: 0.015211149732931518\t| f1 score: 0.9843413259732046\n",
      "epoch: 12\t| Cnt: 161\t| Loss: 0.008917873472091742\t| f1 score: 0.9882467036769202\n",
      "epoch: 12\t| Cnt: 201\t| Loss: 0.013753897298010997\t| f1 score: 0.9835592216459847\n",
      "epoch: 12\t| Cnt: 241\t| Loss: 0.011752583004999905\t| f1 score: 0.987475508165143\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9155450875895086\n",
      "\n",
      "epoch: 13\t| Cnt: 1\t| Loss: 0.009473444893956184\t| f1 score: 0.9687194525904204\n",
      "epoch: 13\t| Cnt: 41\t| Loss: 0.006288659902929794\t| f1 score: 0.9945213041228221\n",
      "epoch: 13\t| Cnt: 81\t| Loss: 0.013612500758608804\t| f1 score: 0.9859222083261457\n",
      "epoch: 13\t| Cnt: 121\t| Loss: 0.007518028050253633\t| f1 score: 0.9929618768328445\n",
      "epoch: 13\t| Cnt: 161\t| Loss: 0.011716802608862053\t| f1 score: 0.9859222083261457\n",
      "epoch: 13\t| Cnt: 201\t| Loss: 0.009490855294279755\t| f1 score: 0.9882697947214076\n",
      "epoch: 13\t| Cnt: 241\t| Loss: 0.011490693905216176\t| f1 score: 0.9882559944799034\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8923412906241377\n",
      "\n",
      "epoch: 14\t| Cnt: 1\t| Loss: 0.0013453853316605091\t| f1 score: 1.0\n",
      "epoch: 14\t| Cnt: 41\t| Loss: 0.009483675271621906\t| f1 score: 0.9906173631476051\n",
      "epoch: 14\t| Cnt: 81\t| Loss: 0.012515669537242502\t| f1 score: 0.9866965671899258\n",
      "epoch: 14\t| Cnt: 121\t| Loss: 0.006293706243741326\t| f1 score: 0.9937438905180841\n",
      "epoch: 14\t| Cnt: 161\t| Loss: 0.007207215309608728\t| f1 score: 0.9906066356161233\n",
      "epoch: 14\t| Cnt: 201\t| Loss: 0.0051248178504465615\t| f1 score: 0.9937454178885631\n",
      "epoch: 14\t| Cnt: 241\t| Loss: 0.009362778509967029\t| f1 score: 0.9882713220918866\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.08\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8867655241387737\n",
      "\n",
      "epoch: 15\t| Cnt: 1\t| Loss: 0.0011847332352772355\t| f1 score: 1.0\n",
      "epoch: 15\t| Cnt: 41\t| Loss: 0.007717118307482451\t| f1 score: 0.9898353494623656\n",
      "epoch: 15\t| Cnt: 81\t| Loss: 0.008583285677013918\t| f1 score: 0.9898246219308838\n",
      "epoch: 15\t| Cnt: 121\t| Loss: 0.007109790355025325\t| f1 score: 0.9906081629866023\n",
      "epoch: 15\t| Cnt: 161\t| Loss: 0.010187954358116258\t| f1 score: 0.9882667220113852\n",
      "epoch: 15\t| Cnt: 201\t| Loss: 0.007649341215437744\t| f1 score: 0.9913932493818642\n",
      "epoch: 15\t| Cnt: 241\t| Loss: 0.010746524868591224\t| f1 score: 0.989054863147605\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9195513792299739\n",
      "\n",
      "epoch: 16\t| Cnt: 1\t| Loss: 0.0006469282670877874\t| f1 score: 1.0\n",
      "epoch: 16\t| Cnt: 41\t| Loss: 0.011609993057209066\t| f1 score: 0.9898292220113852\n",
      "epoch: 16\t| Cnt: 81\t| Loss: 0.00945462826784933\t| f1 score: 0.9898292220113852\n",
      "epoch: 16\t| Cnt: 121\t| Loss: 0.010009700646332931\t| f1 score: 0.9898307493818642\n",
      "epoch: 16\t| Cnt: 161\t| Loss: 0.007190611750411335\t| f1 score: 0.9906112356966247\n",
      "epoch: 16\t| Cnt: 201\t| Loss: 0.004249595911824144\t| f1 score: 0.9945274315738025\n",
      "epoch: 16\t| Cnt: 241\t| Loss: 0.008869946449704003\t| f1 score: 0.9906173631476051\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9110484467889666\n",
      "\n",
      "epoch: 17\t| Cnt: 1\t| Loss: 0.02718372456729412\t| f1 score: 0.9687194525904204\n",
      "epoch: 17\t| Cnt: 41\t| Loss: 0.009816724671691191\t| f1 score: 0.9882575218503824\n",
      "epoch: 17\t| Cnt: 81\t| Loss: 0.010198419625521638\t| f1 score: 0.985911480794664\n",
      "epoch: 17\t| Cnt: 121\t| Loss: 0.006386350069078617\t| f1 score: 0.9913932493818642\n",
      "epoch: 17\t| Cnt: 161\t| Loss: 0.006593415506358724\t| f1 score: 0.9921798631476051\n",
      "epoch: 17\t| Cnt: 201\t| Loss: 0.009790635900571942\t| f1 score: 0.9906035629061009\n",
      "epoch: 17\t| Cnt: 241\t| Loss: 0.007419440387457144\t| f1 score: 0.9921752630671037\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9406551239432679\n",
      "\n",
      "epoch: 18\t| Cnt: 1\t| Loss: 0.003368513658642769\t| f1 score: 1.0\n",
      "epoch: 18\t| Cnt: 41\t| Loss: 0.007633943885593908\t| f1 score: 0.9937392904375827\n",
      "epoch: 18\t| Cnt: 81\t| Loss: 0.011067295941757038\t| f1 score: 0.9866750035159175\n",
      "epoch: 18\t| Cnt: 121\t| Loss: 0.005967586397309788\t| f1 score: 0.9953033178080617\n",
      "epoch: 18\t| Cnt: 161\t| Loss: 0.00665995197778102\t| f1 score: 0.9921752630671037\n",
      "epoch: 18\t| Cnt: 201\t| Loss: 0.009421191608998925\t| f1 score: 0.9898261493013628\n",
      "epoch: 18\t| Cnt: 241\t| Loss: 0.007474293427367229\t| f1 score: 0.9921798631476051\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.917253755799097\n",
      "\n",
      "epoch: 19\t| Cnt: 1\t| Loss: 0.0026969965547323227\t| f1 score: 1.0\n",
      "epoch: 19\t| Cnt: 41\t| Loss: 0.008994255394645734\t| f1 score: 0.9913932493818642\n",
      "epoch: 19\t| Cnt: 81\t| Loss: 0.004813239684153814\t| f1 score: 0.9937392904375827\n",
      "epoch: 19\t| Cnt: 121\t| Loss: 0.009845144508290105\t| f1 score: 0.9906112356966247\n",
      "epoch: 19\t| Cnt: 161\t| Loss: 0.005675081403751392\t| f1 score: 0.9913978494623656\n",
      "epoch: 19\t| Cnt: 201\t| Loss: 0.009375144190562424\t| f1 score: 0.9898338220918866\n",
      "epoch: 19\t| Cnt: 241\t| Loss: 0.007652797536866274\t| f1 score: 0.9921798631476051\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9509455935111103\n",
      "\n",
      "epoch: 20\t| Cnt: 1\t| Loss: 0.0030082683078944683\t| f1 score: 1.0\n",
      "epoch: 20\t| Cnt: 41\t| Loss: 0.006882753563695587\t| f1 score: 0.9890472083261457\n",
      "epoch: 20\t| Cnt: 81\t| Loss: 0.007292731087363791\t| f1 score: 0.9929572767523431\n",
      "epoch: 20\t| Cnt: 121\t| Loss: 0.009754792477178854\t| f1 score: 0.9898153311279007\n",
      "epoch: 20\t| Cnt: 161\t| Loss: 0.008916499646147713\t| f1 score: 0.9874785808751654\n",
      "epoch: 20\t| Cnt: 201\t| Loss: 0.00435559565667063\t| f1 score: 0.9953033178080617\n",
      "epoch: 20\t| Cnt: 241\t| Loss: 0.010315021911810617\t| f1 score: 0.9882559944799034\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9044619059798233\n",
      "\n",
      "epoch: 21\t| Cnt: 1\t| Loss: 0.004025604575872421\t| f1 score: 1.0\n",
      "epoch: 21\t| Cnt: 41\t| Loss: 0.009966244231327437\t| f1 score: 0.9882667220113852\n",
      "epoch: 21\t| Cnt: 81\t| Loss: 0.008121398936782497\t| f1 score: 0.9929618768328445\n",
      "epoch: 21\t| Cnt: 121\t| Loss: 0.009230353951716097\t| f1 score: 0.9921813905180841\n",
      "epoch: 21\t| Cnt: 161\t| Loss: 0.00713693408324616\t| f1 score: 0.9906127630671037\n",
      "epoch: 21\t| Cnt: 201\t| Loss: 0.006115650170249865\t| f1 score: 0.9913932493818642\n",
      "epoch: 21\t| Cnt: 241\t| Loss: 0.009752174574532545\t| f1 score: 0.9906066356161233\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9476837375449085\n",
      "\n",
      "epoch: 22\t| Cnt: 1\t| Loss: 0.0011273855343461037\t| f1 score: 1.0\n",
      "epoch: 22\t| Cnt: 41\t| Loss: 0.0074714597867568955\t| f1 score: 0.9929618768328445\n",
      "epoch: 22\t| Cnt: 81\t| Loss: 0.00608646592736477\t| f1 score: 0.9945259042033235\n",
      "epoch: 22\t| Cnt: 121\t| Loss: 0.004477061973011587\t| f1 score: 0.9937438905180841\n",
      "epoch: 22\t| Cnt: 161\t| Loss: 0.004973961020004936\t| f1 score: 0.9945259042033235\n",
      "epoch: 22\t| Cnt: 201\t| Loss: 0.004448025672172662\t| f1 score: 0.9960899315738025\n",
      "epoch: 22\t| Cnt: 241\t| Loss: 0.01032860058330698\t| f1 score: 0.9898246219308838\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9242144419916456\n",
      "\n",
      "epoch: 23\t| Cnt: 1\t| Loss: 0.025427348911762238\t| f1 score: 0.9687194525904204\n",
      "epoch: 23\t| Cnt: 41\t| Loss: 0.007913521806767677\t| f1 score: 0.9898246219308838\n",
      "epoch: 23\t| Cnt: 81\t| Loss: 0.004741648151684786\t| f1 score: 0.9960914589442815\n",
      "epoch: 23\t| Cnt: 121\t| Loss: 0.004703309888282092\t| f1 score: 0.9953079178885631\n",
      "epoch: 23\t| Cnt: 161\t| Loss: 0.008968977482436458\t| f1 score: 0.9906112356966247\n",
      "epoch: 23\t| Cnt: 201\t| Loss: 0.007475773942132946\t| f1 score: 0.9905973448131402\n",
      "epoch: 23\t| Cnt: 241\t| Loss: 0.0042744668418890795\t| f1 score: 0.9953079178885631\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9616778201680322\n",
      "\n",
      "epoch: 24\t| Cnt: 1\t| Loss: 0.005264869891107082\t| f1 score: 1.0\n",
      "epoch: 24\t| Cnt: 41\t| Loss: 0.00470571967161959\t| f1 score: 0.9937392904375827\n",
      "epoch: 24\t| Cnt: 81\t| Loss: 0.005398965120184585\t| f1 score: 0.9921752630671037\n",
      "epoch: 24\t| Cnt: 121\t| Loss: 0.0036372224800288676\t| f1 score: 0.9960899315738025\n",
      "epoch: 24\t| Cnt: 161\t| Loss: 0.00685286639854894\t| f1 score: 0.9929618768328445\n",
      "epoch: 24\t| Cnt: 201\t| Loss: 0.0034314463962800803\t| f1 score: 0.996871945259042\n",
      "epoch: 24\t| Cnt: 241\t| Loss: 0.006078000253182836\t| f1 score: 0.9921813905180841\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9630519088453486\n",
      "\n",
      "epoch: 25\t| Cnt: 1\t| Loss: 0.0005486100562848151\t| f1 score: 1.0\n",
      "epoch: 25\t| Cnt: 41\t| Loss: 0.007021601087035379\t| f1 score: 0.9937438905180841\n",
      "epoch: 25\t| Cnt: 81\t| Loss: 0.007342180915293284\t| f1 score: 0.9929618768328445\n",
      "epoch: 25\t| Cnt: 121\t| Loss: 0.005675950584554812\t| f1 score: 0.9937438905180841\n",
      "epoch: 25\t| Cnt: 161\t| Loss: 0.005259769456461072\t| f1 score: 0.9953079178885631\n",
      "epoch: 25\t| Cnt: 201\t| Loss: 0.006877285342488904\t| f1 score: 0.9921521720226163\n",
      "epoch: 25\t| Cnt: 241\t| Loss: 0.006148852108890423\t| f1 score: 0.9929572767523431\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9406551239432679\n",
      "\n",
      "epoch: 26\t| Cnt: 1\t| Loss: 0.02345474250614643\t| f1 score: 0.9687194525904204\n",
      "epoch: 26\t| Cnt: 41\t| Loss: 0.008114735173876397\t| f1 score: 0.9921798631476051\n",
      "epoch: 26\t| Cnt: 81\t| Loss: 0.004491832383791916\t| f1 score: 0.9945213041228221\n",
      "epoch: 26\t| Cnt: 121\t| Loss: 0.005108906727400608\t| f1 score: 0.9937438905180841\n",
      "epoch: 26\t| Cnt: 161\t| Loss: 0.0033190603768161963\t| f1 score: 0.9976539589442815\n",
      "epoch: 26\t| Cnt: 201\t| Loss: 0.0040437089912302325\t| f1 score: 0.996871945259042\n",
      "epoch: 26\t| Cnt: 241\t| Loss: 0.006603866974182892\t| f1 score: 0.9945259042033235\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9575995772986197\n",
      "\n",
      "epoch: 27\t| Cnt: 1\t| Loss: 0.005028173327445984\t| f1 score: 1.0\n",
      "epoch: 27\t| Cnt: 41\t| Loss: 0.004033326129138004\t| f1 score: 0.996871945259042\n",
      "epoch: 27\t| Cnt: 81\t| Loss: 0.0038006736460374667\t| f1 score: 0.9945213041228221\n",
      "epoch: 27\t| Cnt: 121\t| Loss: 0.00277401608072978\t| f1 score: 0.996871945259042\n",
      "epoch: 27\t| Cnt: 161\t| Loss: 0.004353074682876467\t| f1 score: 0.9953079178885631\n",
      "epoch: 27\t| Cnt: 201\t| Loss: 0.0017582398555532563\t| f1 score: 0.998435972629521\n",
      "epoch: 27\t| Cnt: 241\t| Loss: 0.003934370174101786\t| f1 score: 0.9929572767523431\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9686233209996777\n",
      "\n",
      "epoch: 28\t| Cnt: 1\t| Loss: 0.0020489152520895004\t| f1 score: 1.0\n",
      "epoch: 28\t| Cnt: 41\t| Loss: 0.005043448122887639\t| f1 score: 0.9945213041228221\n",
      "epoch: 28\t| Cnt: 81\t| Loss: 0.0037199294842139353\t| f1 score: 0.9960899315738025\n",
      "epoch: 28\t| Cnt: 121\t| Loss: 0.00454359716604813\t| f1 score: 0.996871945259042\n",
      "epoch: 28\t| Cnt: 161\t| Loss: 0.0034529119002399966\t| f1 score: 0.9960853314933011\n",
      "epoch: 28\t| Cnt: 201\t| Loss: 0.0015439765196788358\t| f1 score: 0.998435972629521\n",
      "epoch: 28\t| Cnt: 241\t| Loss: 0.0007938399990962353\t| f1 score: 1.0\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9555848381650927\n",
      "\n",
      "epoch: 29\t| Cnt: 1\t| Loss: 0.02287028357386589\t| f1 score: 0.9687194525904204\n",
      "epoch: 29\t| Cnt: 41\t| Loss: 0.007626440433523385\t| f1 score: 0.9929526766718417\n",
      "epoch: 29\t| Cnt: 81\t| Loss: 0.006563693614225485\t| f1 score: 0.9921798631476051\n",
      "epoch: 29\t| Cnt: 121\t| Loss: 0.004331409237056505\t| f1 score: 0.9945213041228221\n",
      "epoch: 29\t| Cnt: 161\t| Loss: 0.007728517327632289\t| f1 score: 0.9906112356966247\n",
      "epoch: 29\t| Cnt: 201\t| Loss: 0.004825118668668438\t| f1 score: 0.9945259042033235\n",
      "epoch: 29\t| Cnt: 241\t| Loss: 0.0038211196162592385\t| f1 score: 0.9953094452590421\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9616778201680322\n",
      "\n",
      "\n",
      "\n",
      "Generating Inputs for fold 2\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| Cnt: 1\t| Loss: 0.17651398479938507\t| f1 score: 0.46843853820598\n",
      "epoch: 0\t| Cnt: 41\t| Loss: 0.15888127349317074\t| f1 score: 0.6111065317907896\n",
      "epoch: 0\t| Cnt: 81\t| Loss: 0.11560458382591605\t| f1 score: 0.7884348498698973\n",
      "epoch: 0\t| Cnt: 121\t| Loss: 0.10954265352338552\t| f1 score: 0.8061509304994565\n",
      "epoch: 0\t| Cnt: 161\t| Loss: 0.09927565800026059\t| f1 score: 0.83382790380128\n",
      "epoch: 0\t| Cnt: 201\t| Loss: 0.08846799042075873\t| f1 score: 0.8493115573841706\n",
      "epoch: 0\t| Cnt: 241\t| Loss: 0.08766758721321821\t| f1 score: 0.8472932433877641\n",
      "\n",
      "Average training loss: 0.11\n",
      "Average training score: 0.80\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.22\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.6958293979938452\n",
      "\n",
      "epoch: 1\t| Cnt: 1\t| Loss: 0.11676933616399765\t| f1 score: 0.8117647058823529\n",
      "epoch: 1\t| Cnt: 41\t| Loss: 0.07673048069700598\t| f1 score: 0.8688872972821237\n",
      "epoch: 1\t| Cnt: 81\t| Loss: 0.08268177211284637\t| f1 score: 0.859087832429163\n",
      "epoch: 1\t| Cnt: 121\t| Loss: 0.07241997844539583\t| f1 score: 0.8857324415603631\n",
      "epoch: 1\t| Cnt: 161\t| Loss: 0.07002714388072491\t| f1 score: 0.8905410697240242\n",
      "epoch: 1\t| Cnt: 201\t| Loss: 0.07170511269941926\t| f1 score: 0.8913719970439569\n",
      "epoch: 1\t| Cnt: 241\t| Loss: 0.055116329621523616\t| f1 score: 0.9159869780336353\n",
      "\n",
      "Average training loss: 0.07\n",
      "Average training score: 0.89\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.36\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.6165877569540277\n",
      "\n",
      "epoch: 2\t| Cnt: 1\t| Loss: 0.05160112306475639\t| f1 score: 0.9054187192118226\n",
      "epoch: 2\t| Cnt: 41\t| Loss: 0.05674332077614963\t| f1 score: 0.9117761589653262\n",
      "epoch: 2\t| Cnt: 81\t| Loss: 0.047227897495031354\t| f1 score: 0.9294228374853498\n",
      "epoch: 2\t| Cnt: 121\t| Loss: 0.04467706466093659\t| f1 score: 0.9363935916431132\n",
      "epoch: 2\t| Cnt: 161\t| Loss: 0.04805415109731257\t| f1 score: 0.9292154150123156\n",
      "epoch: 2\t| Cnt: 201\t| Loss: 0.04024808981921524\t| f1 score: 0.9450397626775793\n",
      "epoch: 2\t| Cnt: 241\t| Loss: 0.04004582886118442\t| f1 score: 0.9402071965546905\n",
      "\n",
      "Average training loss: 0.05\n",
      "Average training score: 0.93\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.28\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.6785983963180037\n",
      "\n",
      "epoch: 3\t| Cnt: 1\t| Loss: 0.03921278938651085\t| f1 score: 0.9687194525904204\n",
      "epoch: 3\t| Cnt: 41\t| Loss: 0.038591473875567314\t| f1 score: 0.9442796428073368\n",
      "epoch: 3\t| Cnt: 81\t| Loss: 0.0352938239229843\t| f1 score: 0.9529469051499658\n",
      "epoch: 3\t| Cnt: 121\t| Loss: 0.029797777975909413\t| f1 score: 0.9623833244744961\n",
      "epoch: 3\t| Cnt: 161\t| Loss: 0.03078237804584205\t| f1 score: 0.959980098095631\n",
      "epoch: 3\t| Cnt: 201\t| Loss: 0.03036793149076402\t| f1 score: 0.9631715562526963\n",
      "epoch: 3\t| Cnt: 241\t| Loss: 0.028798924409784377\t| f1 score: 0.9686425066664345\n",
      "\n",
      "Average training loss: 0.03\n",
      "Average training score: 0.96\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.29\n",
      "Validation took: 0:00:16\n",
      "\n",
      "valid score: 0.6921989551308236\n",
      "\n",
      "epoch: 4\t| Cnt: 1\t| Loss: 0.003826336469501257\t| f1 score: 1.0\n",
      "epoch: 4\t| Cnt: 41\t| Loss: 0.03348756410414353\t| f1 score: 0.9560468117792842\n",
      "epoch: 4\t| Cnt: 81\t| Loss: 0.032185083837248385\t| f1 score: 0.9568766438005749\n",
      "epoch: 4\t| Cnt: 121\t| Loss: 0.0268026341102086\t| f1 score: 0.9663456844715842\n",
      "epoch: 4\t| Cnt: 161\t| Loss: 0.027166658337228\t| f1 score: 0.9671000250008994\n",
      "epoch: 4\t| Cnt: 201\t| Loss: 0.027192373108118773\t| f1 score: 0.9616260198462033\n",
      "epoch: 4\t| Cnt: 241\t| Loss: 0.02516538180061616\t| f1 score: 0.9733576798223588\n",
      "\n",
      "Average training loss: 0.03\n",
      "Average training score: 0.96\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.23\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7328382335914388\n",
      "\n",
      "epoch: 5\t| Cnt: 1\t| Loss: 0.03470476344227791\t| f1 score: 0.9372549019607843\n",
      "epoch: 5\t| Cnt: 41\t| Loss: 0.029750788887031376\t| f1 score: 0.9560760664784336\n",
      "epoch: 5\t| Cnt: 81\t| Loss: 0.023755233129486443\t| f1 score: 0.9710285843910829\n",
      "epoch: 5\t| Cnt: 121\t| Loss: 0.023635492264293134\t| f1 score: 0.9671108431743616\n",
      "epoch: 5\t| Cnt: 161\t| Loss: 0.02093882387271151\t| f1 score: 0.978091343942269\n",
      "epoch: 5\t| Cnt: 201\t| Loss: 0.025175328261684626\t| f1 score: 0.9709978385251361\n",
      "epoch: 5\t| Cnt: 241\t| Loss: 0.018921239319024608\t| f1 score: 0.9772894025645449\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.97\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.15\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.795231067449417\n",
      "\n",
      "epoch: 6\t| Cnt: 1\t| Loss: 0.05894509702920914\t| f1 score: 0.9372549019607843\n",
      "epoch: 6\t| Cnt: 41\t| Loss: 0.02267684577673208\t| f1 score: 0.9702389158843839\n",
      "epoch: 6\t| Cnt: 81\t| Loss: 0.018874394247541205\t| f1 score: 0.973345040606663\n",
      "epoch: 6\t| Cnt: 121\t| Loss: 0.019606537831714378\t| f1 score: 0.9725880116810603\n",
      "epoch: 6\t| Cnt: 161\t| Loss: 0.017625023715663702\t| f1 score: 0.9780851985222242\n",
      "epoch: 6\t| Cnt: 201\t| Loss: 0.02178416418901179\t| f1 score: 0.9764904252857984\n",
      "epoch: 6\t| Cnt: 241\t| Loss: 0.0179320250172168\t| f1 score: 0.976510352978283\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.97\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.13\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8138974436485154\n",
      "\n",
      "epoch: 7\t| Cnt: 1\t| Loss: 0.007530242670327425\t| f1 score: 1.0\n",
      "epoch: 7\t| Cnt: 41\t| Loss: 0.020434322557412087\t| f1 score: 0.9772708029895142\n",
      "epoch: 7\t| Cnt: 81\t| Loss: 0.019677515170769766\t| f1 score: 0.9749478529782831\n",
      "epoch: 7\t| Cnt: 121\t| Loss: 0.01659775141160935\t| f1 score: 0.9788748849979875\n",
      "epoch: 7\t| Cnt: 161\t| Loss: 0.019119289057562126\t| f1 score: 0.9780404711308126\n",
      "epoch: 7\t| Cnt: 201\t| Loss: 0.019191990373656154\t| f1 score: 0.9749478529782831\n",
      "epoch: 7\t| Cnt: 241\t| Loss: 0.018959639873355628\t| f1 score: 0.9749078163093532\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.09\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.856949545925102\n",
      "\n",
      "epoch: 8\t| Cnt: 1\t| Loss: 0.04391083866357803\t| f1 score: 0.9375\n",
      "epoch: 8\t| Cnt: 41\t| Loss: 0.02112606390437577\t| f1 score: 0.9756879362794433\n",
      "epoch: 8\t| Cnt: 81\t| Loss: 0.01800792583380826\t| f1 score: 0.9819998670289231\n",
      "epoch: 8\t| Cnt: 121\t| Loss: 0.016564698587171734\t| f1 score: 0.9820075398194469\n",
      "epoch: 8\t| Cnt: 161\t| Loss: 0.01569940188783221\t| f1 score: 0.9819998849979875\n",
      "epoch: 8\t| Cnt: 201\t| Loss: 0.013325967630953528\t| f1 score: 0.9843413259732046\n",
      "epoch: 8\t| Cnt: 241\t| Loss: 0.014818267864757217\t| f1 score: 0.9819968122879651\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.09\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8613709605736133\n",
      "\n",
      "epoch: 9\t| Cnt: 1\t| Loss: 0.03537449240684509\t| f1 score: 0.9687194525904204\n",
      "epoch: 9\t| Cnt: 41\t| Loss: 0.01903032630798407\t| f1 score: 0.9788748849979875\n",
      "epoch: 9\t| Cnt: 81\t| Loss: 0.016163999433047138\t| f1 score: 0.9835546215654833\n",
      "epoch: 9\t| Cnt: 121\t| Loss: 0.016369586536893622\t| f1 score: 0.9827649350897201\n",
      "epoch: 9\t| Cnt: 161\t| Loss: 0.010469845929765142\t| f1 score: 0.9890441356161233\n",
      "epoch: 9\t| Cnt: 201\t| Loss: 0.013021141910576262\t| f1 score: 0.9843320351702214\n",
      "epoch: 9\t| Cnt: 241\t| Loss: 0.018019752425607292\t| f1 score: 0.9772923666635226\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.13\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8259290686449805\n",
      "\n",
      "epoch: 10\t| Cnt: 1\t| Loss: 0.0033641927875578403\t| f1 score: 1.0\n",
      "epoch: 10\t| Cnt: 41\t| Loss: 0.01386593958886806\t| f1 score: 0.984347453424185\n",
      "epoch: 10\t| Cnt: 81\t| Loss: 0.016804773441981523\t| f1 score: 0.9780867438617676\n",
      "epoch: 10\t| Cnt: 121\t| Loss: 0.010669237072579562\t| f1 score: 0.9874831809556668\n",
      "epoch: 10\t| Cnt: 161\t| Loss: 0.011818956144270486\t| f1 score: 0.985123339658444\n",
      "epoch: 10\t| Cnt: 201\t| Loss: 0.014975906303152441\t| f1 score: 0.9765149530587844\n",
      "epoch: 10\t| Cnt: 241\t| Loss: 0.012342683676979504\t| f1 score: 0.9859191535851878\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8912396474661238\n",
      "\n",
      "epoch: 11\t| Cnt: 1\t| Loss: 0.0022427039220929146\t| f1 score: 1.0\n",
      "epoch: 11\t| Cnt: 41\t| Loss: 0.013383847381919622\t| f1 score: 0.9843535808751653\n",
      "epoch: 11\t| Cnt: 81\t| Loss: 0.014230661252804566\t| f1 score: 0.9835623670289231\n",
      "epoch: 11\t| Cnt: 121\t| Loss: 0.012557404456310905\t| f1 score: 0.9827726985222242\n",
      "epoch: 11\t| Cnt: 161\t| Loss: 0.01098772376863053\t| f1 score: 0.9898292220113852\n",
      "epoch: 11\t| Cnt: 201\t| Loss: 0.01163383549428545\t| f1 score: 0.9843427627017032\n",
      "epoch: 11\t| Cnt: 241\t| Loss: 0.009785222564823925\t| f1 score: 0.9866934944799034\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.12\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8322238426174928\n",
      "\n",
      "epoch: 12\t| Cnt: 1\t| Loss: 0.003802623599767685\t| f1 score: 1.0\n",
      "epoch: 12\t| Cnt: 41\t| Loss: 0.01288742141041439\t| f1 score: 0.9827849534241849\n",
      "epoch: 12\t| Cnt: 81\t| Loss: 0.01044758130738046\t| f1 score: 0.9882421035964188\n",
      "epoch: 12\t| Cnt: 121\t| Loss: 0.016878678018110806\t| f1 score: 0.9773046215654834\n",
      "epoch: 12\t| Cnt: 161\t| Loss: 0.010665557254105807\t| f1 score: 0.9859222083261457\n",
      "epoch: 12\t| Cnt: 201\t| Loss: 0.014705623441841453\t| f1 score: 0.9843089441257341\n",
      "epoch: 12\t| Cnt: 241\t| Loss: 0.011132762966735755\t| f1 score: 0.9874862356966247\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8987775307458514\n",
      "\n",
      "epoch: 13\t| Cnt: 1\t| Loss: 0.005950215272605419\t| f1 score: 1.0\n",
      "epoch: 13\t| Cnt: 41\t| Loss: 0.01318485951051116\t| f1 score: 0.9835684944799035\n",
      "epoch: 13\t| Cnt: 81\t| Loss: 0.009998760194866918\t| f1 score: 0.985123339658444\n",
      "epoch: 13\t| Cnt: 121\t| Loss: 0.008106271909491624\t| f1 score: 0.9921752630671037\n",
      "epoch: 13\t| Cnt: 161\t| Loss: 0.006285321201721672\t| f1 score: 0.9929618768328445\n",
      "epoch: 13\t| Cnt: 201\t| Loss: 0.00984484035288915\t| f1 score: 0.9866826763064414\n",
      "epoch: 13\t| Cnt: 241\t| Loss: 0.008035947311145718\t| f1 score: 0.9906112356966247\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8987775307458514\n",
      "\n",
      "epoch: 14\t| Cnt: 1\t| Loss: 0.0341481976211071\t| f1 score: 0.9372549019607843\n",
      "epoch: 14\t| Cnt: 41\t| Loss: 0.009808011920540594\t| f1 score: 0.9906158357771261\n",
      "epoch: 14\t| Cnt: 81\t| Loss: 0.0057132988978992215\t| f1 score: 0.9945259042033235\n",
      "epoch: 14\t| Cnt: 121\t| Loss: 0.012828808921767632\t| f1 score: 0.9851417399804496\n",
      "epoch: 14\t| Cnt: 161\t| Loss: 0.014539025016711093\t| f1 score: 0.9820106125294693\n",
      "epoch: 14\t| Cnt: 201\t| Loss: 0.01187507574504707\t| f1 score: 0.9866965671899258\n",
      "epoch: 14\t| Cnt: 241\t| Loss: 0.008906894465326332\t| f1 score: 0.9874831809556668\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9235492326833277\n",
      "\n",
      "epoch: 15\t| Cnt: 1\t| Loss: 0.05111870914697647\t| f1 score: 0.9687194525904204\n",
      "epoch: 15\t| Cnt: 41\t| Loss: 0.009740645794954617\t| f1 score: 0.9874692900721822\n",
      "epoch: 15\t| Cnt: 81\t| Loss: 0.0105456749064615\t| f1 score: 0.98667807622594\n",
      "epoch: 15\t| Cnt: 121\t| Loss: 0.01001500235433923\t| f1 score: 0.9890333174426612\n",
      "epoch: 15\t| Cnt: 161\t| Loss: 0.01220309636555612\t| f1 score: 0.9835761672704273\n",
      "epoch: 15\t| Cnt: 201\t| Loss: 0.009429430500313174\t| f1 score: 0.9890518084066471\n",
      "epoch: 15\t| Cnt: 241\t| Loss: 0.008489902048313524\t| f1 score: 0.9874847083261458\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8942250072490623\n",
      "\n",
      "epoch: 16\t| Cnt: 1\t| Loss: 0.003245897591114044\t| f1 score: 1.0\n",
      "epoch: 16\t| Cnt: 41\t| Loss: 0.005549523685476743\t| f1 score: 0.9921706629866023\n",
      "epoch: 16\t| Cnt: 81\t| Loss: 0.008751539881632197\t| f1 score: 0.9921813905180841\n",
      "epoch: 16\t| Cnt: 121\t| Loss: 0.007719636365072802\t| f1 score: 0.9890518084066471\n",
      "epoch: 16\t| Cnt: 161\t| Loss: 0.010177999005827587\t| f1 score: 0.9890487356966247\n",
      "epoch: 16\t| Cnt: 201\t| Loss: 0.004560071483138017\t| f1 score: 0.9937438905180841\n",
      "epoch: 16\t| Cnt: 241\t| Loss: 0.006095106026623398\t| f1 score: 0.9953033178080617\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9511752373905538\n",
      "\n",
      "epoch: 17\t| Cnt: 1\t| Loss: 0.05196073651313782\t| f1 score: 0.9687194525904204\n",
      "epoch: 17\t| Cnt: 41\t| Loss: 0.009951333995559253\t| f1 score: 0.9882605945604048\n",
      "epoch: 17\t| Cnt: 81\t| Loss: 0.007706900162156671\t| f1 score: 0.9937392904375827\n",
      "epoch: 17\t| Cnt: 121\t| Loss: 0.007906465519045013\t| f1 score: 0.9913840492208614\n",
      "epoch: 17\t| Cnt: 161\t| Loss: 0.006159061886864947\t| f1 score: 0.9921706629866023\n",
      "epoch: 17\t| Cnt: 201\t| Loss: 0.004826035027508624\t| f1 score: 0.9953079178885631\n",
      "epoch: 17\t| Cnt: 241\t| Loss: 0.0064487154406378975\t| f1 score: 0.9945259042033235\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9298768740177531\n",
      "\n",
      "epoch: 18\t| Cnt: 1\t| Loss: 0.00038578739622607827\t| f1 score: 1.0\n",
      "epoch: 18\t| Cnt: 41\t| Loss: 0.009680699481396004\t| f1 score: 0.9898338220918866\n",
      "epoch: 18\t| Cnt: 81\t| Loss: 0.008771374271600508\t| f1 score: 0.9913886493013628\n",
      "epoch: 18\t| Cnt: 121\t| Loss: 0.010166667921293993\t| f1 score: 0.9890472083261457\n",
      "epoch: 18\t| Cnt: 161\t| Loss: 0.01133771398308454\t| f1 score: 0.9874785808751654\n",
      "epoch: 18\t| Cnt: 201\t| Loss: 0.010707907282630913\t| f1 score: 0.9898215492208614\n",
      "epoch: 18\t| Cnt: 241\t| Loss: 0.0050382997760607395\t| f1 score: 0.9953079178885631\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9406005085880464\n",
      "\n",
      "epoch: 19\t| Cnt: 1\t| Loss: 0.0012058799620717764\t| f1 score: 1.0\n",
      "epoch: 19\t| Cnt: 41\t| Loss: 0.004795724990253802\t| f1 score: 0.9960899315738025\n",
      "epoch: 19\t| Cnt: 81\t| Loss: 0.0058906765400024595\t| f1 score: 0.9921752630671037\n",
      "epoch: 19\t| Cnt: 121\t| Loss: 0.008528223945904755\t| f1 score: 0.9906158357771261\n",
      "epoch: 19\t| Cnt: 161\t| Loss: 0.005766043199400883\t| f1 score: 0.9937392904375827\n",
      "epoch: 19\t| Cnt: 201\t| Loss: 0.0072098824864951895\t| f1 score: 0.9906066356161233\n",
      "epoch: 19\t| Cnt: 241\t| Loss: 0.005709311952523421\t| f1 score: 0.9937392904375827\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9595738158558338\n",
      "\n",
      "epoch: 20\t| Cnt: 1\t| Loss: 0.04342716187238693\t| f1 score: 0.9687194525904204\n",
      "epoch: 20\t| Cnt: 41\t| Loss: 0.0058729328848130535\t| f1 score: 0.9937438905180841\n",
      "epoch: 20\t| Cnt: 81\t| Loss: 0.0049732834202586675\t| f1 score: 0.9945259042033235\n",
      "epoch: 20\t| Cnt: 121\t| Loss: 0.009214038336358499\t| f1 score: 0.990618890518084\n",
      "epoch: 20\t| Cnt: 161\t| Loss: 0.010501640475558816\t| f1 score: 0.9906066356161233\n",
      "epoch: 20\t| Cnt: 201\t| Loss: 0.012828981844359077\t| f1 score: 0.9867011672704272\n",
      "epoch: 20\t| Cnt: 241\t| Loss: 0.009528339204553048\t| f1 score: 0.9874847083261458\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9304604194619024\n",
      "\n",
      "epoch: 21\t| Cnt: 1\t| Loss: 0.0003527483786456287\t| f1 score: 1.0\n",
      "epoch: 21\t| Cnt: 41\t| Loss: 0.005560871353372932\t| f1 score: 0.9937392904375827\n",
      "epoch: 21\t| Cnt: 81\t| Loss: 0.005805487641919171\t| f1 score: 0.9921752630671037\n",
      "epoch: 21\t| Cnt: 121\t| Loss: 0.007262829894898459\t| f1 score: 0.9913978494623656\n",
      "epoch: 21\t| Cnt: 161\t| Loss: 0.0072240799163409974\t| f1 score: 0.9913932493818642\n",
      "epoch: 21\t| Cnt: 201\t| Loss: 0.0077546548411191905\t| f1 score: 0.9913993768328446\n",
      "epoch: 21\t| Cnt: 241\t| Loss: 0.004819726696587168\t| f1 score: 0.9953079178885631\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:20\n",
      "\n",
      "valid score: 0.9511752373905538\n",
      "\n",
      "epoch: 22\t| Cnt: 1\t| Loss: 0.025152914226055145\t| f1 score: 0.9687194525904204\n",
      "epoch: 22\t| Cnt: 41\t| Loss: 0.004564368410501629\t| f1 score: 0.9945259042033235\n",
      "epoch: 22\t| Cnt: 81\t| Loss: 0.006660861965065124\t| f1 score: 0.9921752630671037\n",
      "epoch: 22\t| Cnt: 121\t| Loss: 0.003284005161913228\t| f1 score: 0.996871945259042\n",
      "epoch: 22\t| Cnt: 161\t| Loss: 0.004094718222040683\t| f1 score: 0.9960914589442815\n",
      "epoch: 22\t| Cnt: 201\t| Loss: 0.007137465388950659\t| f1 score: 0.992182917888563\n",
      "epoch: 22\t| Cnt: 241\t| Loss: 0.007709073780279141\t| f1 score: 0.9898353494623656\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.08\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.881090845769313\n",
      "\n",
      "epoch: 23\t| Cnt: 1\t| Loss: 0.005536860320717096\t| f1 score: 1.0\n",
      "epoch: 23\t| Cnt: 41\t| Loss: 0.006930931136594154\t| f1 score: 0.9921752630671037\n",
      "epoch: 23\t| Cnt: 81\t| Loss: 0.0064856056953431105\t| f1 score: 0.9921798631476051\n",
      "epoch: 23\t| Cnt: 121\t| Loss: 0.005055749227904016\t| f1 score: 0.9953033178080617\n",
      "epoch: 23\t| Cnt: 161\t| Loss: 0.0013671859545866028\t| f1 score: 0.9992179863147606\n",
      "epoch: 23\t| Cnt: 201\t| Loss: 0.0025793962686293526\t| f1 score: 0.9976539589442815\n",
      "epoch: 23\t| Cnt: 241\t| Loss: 0.0015869820461375638\t| f1 score: 0.9992179863147606\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:16\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9709913014935172\n",
      "\n",
      "epoch: 24\t| Cnt: 1\t| Loss: 0.0006116690346971154\t| f1 score: 1.0\n",
      "epoch: 24\t| Cnt: 41\t| Loss: 0.006746646568717552\t| f1 score: 0.9929588041228221\n",
      "epoch: 24\t| Cnt: 81\t| Loss: 0.003997558468108764\t| f1 score: 0.9976539589442815\n",
      "epoch: 24\t| Cnt: 121\t| Loss: 0.005372942496614996\t| f1 score: 0.9945167040423207\n",
      "epoch: 24\t| Cnt: 161\t| Loss: 0.0018214419596915832\t| f1 score: 0.9976539589442815\n",
      "epoch: 24\t| Cnt: 201\t| Loss: 0.004326186762045836\t| f1 score: 0.9953033178080617\n",
      "epoch: 24\t| Cnt: 241\t| Loss: 0.004676286554968101\t| f1 score: 0.9953094452590421\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.960231534060471\n",
      "\n",
      "epoch: 25\t| Cnt: 1\t| Loss: 0.00028108959668315947\t| f1 score: 1.0\n",
      "epoch: 25\t| Cnt: 41\t| Loss: 0.005313560469949153\t| f1 score: 0.9945167040423207\n",
      "epoch: 25\t| Cnt: 81\t| Loss: 0.006072193682848592\t| f1 score: 0.9929618768328445\n",
      "epoch: 25\t| Cnt: 121\t| Loss: 0.005694096541265026\t| f1 score: 0.9921813905180841\n",
      "epoch: 25\t| Cnt: 201\t| Loss: 0.001997648333053803\t| f1 score: 0.998435972629521\n",
      "epoch: 25\t| Cnt: 241\t| Loss: 0.0050069799817720195\t| f1 score: 0.9953079178885631\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9765438379191365\n",
      "\n",
      "epoch: 26\t| Cnt: 1\t| Loss: 0.0005424353876151145\t| f1 score: 1.0\n",
      "epoch: 26\t| Cnt: 41\t| Loss: 0.005080736073796288\t| f1 score: 0.9945259042033235\n",
      "epoch: 26\t| Cnt: 81\t| Loss: 0.0038583553472562927\t| f1 score: 0.9953033178080617\n",
      "epoch: 26\t| Cnt: 121\t| Loss: 0.0030540363499312662\t| f1 score: 0.996871945259042\n",
      "epoch: 26\t| Cnt: 161\t| Loss: 0.003941047800981323\t| f1 score: 0.9953094452590421\n",
      "epoch: 26\t| Cnt: 201\t| Loss: 0.0056773414289637\t| f1 score: 0.9953079178885631\n",
      "epoch: 26\t| Cnt: 241\t| Loss: 0.0030766465006308863\t| f1 score: 0.996871945259042\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9622149273271874\n",
      "\n",
      "epoch: 27\t| Cnt: 1\t| Loss: 0.0015730127925053239\t| f1 score: 1.0\n",
      "epoch: 27\t| Cnt: 41\t| Loss: 0.00531313526116719\t| f1 score: 0.9953079178885631\n",
      "epoch: 27\t| Cnt: 81\t| Loss: 0.006320170010076254\t| f1 score: 0.9906127630671037\n",
      "epoch: 27\t| Cnt: 121\t| Loss: 0.004105106649876689\t| f1 score: 0.9953079178885631\n",
      "epoch: 27\t| Cnt: 161\t| Loss: 0.0030772216221521377\t| f1 score: 0.9953079178885631\n",
      "epoch: 27\t| Cnt: 201\t| Loss: 0.0044615943097596755\t| f1 score: 0.9953094452590421\n",
      "epoch: 27\t| Cnt: 241\t| Loss: 0.0075874477657635\t| f1 score: 0.9945259042033235\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9550168607240568\n",
      "\n",
      "epoch: 28\t| Cnt: 1\t| Loss: 0.0002783596282824874\t| f1 score: 1.0\n",
      "epoch: 28\t| Cnt: 41\t| Loss: 0.00518316277921258\t| f1 score: 0.996871945259042\n",
      "epoch: 28\t| Cnt: 81\t| Loss: 0.0024728067357500548\t| f1 score: 0.9976493588637801\n",
      "epoch: 28\t| Cnt: 121\t| Loss: 0.004967661311093252\t| f1 score: 0.9953079178885631\n",
      "epoch: 28\t| Cnt: 161\t| Loss: 0.004411273082223488\t| f1 score: 0.9953079178885631\n",
      "epoch: 28\t| Cnt: 201\t| Loss: 0.0020923250733176245\t| f1 score: 0.9976493588637801\n",
      "epoch: 28\t| Cnt: 241\t| Loss: 0.002283446923320298\t| f1 score: 0.998435972629521\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9758432727355872\n",
      "\n",
      "epoch: 29\t| Cnt: 1\t| Loss: 0.0003849176282528788\t| f1 score: 1.0\n",
      "epoch: 29\t| Cnt: 41\t| Loss: 0.0008405797590967268\t| f1 score: 1.0\n",
      "epoch: 29\t| Cnt: 81\t| Loss: 0.004148411817004672\t| f1 score: 0.9953033178080617\n",
      "epoch: 29\t| Cnt: 121\t| Loss: 0.005353577411005972\t| f1 score: 0.9945259042033235\n",
      "epoch: 29\t| Cnt: 161\t| Loss: 0.004293449817487272\t| f1 score: 0.9945259042033235\n",
      "epoch: 29\t| Cnt: 201\t| Loss: 0.00279045831921394\t| f1 score: 0.9953033178080617\n",
      "epoch: 29\t| Cnt: 241\t| Loss: 0.005078295141356648\t| f1 score: 0.9945074132393377\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.01\n",
      "Validation took: 0:00:17\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.9836542271068276\n",
      "\n",
      "\n",
      "\n",
      "Generating Inputs for fold 3\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| Cnt: 1\t| Loss: 0.17926818132400513\t| f1 score: 0.4009852216748768\n",
      "epoch: 0\t| Cnt: 41\t| Loss: 0.15585429407656193\t| f1 score: 0.6317161125194313\n",
      "epoch: 0\t| Cnt: 81\t| Loss: 0.11846734285354614\t| f1 score: 0.771126183305467\n",
      "epoch: 0\t| Cnt: 121\t| Loss: 0.10950720477849245\t| f1 score: 0.8084993325656906\n",
      "epoch: 0\t| Cnt: 161\t| Loss: 0.0968978582881391\t| f1 score: 0.8298425149389196\n",
      "epoch: 0\t| Cnt: 201\t| Loss: 0.08875387636944651\t| f1 score: 0.8577110560813448\n",
      "epoch: 0\t| Cnt: 241\t| Loss: 0.0745837333612144\t| f1 score: 0.8768352292429504\n",
      "\n",
      "Average training loss: 0.10\n",
      "Average training score: 0.80\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.42\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.5976587356680898\n",
      "\n",
      "epoch: 1\t| Cnt: 1\t| Loss: 0.12984232604503632\t| f1 score: 0.7757757757757757\n",
      "epoch: 1\t| Cnt: 41\t| Loss: 0.07029291009530425\t| f1 score: 0.8894778785804128\n",
      "epoch: 1\t| Cnt: 81\t| Loss: 0.059599747369065884\t| f1 score: 0.8994848488153139\n",
      "epoch: 1\t| Cnt: 121\t| Loss: 0.05501357764005661\t| f1 score: 0.9173100378464589\n",
      "epoch: 1\t| Cnt: 161\t| Loss: 0.0555284399073571\t| f1 score: 0.9172513491022822\n",
      "epoch: 1\t| Cnt: 201\t| Loss: 0.05016949381679296\t| f1 score: 0.9229359047963774\n",
      "epoch: 1\t| Cnt: 241\t| Loss: 0.047965494357049464\t| f1 score: 0.9278381864678323\n",
      "\n",
      "Average training loss: 0.06\n",
      "Average training score: 0.92\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.19\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7475882940154068\n",
      "\n",
      "epoch: 2\t| Cnt: 1\t| Loss: 0.04788195341825485\t| f1 score: 0.9054187192118226\n",
      "epoch: 2\t| Cnt: 41\t| Loss: 0.03940372510114685\t| f1 score: 0.9427698369265798\n",
      "epoch: 2\t| Cnt: 81\t| Loss: 0.03498989045619964\t| f1 score: 0.952061610645638\n",
      "epoch: 2\t| Cnt: 121\t| Loss: 0.03627625710796565\t| f1 score: 0.9521479096366022\n",
      "epoch: 2\t| Cnt: 161\t| Loss: 0.035778416553512216\t| f1 score: 0.9560699210583887\n",
      "epoch: 2\t| Cnt: 201\t| Loss: 0.03484505006344989\t| f1 score: 0.9521433199650214\n",
      "epoch: 2\t| Cnt: 241\t| Loss: 0.03118883753195405\t| f1 score: 0.9577405698349721\n",
      "\n",
      "Average training loss: 0.04\n",
      "Average training score: 0.95\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.24\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.730666917407329\n",
      "\n",
      "epoch: 3\t| Cnt: 1\t| Loss: 0.03722342476248741\t| f1 score: 0.9372549019607843\n",
      "epoch: 3\t| Cnt: 41\t| Loss: 0.029566845495719463\t| f1 score: 0.9623602334300088\n",
      "epoch: 3\t| Cnt: 81\t| Loss: 0.029322656616568566\t| f1 score: 0.9607915515407296\n",
      "epoch: 3\t| Cnt: 121\t| Loss: 0.024570644553750753\t| f1 score: 0.9709836719389614\n",
      "epoch: 3\t| Cnt: 161\t| Loss: 0.025163221097318455\t| f1 score: 0.9693933901719923\n",
      "epoch: 3\t| Cnt: 201\t| Loss: 0.02784342788509093\t| f1 score: 0.9616197837841781\n",
      "epoch: 3\t| Cnt: 241\t| Loss: 0.022126181225758046\t| f1 score: 0.9718182528977817\n",
      "\n",
      "Average training loss: 0.03\n",
      "Average training score: 0.97\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.27\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7265954316356411\n",
      "\n",
      "epoch: 4\t| Cnt: 1\t| Loss: 0.054699160158634186\t| f1 score: 0.9054187192118226\n",
      "epoch: 4\t| Cnt: 41\t| Loss: 0.027089686930412426\t| f1 score: 0.9647646935075983\n",
      "epoch: 4\t| Cnt: 81\t| Loss: 0.02841668054461479\t| f1 score: 0.9647094740414115\n",
      "epoch: 4\t| Cnt: 121\t| Loss: 0.02713376609608531\t| f1 score: 0.96152510510811\n",
      "epoch: 4\t| Cnt: 161\t| Loss: 0.03313248956110328\t| f1 score: 0.9561226149120788\n",
      "epoch: 4\t| Cnt: 201\t| Loss: 0.02858999780146405\t| f1 score: 0.9645816390104958\n",
      "epoch: 4\t| Cnt: 241\t| Loss: 0.021710179024375977\t| f1 score: 0.9733638072733392\n",
      "\n",
      "Average training loss: 0.03\n",
      "Average training score: 0.97\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.15\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8010907716891027\n",
      "\n",
      "epoch: 5\t| Cnt: 1\t| Loss: 0.009396201930940151\t| f1 score: 1.0\n",
      "epoch: 5\t| Cnt: 41\t| Loss: 0.019204752671066673\t| f1 score: 0.9749371254468013\n",
      "epoch: 5\t| Cnt: 81\t| Loss: 0.02727512050187215\t| f1 score: 0.9631265531585946\n",
      "epoch: 5\t| Cnt: 121\t| Loss: 0.018234944343566893\t| f1 score: 0.9757191391320408\n",
      "epoch: 5\t| Cnt: 161\t| Loss: 0.021575525775551795\t| f1 score: 0.9726080479845898\n",
      "epoch: 5\t| Cnt: 201\t| Loss: 0.01776300321216695\t| f1 score: 0.9804250214849819\n",
      "epoch: 5\t| Cnt: 241\t| Loss: 0.020807930955197663\t| f1 score: 0.9804312575470071\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.97\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.15\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.808163938326929\n",
      "\n",
      "epoch: 6\t| Cnt: 1\t| Loss: 0.022675693035125732\t| f1 score: 0.9687194525904204\n",
      "epoch: 6\t| Cnt: 41\t| Loss: 0.016897423681803046\t| f1 score: 0.9812039804292635\n",
      "epoch: 6\t| Cnt: 81\t| Loss: 0.023541256948374212\t| f1 score: 0.965560706687367\n",
      "epoch: 6\t| Cnt: 121\t| Loss: 0.019445514198741874\t| f1 score: 0.9788471032310184\n",
      "epoch: 6\t| Cnt: 161\t| Loss: 0.01701601061504334\t| f1 score: 0.9812255261342073\n",
      "epoch: 6\t| Cnt: 201\t| Loss: 0.01648707608692348\t| f1 score: 0.9803801090328605\n",
      "epoch: 6\t| Cnt: 241\t| Loss: 0.019070824212394654\t| f1 score: 0.9757330300155254\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.14\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8182332373508844\n",
      "\n",
      "epoch: 7\t| Cnt: 1\t| Loss: 0.0024195914156734943\t| f1 score: 1.0\n",
      "epoch: 7\t| Cnt: 41\t| Loss: 0.020383003423921763\t| f1 score: 0.9741350934270969\n",
      "epoch: 7\t| Cnt: 81\t| Loss: 0.018152937956620006\t| f1 score: 0.9772955300155253\n",
      "epoch: 7\t| Cnt: 121\t| Loss: 0.014476125553483144\t| f1 score: 0.9843320351702214\n",
      "epoch: 7\t| Cnt: 161\t| Loss: 0.009584256410016678\t| f1 score: 0.9898353494623656\n",
      "epoch: 7\t| Cnt: 201\t| Loss: 0.018243954490753823\t| f1 score: 0.9788779577080099\n",
      "epoch: 7\t| Cnt: 241\t| Loss: 0.017552972910925745\t| f1 score: 0.9804265488554609\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.10\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.848997775833725\n",
      "\n",
      "epoch: 8\t| Cnt: 1\t| Loss: 0.00457106065005064\t| f1 score: 1.0\n",
      "epoch: 8\t| Cnt: 41\t| Loss: 0.019402553464169615\t| f1 score: 0.9804311489359623\n",
      "epoch: 8\t| Cnt: 81\t| Loss: 0.015718952217139304\t| f1 score: 0.9804188940340015\n",
      "epoch: 8\t| Cnt: 121\t| Loss: 0.01957453736104071\t| f1 score: 0.9772847118420632\n",
      "epoch: 8\t| Cnt: 161\t| Loss: 0.013522807264234871\t| f1 score: 0.9867011672704272\n",
      "epoch: 8\t| Cnt: 201\t| Loss: 0.019996717365575022\t| f1 score: 0.9765089162497844\n",
      "epoch: 8\t| Cnt: 241\t| Loss: 0.017917756567476316\t| f1 score: 0.9780821437812662\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.18\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7897419239639826\n",
      "\n",
      "epoch: 9\t| Cnt: 1\t| Loss: 0.003737706458196044\t| f1 score: 1.0\n",
      "epoch: 9\t| Cnt: 41\t| Loss: 0.009899621875956655\t| f1 score: 0.9867011672704272\n",
      "epoch: 9\t| Cnt: 81\t| Loss: 0.019679392541002018\t| f1 score: 0.9725941571011052\n",
      "epoch: 9\t| Cnt: 121\t| Loss: 0.013962631658068858\t| f1 score: 0.9827588076387397\n",
      "epoch: 9\t| Cnt: 161\t| Loss: 0.015040875590057113\t| f1 score: 0.9820090671899259\n",
      "epoch: 9\t| Cnt: 201\t| Loss: 0.011464386901934631\t| f1 score: 0.9866965671899258\n",
      "epoch: 9\t| Cnt: 241\t| Loss: 0.018961843830766156\t| f1 score: 0.9772970573860043\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.08\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8766596628282706\n",
      "\n",
      "epoch: 10\t| Cnt: 1\t| Loss: 0.020050350576639175\t| f1 score: 0.9687194525904204\n",
      "epoch: 10\t| Cnt: 41\t| Loss: 0.010775722452672198\t| f1 score: 0.9882697947214076\n",
      "epoch: 10\t| Cnt: 81\t| Loss: 0.01093745666439645\t| f1 score: 0.9874692900721822\n",
      "epoch: 10\t| Cnt: 121\t| Loss: 0.016579028783598914\t| f1 score: 0.9827649350897201\n",
      "epoch: 10\t| Cnt: 161\t| Loss: 0.014713348404620774\t| f1 score: 0.9827926262147088\n",
      "epoch: 10\t| Cnt: 201\t| Loss: 0.01416275852243416\t| f1 score: 0.9843551262147088\n",
      "epoch: 10\t| Cnt: 241\t| Loss: 0.012789306425838731\t| f1 score: 0.985124867028923\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.892639325200147\n",
      "\n",
      "epoch: 11\t| Cnt: 1\t| Loss: 0.005635935813188553\t| f1 score: 1.0\n",
      "epoch: 11\t| Cnt: 41\t| Loss: 0.009092294992296957\t| f1 score: 0.9913762857883572\n",
      "epoch: 11\t| Cnt: 81\t| Loss: 0.01704047473613173\t| f1 score: 0.9804158213239791\n",
      "epoch: 11\t| Cnt: 121\t| Loss: 0.011688498624425846\t| f1 score: 0.9858960625407004\n",
      "epoch: 11\t| Cnt: 161\t| Loss: 0.012883696175413207\t| f1 score: 0.9835454214044805\n",
      "epoch: 11\t| Cnt: 201\t| Loss: 0.014378314666100778\t| f1 score: 0.9804188940340015\n",
      "epoch: 11\t| Cnt: 241\t| Loss: 0.010281427277368494\t| f1 score: 0.9906127630671037\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.916740076324069\n",
      "\n",
      "epoch: 12\t| Cnt: 1\t| Loss: 0.009138944558799267\t| f1 score: 0.9687194525904204\n",
      "epoch: 12\t| Cnt: 41\t| Loss: 0.01336148563568713\t| f1 score: 0.984345926053706\n",
      "epoch: 12\t| Cnt: 81\t| Loss: 0.00875922488339711\t| f1 score: 0.9874847083261458\n",
      "epoch: 12\t| Cnt: 121\t| Loss: 0.011060390758211724\t| f1 score: 0.9890426082456443\n",
      "epoch: 12\t| Cnt: 161\t| Loss: 0.011276963372074534\t| f1 score: 0.9898353494623656\n",
      "epoch: 12\t| Cnt: 201\t| Loss: 0.012085798956104555\t| f1 score: 0.9851294671094244\n",
      "epoch: 12\t| Cnt: 241\t| Loss: 0.007597899084794335\t| f1 score: 0.9890487356966247\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8887763982877745\n",
      "\n",
      "epoch: 13\t| Cnt: 1\t| Loss: 0.00141667271964252\t| f1 score: 1.0\n",
      "epoch: 13\t| Cnt: 41\t| Loss: 0.009578101031365804\t| f1 score: 0.9882605945604048\n",
      "epoch: 13\t| Cnt: 81\t| Loss: 0.014599640884262044\t| f1 score: 0.9866934944799034\n",
      "epoch: 13\t| Cnt: 121\t| Loss: 0.01144480990478769\t| f1 score: 0.9874723448131402\n",
      "epoch: 13\t| Cnt: 161\t| Loss: 0.007894170423969626\t| f1 score: 0.9929618768328445\n",
      "epoch: 13\t| Cnt: 201\t| Loss: 0.012389692233409733\t| f1 score: 0.9859021899916808\n",
      "epoch: 13\t| Cnt: 241\t| Loss: 0.006368909258162603\t| f1 score: 0.9945167040423207\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "epoch: 14\t| Cnt: 41\t| Loss: 0.010546577301283833\t| f1 score: 0.9890472083261457\n",
      "epoch: 14\t| Cnt: 81\t| Loss: 0.006335573043907061\t| f1 score: 0.9929572767523431\n",
      "epoch: 14\t| Cnt: 121\t| Loss: 0.008118059518164956\t| f1 score: 0.9913947767523432\n",
      "epoch: 14\t| Cnt: 161\t| Loss: 0.008760006865486503\t| f1 score: 0.9913793584983797\n",
      "epoch: 14\t| Cnt: 201\t| Loss: 0.01228760951780714\t| f1 score: 0.9851340671899258\n",
      "epoch: 14\t| Cnt: 241\t| Loss: 0.011688895438419422\t| f1 score: 0.9882697947214076\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.06\n",
      "Validation took: 0:00:16\n",
      "\n",
      "valid score: 0.9149309484043604\n",
      "\n",
      "epoch: 15\t| Cnt: 1\t| Loss: 0.0018757542129606009\t| f1 score: 1.0\n",
      "epoch: 15\t| Cnt: 41\t| Loss: 0.008261185683659278\t| f1 score: 0.9913978494623656\n",
      "epoch: 15\t| Cnt: 81\t| Loss: 0.004911687565618194\t| f1 score: 0.9953079178885631\n",
      "epoch: 15\t| Cnt: 121\t| Loss: 0.008168487505463418\t| f1 score: 0.9929588041228221\n",
      "epoch: 15\t| Cnt: 161\t| Loss: 0.008686473097623094\t| f1 score: 0.9906127630671037\n",
      "epoch: 15\t| Cnt: 201\t| Loss: 0.007787238229502691\t| f1 score: 0.9906112356966247\n",
      "epoch: 15\t| Cnt: 241\t| Loss: 0.004805233461229364\t| f1 score: 0.9937438905180841\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9441631035067076\n",
      "\n",
      "epoch: 16\t| Cnt: 1\t| Loss: 0.00121320690959692\t| f1 score: 1.0\n",
      "epoch: 16\t| Cnt: 41\t| Loss: 0.005348291875270661\t| f1 score: 0.9953079178885631\n",
      "epoch: 16\t| Cnt: 81\t| Loss: 0.006656344806833659\t| f1 score: 0.9937454178885631\n",
      "epoch: 16\t| Cnt: 121\t| Loss: 0.013788046660192777\t| f1 score: 0.9866996219308838\n",
      "epoch: 16\t| Cnt: 161\t| Loss: 0.011074702531914227\t| f1 score: 0.9890441356161233\n",
      "epoch: 16\t| Cnt: 201\t| Loss: 0.012559539443464019\t| f1 score: 0.9858868623796976\n",
      "epoch: 16\t| Cnt: 241\t| Loss: 0.010591589182149619\t| f1 score: 0.9890333174426612\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9211001395656793\n",
      "\n",
      "epoch: 17\t| Cnt: 1\t| Loss: 0.010384170338511467\t| f1 score: 0.9687194525904204\n",
      "epoch: 17\t| Cnt: 41\t| Loss: 0.0052913052044459615\t| f1 score: 0.9945259042033235\n",
      "epoch: 17\t| Cnt: 81\t| Loss: 0.010067443519074005\t| f1 score: 0.9898292220113852\n",
      "epoch: 17\t| Cnt: 121\t| Loss: 0.0051174255095247645\t| f1 score: 0.9945213041228221\n",
      "epoch: 17\t| Cnt: 161\t| Loss: 0.012363731441291747\t| f1 score: 0.9866980945604048\n",
      "epoch: 17\t| Cnt: 201\t| Loss: 0.009578976022748976\t| f1 score: 0.9906158357771261\n",
      "epoch: 17\t| Cnt: 241\t| Loss: 0.01261232626857236\t| f1 score: 0.9851155762259399\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8980597707037716\n",
      "\n",
      "epoch: 18\t| Cnt: 1\t| Loss: 0.0007655874360352755\t| f1 score: 1.0\n",
      "epoch: 18\t| Cnt: 41\t| Loss: 0.01415670891510672\t| f1 score: 0.9859206809556668\n",
      "epoch: 18\t| Cnt: 81\t| Loss: 0.006087307406414766\t| f1 score: 0.9929588041228221\n",
      "epoch: 18\t| Cnt: 121\t| Loss: 0.00684152971371077\t| f1 score: 0.9929618768328445\n",
      "epoch: 18\t| Cnt: 161\t| Loss: 0.005240938073256984\t| f1 score: 0.9929618768328445\n",
      "epoch: 18\t| Cnt: 201\t| Loss: 0.009233637699799147\t| f1 score: 0.9890349354551204\n",
      "epoch: 18\t| Cnt: 241\t| Loss: 0.009119819402258145\t| f1 score: 0.9898353494623656\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9061785331078348\n",
      "\n",
      "epoch: 19\t| Cnt: 1\t| Loss: 0.041856300085783005\t| f1 score: 0.9687194525904204\n",
      "epoch: 19\t| Cnt: 41\t| Loss: 0.008033330999751342\t| f1 score: 0.9913886493013628\n",
      "epoch: 19\t| Cnt: 81\t| Loss: 0.004721682814124506\t| f1 score: 0.9953079178885631\n",
      "epoch: 19\t| Cnt: 121\t| Loss: 0.006851988640846685\t| f1 score: 0.9921798631476051\n",
      "epoch: 19\t| Cnt: 161\t| Loss: 0.005227346842730185\t| f1 score: 0.9945274315738025\n",
      "epoch: 19\t| Cnt: 201\t| Loss: 0.006754860173532507\t| f1 score: 0.9906050902765798\n",
      "epoch: 19\t| Cnt: 241\t| Loss: 0.008674490584235172\t| f1 score: 0.9898292220113852\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9335145159321794\n",
      "\n",
      "epoch: 20\t| Cnt: 1\t| Loss: 0.002130052074790001\t| f1 score: 1.0\n",
      "epoch: 20\t| Cnt: 41\t| Loss: 0.008071926890261238\t| f1 score: 0.9890533357771261\n",
      "epoch: 20\t| Cnt: 81\t| Loss: 0.007028231468575541\t| f1 score: 0.9921767904375827\n",
      "epoch: 20\t| Cnt: 121\t| Loss: 0.0022392445738660172\t| f1 score: 0.9968673451785406\n",
      "epoch: 20\t| Cnt: 161\t| Loss: 0.009111862543068127\t| f1 score: 0.9913947767523432\n",
      "epoch: 20\t| Cnt: 201\t| Loss: 0.009664441995846573\t| f1 score: 0.9906112356966247\n",
      "epoch: 20\t| Cnt: 241\t| Loss: 0.004648728777829092\t| f1 score: 0.9960899315738025\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9283587424227955\n",
      "\n",
      "epoch: 21\t| Cnt: 1\t| Loss: 0.0010188375599682331\t| f1 score: 1.0\n",
      "epoch: 21\t| Cnt: 41\t| Loss: 0.008093072974588722\t| f1 score: 0.9921706629866023\n",
      "epoch: 21\t| Cnt: 81\t| Loss: 0.0053827684532734565\t| f1 score: 0.9921752630671037\n",
      "epoch: 21\t| Cnt: 121\t| Loss: 0.004607881110132439\t| f1 score: 0.9945259042033235\n",
      "epoch: 21\t| Cnt: 161\t| Loss: 0.005586439302715007\t| f1 score: 0.9960914589442815\n",
      "epoch: 21\t| Cnt: 201\t| Loss: 0.007577155688341009\t| f1 score: 0.9921752630671037\n",
      "epoch: 21\t| Cnt: 241\t| Loss: 0.007242481123830658\t| f1 score: 0.9929618768328445\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9211001395656793\n",
      "\n",
      "epoch: 22\t| Cnt: 1\t| Loss: 0.004267352167516947\t| f1 score: 1.0\n",
      "epoch: 22\t| Cnt: 41\t| Loss: 0.004844589396816446\t| f1 score: 0.9960899315738025\n",
      "epoch: 22\t| Cnt: 81\t| Loss: 0.004976571477891411\t| f1 score: 0.9929618768328445\n",
      "epoch: 22\t| Cnt: 121\t| Loss: 0.006904907336138422\t| f1 score: 0.9937438905180841\n",
      "epoch: 22\t| Cnt: 161\t| Loss: 0.013102982233976945\t| f1 score: 0.9874785808751654\n",
      "epoch: 22\t| Cnt: 201\t| Loss: 0.0061379049948300235\t| f1 score: 0.9945259042033235\n",
      "epoch: 22\t| Cnt: 241\t| Loss: 0.006668952901964076\t| f1 score: 0.9937438905180841\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9370131635595386\n",
      "\n",
      "epoch: 23\t| Cnt: 1\t| Loss: 0.0005560736171901226\t| f1 score: 1.0\n",
      "epoch: 23\t| Cnt: 41\t| Loss: 0.002747477735101711\t| f1 score: 0.996871945259042\n",
      "epoch: 23\t| Cnt: 81\t| Loss: 0.005384086485719308\t| f1 score: 0.9953079178885631\n",
      "epoch: 23\t| Cnt: 121\t| Loss: 0.004934340663749026\t| f1 score: 0.9929618768328445\n",
      "epoch: 23\t| Cnt: 161\t| Loss: 0.008911342907958896\t| f1 score: 0.9898292220113852\n",
      "epoch: 23\t| Cnt: 201\t| Loss: 0.005676252667035442\t| f1 score: 0.9937438905180841\n",
      "epoch: 23\t| Cnt: 241\t| Loss: 0.009369376655013185\t| f1 score: 0.9913978494623656\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9578279405987438\n",
      "\n",
      "epoch: 24\t| Cnt: 1\t| Loss: 0.03681308031082153\t| f1 score: 0.9687194525904204\n",
      "epoch: 24\t| Cnt: 41\t| Loss: 0.0065606218588072805\t| f1 score: 0.9929572767523431\n",
      "epoch: 24\t| Cnt: 81\t| Loss: 0.003338905593409436\t| f1 score: 0.9960899315738025\n",
      "epoch: 24\t| Cnt: 121\t| Loss: 0.006352566181158181\t| f1 score: 0.9945259042033235\n",
      "epoch: 24\t| Cnt: 161\t| Loss: 0.0077835320618760305\t| f1 score: 0.9929572767523431\n",
      "epoch: 24\t| Cnt: 201\t| Loss: 0.007312214767443948\t| f1 score: 0.9898338220918866\n",
      "epoch: 24\t| Cnt: 241\t| Loss: 0.006315090358111774\t| f1 score: 0.9929526766718417\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9465929324299827\n",
      "\n",
      "epoch: 25\t| Cnt: 1\t| Loss: 0.0005508704925887287\t| f1 score: 1.0\n",
      "epoch: 25\t| Cnt: 41\t| Loss: 0.002930311679665465\t| f1 score: 0.9976539589442815\n",
      "epoch: 25\t| Cnt: 81\t| Loss: 0.0058727201409055855\t| f1 score: 0.9945167040423207\n",
      "epoch: 25\t| Cnt: 121\t| Loss: 0.004762332223617704\t| f1 score: 0.9960899315738025\n",
      "epoch: 25\t| Cnt: 161\t| Loss: 0.0025257109911763108\t| f1 score: 0.9976539589442815\n",
      "epoch: 25\t| Cnt: 201\t| Loss: 0.004614953269629041\t| f1 score: 0.9968673451785406\n",
      "epoch: 25\t| Cnt: 241\t| Loss: 0.005087663465383229\t| f1 score: 0.9953033178080617\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9484309437371474\n",
      "\n",
      "epoch: 26\t| Cnt: 1\t| Loss: 0.000770108075812459\t| f1 score: 1.0\n",
      "epoch: 26\t| Cnt: 41\t| Loss: 0.003970293476595543\t| f1 score: 0.9960899315738025\n",
      "epoch: 26\t| Cnt: 81\t| Loss: 0.002662657316977857\t| f1 score: 0.996871945259042\n",
      "epoch: 26\t| Cnt: 121\t| Loss: 0.007267914750264027\t| f1 score: 0.9921767904375827\n",
      "epoch: 26\t| Cnt: 161\t| Loss: 0.004971313297573943\t| f1 score: 0.9937346903570813\n",
      "epoch: 26\t| Cnt: 201\t| Loss: 0.003506247088080272\t| f1 score: 0.9976539589442815\n",
      "epoch: 26\t| Cnt: 241\t| Loss: 0.003511092952612671\t| f1 score: 0.9976539589442815\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9675852172962565\n",
      "\n",
      "epoch: 27\t| Cnt: 1\t| Loss: 0.00183086225297302\t| f1 score: 1.0\n",
      "epoch: 27\t| Cnt: 41\t| Loss: 0.0038598687293415423\t| f1 score: 0.9960914589442815\n",
      "epoch: 27\t| Cnt: 81\t| Loss: 0.0035194433090509846\t| f1 score: 0.9953079178885631\n",
      "epoch: 27\t| Cnt: 121\t| Loss: 0.004183272895170375\t| f1 score: 0.9953079178885631\n",
      "epoch: 27\t| Cnt: 161\t| Loss: 0.007177176012919517\t| f1 score: 0.9921798631476051\n",
      "epoch: 27\t| Cnt: 201\t| Loss: 0.002943922735721571\t| f1 score: 0.9976539589442815\n",
      "epoch: 27\t| Cnt: 241\t| Loss: 0.004607070433121407\t| f1 score: 0.9953094452590421\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:16\n",
      "\n",
      "valid score: 0.9702508152623117\n",
      "\n",
      "epoch: 28\t| Cnt: 1\t| Loss: 0.001137942192144692\t| f1 score: 1.0\n",
      "epoch: 28\t| Cnt: 41\t| Loss: 0.0016037569355830783\t| f1 score: 0.9976539589442815\n",
      "epoch: 28\t| Cnt: 81\t| Loss: 0.002026944063436531\t| f1 score: 0.996871945259042\n",
      "epoch: 28\t| Cnt: 121\t| Loss: 0.002713482475519413\t| f1 score: 0.9960899315738025\n",
      "epoch: 28\t| Cnt: 161\t| Loss: 0.007511488669479149\t| f1 score: 0.9945213041228221\n",
      "epoch: 28\t| Cnt: 201\t| Loss: 0.005158388413474313\t| f1 score: 0.9953033178080617\n",
      "epoch: 28\t| Cnt: 241\t| Loss: 0.003065888817218365\t| f1 score: 0.9960899315738025\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:16\n",
      "\n",
      "valid score: 0.9756654018056747\n",
      "\n",
      "epoch: 29\t| Cnt: 1\t| Loss: 0.00575973279774189\t| f1 score: 0.9687194525904204\n",
      "epoch: 29\t| Cnt: 41\t| Loss: 0.0029335011269722598\t| f1 score: 0.996871945259042\n",
      "epoch: 29\t| Cnt: 81\t| Loss: 0.0027635371749056502\t| f1 score: 0.9976539589442815\n",
      "epoch: 29\t| Cnt: 121\t| Loss: 0.004111929136706749\t| f1 score: 0.9960899315738025\n",
      "epoch: 29\t| Cnt: 161\t| Loss: 0.00411004537527333\t| f1 score: 0.9960914589442815\n",
      "epoch: 29\t| Cnt: 201\t| Loss: 0.0030893021419615254\t| f1 score: 0.996871945259042\n",
      "epoch: 29\t| Cnt: 241\t| Loss: 0.0025911098382493947\t| f1 score: 0.996871945259042\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.972944058270411\n",
      "\n",
      "\n",
      "\n",
      "Generating Inputs for fold 4\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| Cnt: 1\t| Loss: 0.16859598457813263\t| f1 score: 0.6532019704433498\n",
      "epoch: 0\t| Cnt: 41\t| Loss: 0.15945880003273488\t| f1 score: 0.6334720014368387\n",
      "epoch: 0\t| Cnt: 81\t| Loss: 0.11878691464662552\t| f1 score: 0.7800438785072534\n",
      "epoch: 0\t| Cnt: 121\t| Loss: 0.10137451840564608\t| f1 score: 0.8162094710565653\n",
      "epoch: 0\t| Cnt: 161\t| Loss: 0.09981902819126845\t| f1 score: 0.8348490938233482\n",
      "epoch: 0\t| Cnt: 201\t| Loss: 0.09747067606076598\t| f1 score: 0.8299643141968034\n",
      "epoch: 0\t| Cnt: 241\t| Loss: 0.09397750645875931\t| f1 score: 0.8345394822754209\n",
      "Validation Loss: 0.35\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.6279541169582401\n",
      "\n",
      "epoch: 1\t| Cnt: 1\t| Loss: 0.08592928946018219\t| f1 score: 0.8745098039215686\n",
      "epoch: 1\t| Cnt: 41\t| Loss: 0.07225548941642046\t| f1 score: 0.8819098793850129\n",
      "epoch: 1\t| Cnt: 81\t| Loss: 0.07050918005406856\t| f1 score: 0.8808479438961083\n",
      "epoch: 1\t| Cnt: 121\t| Loss: 0.06258681304752826\t| f1 score: 0.9009827604670118\n",
      "epoch: 1\t| Cnt: 161\t| Loss: 0.05171742797829211\t| f1 score: 0.9159866663928161\n",
      "epoch: 1\t| Cnt: 201\t| Loss: 0.05468303561210632\t| f1 score: 0.9158937706669255\n",
      "epoch: 1\t| Cnt: 241\t| Loss: 0.05226602884940803\t| f1 score: 0.9214058721627996\n",
      "\n",
      "Average training loss: 0.06\n",
      "Average training score: 0.90\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.36\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.6399317699598249\n",
      "\n",
      "epoch: 2\t| Cnt: 1\t| Loss: 0.03469894081354141\t| f1 score: 0.9687194525904204\n",
      "epoch: 2\t| Cnt: 41\t| Loss: 0.04778643948957324\t| f1 score: 0.9269876784199684\n",
      "epoch: 2\t| Cnt: 81\t| Loss: 0.042644756566733125\t| f1 score: 0.9332419306559693\n",
      "epoch: 2\t| Cnt: 121\t| Loss: 0.04422622362617403\t| f1 score: 0.9364270879037899\n",
      "epoch: 2\t| Cnt: 161\t| Loss: 0.03864650335162878\t| f1 score: 0.945873255017954\n",
      "epoch: 2\t| Cnt: 201\t| Loss: 0.0300346254138276\t| f1 score: 0.9576742787695522\n",
      "epoch: 2\t| Cnt: 241\t| Loss: 0.03814534035045654\t| f1 score: 0.9505853114344781\n",
      "\n",
      "Average training loss: 0.04\n",
      "Average training score: 0.94\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.27\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.6876038587470626\n",
      "\n",
      "epoch: 3\t| Cnt: 1\t| Loss: 0.029225699603557587\t| f1 score: 0.9687194525904204\n",
      "epoch: 3\t| Cnt: 41\t| Loss: 0.03219079448608682\t| f1 score: 0.9536545703999739\n",
      "epoch: 3\t| Cnt: 81\t| Loss: 0.032638961216434836\t| f1 score: 0.9584718193198001\n",
      "epoch: 3\t| Cnt: 121\t| Loss: 0.03464324045926333\t| f1 score: 0.954477854187315\n",
      "epoch: 3\t| Cnt: 161\t| Loss: 0.03388798389933072\t| f1 score: 0.9496686730462208\n",
      "epoch: 3\t| Cnt: 201\t| Loss: 0.025341472774744033\t| f1 score: 0.9631992473776851\n",
      "epoch: 3\t| Cnt: 241\t| Loss: 0.02495434262091294\t| f1 score: 0.967885292680122\n",
      "\n",
      "Average training loss: 0.03\n",
      "Average training score: 0.96\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.18\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7681603615212202\n",
      "\n",
      "epoch: 4\t| Cnt: 1\t| Loss: 0.022211868315935135\t| f1 score: 0.9687194525904204\n",
      "epoch: 4\t| Cnt: 41\t| Loss: 0.022236582811456174\t| f1 score: 0.9726203028865505\n",
      "epoch: 4\t| Cnt: 81\t| Loss: 0.02872285253251903\t| f1 score: 0.9645350005789506\n",
      "epoch: 4\t| Cnt: 121\t| Loss: 0.03200235496042296\t| f1 score: 0.9544405059146726\n",
      "epoch: 4\t| Cnt: 161\t| Loss: 0.030394470668397844\t| f1 score: 0.9599214178222922\n",
      "epoch: 4\t| Cnt: 201\t| Loss: 0.02406650279299356\t| f1 score: 0.967892856859601\n",
      "epoch: 4\t| Cnt: 241\t| Loss: 0.029472357517806812\t| f1 score: 0.9615673836022427\n",
      "\n",
      "Average training loss: 0.03\n",
      "Average training score: 0.96\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.11\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8154661198787128\n",
      "\n",
      "epoch: 5\t| Cnt: 1\t| Loss: 0.03098883293569088\t| f1 score: 0.9687194525904204\n",
      "epoch: 5\t| Cnt: 41\t| Loss: 0.030606968054780737\t| f1 score: 0.9599675353296002\n",
      "epoch: 5\t| Cnt: 81\t| Loss: 0.025294425821630283\t| f1 score: 0.9671385342993503\n",
      "epoch: 5\t| Cnt: 121\t| Loss: 0.024238202464766802\t| f1 score: 0.9671000250008994\n",
      "epoch: 5\t| Cnt: 161\t| Loss: 0.02151792438235134\t| f1 score: 0.9733250222721981\n",
      "epoch: 5\t| Cnt: 201\t| Loss: 0.021304104977753015\t| f1 score: 0.9757191391320408\n",
      "epoch: 5\t| Cnt: 241\t| Loss: 0.022505295323207976\t| f1 score: 0.9741535843910828\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.97\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.18\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7910563089930569\n",
      "\n",
      "epoch: 6\t| Cnt: 1\t| Loss: 0.022238796576857567\t| f1 score: 0.9687194525904204\n",
      "epoch: 6\t| Cnt: 41\t| Loss: 0.027984914754051717\t| f1 score: 0.9702265523713784\n",
      "epoch: 6\t| Cnt: 81\t| Loss: 0.020524398487759755\t| f1 score: 0.9718168341383475\n",
      "epoch: 6\t| Cnt: 121\t| Loss: 0.02169611743884161\t| f1 score: 0.9733638979153195\n",
      "epoch: 6\t| Cnt: 161\t| Loss: 0.019605731044430287\t| f1 score: 0.9780852164912887\n",
      "epoch: 6\t| Cnt: 201\t| Loss: 0.017854685703059658\t| f1 score: 0.9773047301765281\n",
      "epoch: 6\t| Cnt: 241\t| Loss: 0.019913725642254576\t| f1 score: 0.9788517033115198\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.10\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8514650159444757\n",
      "\n",
      "epoch: 7\t| Cnt: 1\t| Loss: 0.005899163894355297\t| f1 score: 1.0\n",
      "epoch: 7\t| Cnt: 41\t| Loss: 0.01951799656962976\t| f1 score: 0.9749078163093532\n",
      "epoch: 7\t| Cnt: 81\t| Loss: 0.01732601445692126\t| f1 score: 0.9780636528172802\n",
      "epoch: 7\t| Cnt: 121\t| Loss: 0.017383162456098944\t| f1 score: 0.9812040710712437\n",
      "epoch: 7\t| Cnt: 161\t| Loss: 0.012203648500144482\t| f1 score: 0.9827941535851877\n",
      "epoch: 7\t| Cnt: 201\t| Loss: 0.01758700541977305\t| f1 score: 0.9773047301765281\n",
      "epoch: 7\t| Cnt: 241\t| Loss: 0.016737662273226307\t| f1 score: 0.9796492438617677\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.09\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8482807031388468\n",
      "\n",
      "epoch: 8\t| Cnt: 1\t| Loss: 0.008036413230001926\t| f1 score: 1.0\n",
      "epoch: 8\t| Cnt: 41\t| Loss: 0.01889897795044817\t| f1 score: 0.9796460805097649\n",
      "epoch: 8\t| Cnt: 81\t| Loss: 0.01644269020180218\t| f1 score: 0.9796322802682607\n",
      "epoch: 8\t| Cnt: 121\t| Loss: 0.01663877893006429\t| f1 score: 0.9780682528977817\n",
      "epoch: 8\t| Cnt: 161\t| Loss: 0.01473707459808793\t| f1 score: 0.9804281848369847\n",
      "epoch: 8\t| Cnt: 201\t| Loss: 0.015570127847604453\t| f1 score: 0.9843520535046864\n",
      "epoch: 8\t| Cnt: 241\t| Loss: 0.022888927356689237\t| f1 score: 0.9717691246788938\n",
      "\n",
      "Average training loss: 0.02\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.14\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8075194565206592\n",
      "\n",
      "epoch: 9\t| Cnt: 1\t| Loss: 0.002290019067004323\t| f1 score: 1.0\n",
      "epoch: 9\t| Cnt: 41\t| Loss: 0.013036842067958788\t| f1 score: 0.9843566535851878\n",
      "epoch: 9\t| Cnt: 81\t| Loss: 0.013549741811584682\t| f1 score: 0.9843055050710412\n",
      "epoch: 9\t| Cnt: 121\t| Loss: 0.015483244886854663\t| f1 score: 0.978091343942269\n",
      "epoch: 9\t| Cnt: 161\t| Loss: 0.011801658652257175\t| f1 score: 0.9866734761454385\n",
      "epoch: 9\t| Cnt: 201\t| Loss: 0.011671436074539087\t| f1 score: 0.9843366352507228\n",
      "epoch: 9\t| Cnt: 241\t| Loss: 0.01323189271352021\t| f1 score: 0.9835515488554609\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.10\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8567429105977151\n",
      "\n",
      "epoch: 10\t| Cnt: 1\t| Loss: 0.006835979875177145\t| f1 score: 1.0\n",
      "epoch: 10\t| Cnt: 41\t| Loss: 0.015576453803805634\t| f1 score: 0.9796414804292635\n",
      "epoch: 10\t| Cnt: 81\t| Loss: 0.016657016889075747\t| f1 score: 0.9827834260537059\n",
      "epoch: 10\t| Cnt: 121\t| Loss: 0.011799605858686845\t| f1 score: 0.9843505261342074\n",
      "epoch: 10\t| Cnt: 161\t| Loss: 0.015166550644789823\t| f1 score: 0.9820044850784889\n",
      "epoch: 10\t| Cnt: 201\t| Loss: 0.015430993726477027\t| f1 score: 0.9835700398194469\n",
      "epoch: 10\t| Cnt: 241\t| Loss: 0.010476421104976907\t| f1 score: 0.9874847083261458\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.98\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.09\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8672702375540134\n",
      "\n",
      "epoch: 11\t| Cnt: 1\t| Loss: 0.004416967276483774\t| f1 score: 1.0\n",
      "epoch: 11\t| Cnt: 41\t| Loss: 0.013812707923352718\t| f1 score: 0.9859130081651429\n",
      "epoch: 11\t| Cnt: 81\t| Loss: 0.008041708270320668\t| f1 score: 0.9913947767523432\n",
      "epoch: 11\t| Cnt: 121\t| Loss: 0.010654084339330438\t| f1 score: 0.9874831809556668\n",
      "epoch: 11\t| Cnt: 161\t| Loss: 0.011199394703726284\t| f1 score: 0.9835700398194469\n",
      "epoch: 11\t| Cnt: 201\t| Loss: 0.01571205494401511\t| f1 score: 0.9812224534241849\n",
      "epoch: 11\t| Cnt: 241\t| Loss: 0.007808282933547161\t| f1 score: 0.9906158357771261\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.08\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8694380776300534\n",
      "\n",
      "epoch: 12\t| Cnt: 1\t| Loss: 0.010980095714330673\t| f1 score: 1.0\n",
      "epoch: 12\t| Cnt: 41\t| Loss: 0.01228182050108444\t| f1 score: 0.9859145535046864\n",
      "epoch: 12\t| Cnt: 81\t| Loss: 0.010300664429087192\t| f1 score: 0.9866965671899258\n",
      "epoch: 12\t| Cnt: 121\t| Loss: 0.01198048688675044\t| f1 score: 0.9859206809556668\n",
      "epoch: 12\t| Cnt: 161\t| Loss: 0.00768290159467142\t| f1 score: 0.9898307493818642\n",
      "epoch: 12\t| Cnt: 201\t| Loss: 0.011037670643418096\t| f1 score: 0.9890380081651429\n",
      "epoch: 12\t| Cnt: 241\t| Loss: 0.012743473312002606\t| f1 score: 0.987473980794664\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.07\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8796936297403325\n",
      "\n",
      "epoch: 13\t| Cnt: 1\t| Loss: 0.0008199014700949192\t| f1 score: 1.0\n",
      "epoch: 13\t| Cnt: 41\t| Loss: 0.007791309598542284\t| f1 score: 0.9921798631476051\n",
      "epoch: 13\t| Cnt: 81\t| Loss: 0.005598556375480257\t| f1 score: 0.9953079178885631\n",
      "epoch: 13\t| Cnt: 121\t| Loss: 0.01345252772589447\t| f1 score: 0.9843367258927032\n",
      "epoch: 13\t| Cnt: 161\t| Loss: 0.011422753747319802\t| f1 score: 0.985123339658444\n",
      "epoch: 13\t| Cnt: 201\t| Loss: 0.01606890337425284\t| f1 score: 0.9827680077997425\n",
      "epoch: 13\t| Cnt: 241\t| Loss: 0.014684747143473943\t| f1 score: 0.9796492438617677\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9216448446554375\n",
      "\n",
      "epoch: 14\t| Cnt: 1\t| Loss: 0.00696165394037962\t| f1 score: 1.0\n",
      "epoch: 14\t| Cnt: 41\t| Loss: 0.009156475083727855\t| f1 score: 0.9906127630671037\n",
      "epoch: 14\t| Cnt: 81\t| Loss: 0.00869128387857927\t| f1 score: 0.9898246219308838\n",
      "epoch: 14\t| Cnt: 121\t| Loss: 0.009037145302863791\t| f1 score: 0.9913886493013628\n",
      "epoch: 14\t| Cnt: 161\t| Loss: 0.012626747140893712\t| f1 score: 0.9874831809556668\n",
      "epoch: 14\t| Cnt: 201\t| Loss: 0.009757282253121956\t| f1 score: 0.9906112356966247\n",
      "epoch: 14\t| Cnt: 241\t| Loss: 0.013004970105248504\t| f1 score: 0.9859145535046864\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.08\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.8646968300789295\n",
      "\n",
      "epoch: 15\t| Cnt: 1\t| Loss: 0.004082023166120052\t| f1 score: 1.0\n",
      "epoch: 15\t| Cnt: 41\t| Loss: 0.010614965748391113\t| f1 score: 0.9882621219308838\n",
      "epoch: 15\t| Cnt: 81\t| Loss: 0.009542888401483651\t| f1 score: 0.9890518084066471\n",
      "epoch: 15\t| Cnt: 121\t| Loss: 0.011378776704077609\t| f1 score: 0.9843335625407004\n",
      "epoch: 15\t| Cnt: 161\t| Loss: 0.00965276427596109\t| f1 score: 0.9874847083261458\n",
      "epoch: 15\t| Cnt: 201\t| Loss: 0.013333699540817178\t| f1 score: 0.9851340671899258\n",
      "epoch: 15\t| Cnt: 241\t| Loss: 0.006573294990812428\t| f1 score: 0.9921813905180841\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:16\n",
      "\n",
      "valid score: 0.9403999190720259\n",
      "\n",
      "epoch: 16\t| Cnt: 1\t| Loss: 0.004686354659497738\t| f1 score: 1.0\n",
      "epoch: 16\t| Cnt: 41\t| Loss: 0.008937498291197698\t| f1 score: 0.9913901766718418\n",
      "epoch: 16\t| Cnt: 81\t| Loss: 0.005183506540197414\t| f1 score: 0.9953079178885631\n",
      "epoch: 16\t| Cnt: 121\t| Loss: 0.008842357638059184\t| f1 score: 0.9882467036769202\n",
      "epoch: 16\t| Cnt: 161\t| Loss: 0.007917744229052915\t| f1 score: 0.9898292220113852\n",
      "epoch: 16\t| Cnt: 201\t| Loss: 0.0069811214227229355\t| f1 score: 0.9921644269245771\n",
      "epoch: 16\t| Cnt: 241\t| Loss: 0.007697189386817627\t| f1 score: 0.9898246219308838\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9282988484480945\n",
      "\n",
      "epoch: 17\t| Cnt: 1\t| Loss: 0.0032758070155978203\t| f1 score: 1.0\n",
      "epoch: 17\t| Cnt: 41\t| Loss: 0.009849925253365654\t| f1 score: 0.9890380081651429\n",
      "epoch: 17\t| Cnt: 81\t| Loss: 0.0076064180422690695\t| f1 score: 0.9906127630671037\n",
      "epoch: 17\t| Cnt: 121\t| Loss: 0.01042436129791895\t| f1 score: 0.9874801082456444\n",
      "epoch: 17\t| Cnt: 161\t| Loss: 0.011390866519650444\t| f1 score: 0.9882651946409062\n",
      "epoch: 17\t| Cnt: 201\t| Loss: 0.009845148862950737\t| f1 score: 0.9898307493818642\n",
      "epoch: 17\t| Cnt: 241\t| Loss: 0.009684849169570953\t| f1 score: 0.9906158357771261\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.05\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.91199801373831\n",
      "\n",
      "epoch: 18\t| Cnt: 1\t| Loss: 0.0008527415338903666\t| f1 score: 1.0\n",
      "epoch: 18\t| Cnt: 41\t| Loss: 0.00783693098128424\t| f1 score: 0.9898322767523432\n",
      "epoch: 18\t| Cnt: 81\t| Loss: 0.008418335733585991\t| f1 score: 0.9890487356966247\n",
      "epoch: 18\t| Cnt: 121\t| Loss: 0.008736323201446794\t| f1 score: 0.9906081629866023\n",
      "epoch: 18\t| Cnt: 161\t| Loss: 0.0037457904385519215\t| f1 score: 0.9953079178885631\n",
      "epoch: 18\t| Cnt: 201\t| Loss: 0.006105736547760898\t| f1 score: 0.9913978494623656\n",
      "epoch: 18\t| Cnt: 241\t| Loss: 0.008061393426032737\t| f1 score: 0.9913978494623656\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9415840546076795\n",
      "\n",
      "epoch: 19\t| Cnt: 1\t| Loss: 0.0032839151099324226\t| f1 score: 1.0\n",
      "epoch: 19\t| Cnt: 41\t| Loss: 0.009401845635875362\t| f1 score: 0.9882667220113852\n",
      "epoch: 19\t| Cnt: 81\t| Loss: 0.010152310201374349\t| f1 score: 0.9859206809556668\n",
      "epoch: 19\t| Cnt: 121\t| Loss: 0.008160764210333581\t| f1 score: 0.9921798631476051\n",
      "epoch: 19\t| Cnt: 161\t| Loss: 0.010027117464051116\t| f1 score: 0.9867042220113852\n",
      "epoch: 19\t| Cnt: 201\t| Loss: 0.006245277701236773\t| f1 score: 0.9921813905180841\n",
      "epoch: 19\t| Cnt: 241\t| Loss: 0.007894262655463535\t| f1 score: 0.9921798631476051\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9380485161399379\n",
      "\n",
      "epoch: 20\t| Cnt: 1\t| Loss: 0.003616729751229286\t| f1 score: 1.0\n",
      "epoch: 20\t| Cnt: 41\t| Loss: 0.008285096781764877\t| f1 score: 0.9937392904375827\n",
      "epoch: 20\t| Cnt: 81\t| Loss: 0.007104940857971087\t| f1 score: 0.9906158357771261\n",
      "epoch: 20\t| Cnt: 121\t| Loss: 0.006105958549596835\t| f1 score: 0.9929618768328445\n",
      "epoch: 20\t| Cnt: 161\t| Loss: 0.00331234771583695\t| f1 score: 0.996871945259042\n",
      "epoch: 20\t| Cnt: 201\t| Loss: 0.008244477161497343\t| f1 score: 0.9913840492208614\n",
      "epoch: 20\t| Cnt: 241\t| Loss: 0.003928851294040215\t| f1 score: 0.996871945259042\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9494213501995603\n",
      "\n",
      "epoch: 21\t| Cnt: 1\t| Loss: 0.0009675782639533281\t| f1 score: 1.0\n",
      "epoch: 21\t| Cnt: 41\t| Loss: 0.00584076052364253\t| f1 score: 0.9937392904375827\n",
      "epoch: 21\t| Cnt: 81\t| Loss: 0.006640794373379322\t| f1 score: 0.9937392904375827\n",
      "epoch: 21\t| Cnt: 121\t| Loss: 0.004508196659298846\t| f1 score: 0.9937438905180841\n",
      "epoch: 21\t| Cnt: 161\t| Loss: 0.007752787225763313\t| f1 score: 0.9874785808751654\n",
      "epoch: 21\t| Cnt: 201\t| Loss: 0.008171578431210946\t| f1 score: 0.9890241172816584\n",
      "epoch: 21\t| Cnt: 241\t| Loss: 0.003805725771235302\t| f1 score: 0.9960899315738025\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.03\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9386342716547146\n",
      "\n",
      "epoch: 22\t| Cnt: 1\t| Loss: 0.0009891643421724439\t| f1 score: 1.0\n",
      "epoch: 22\t| Cnt: 41\t| Loss: 0.005640199357003439\t| f1 score: 0.9937438905180841\n",
      "epoch: 22\t| Cnt: 81\t| Loss: 0.004799601599370362\t| f1 score: 0.9921752630671037\n",
      "epoch: 22\t| Cnt: 121\t| Loss: 0.005531595825596014\t| f1 score: 0.9937438905180841\n",
      "epoch: 22\t| Cnt: 161\t| Loss: 0.005882030706561636\t| f1 score: 0.9937438905180841\n",
      "epoch: 22\t| Cnt: 201\t| Loss: 0.006778950657462701\t| f1 score: 0.9913932493818642\n",
      "epoch: 22\t| Cnt: 241\t| Loss: 0.00766657251988363\t| f1 score: 0.9906066356161233\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.20\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.7843229549964418\n",
      "\n",
      "epoch: 23\t| Cnt: 1\t| Loss: 0.004920420236885548\t| f1 score: 1.0\n",
      "epoch: 23\t| Cnt: 41\t| Loss: 0.009599496058945079\t| f1 score: 0.9882651946409062\n",
      "epoch: 23\t| Cnt: 81\t| Loss: 0.007429880300696823\t| f1 score: 0.9913932493818642\n",
      "epoch: 23\t| Cnt: 121\t| Loss: 0.0034533164460299305\t| f1 score: 0.996871945259042\n",
      "epoch: 23\t| Cnt: 161\t| Loss: 0.005195449552775244\t| f1 score: 0.9953079178885631\n",
      "epoch: 23\t| Cnt: 201\t| Loss: 0.006636670542502543\t| f1 score: 0.9937454178885631\n",
      "epoch: 23\t| Cnt: 241\t| Loss: 0.006724536791443825\t| f1 score: 0.9921706629866023\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.04\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.934562949301249\n",
      "\n",
      "epoch: 24\t| Cnt: 1\t| Loss: 0.012082459405064583\t| f1 score: 0.9687194525904204\n",
      "epoch: 24\t| Cnt: 41\t| Loss: 0.0038992471705569186\t| f1 score: 0.9953033178080617\n",
      "epoch: 24\t| Cnt: 81\t| Loss: 0.00478005483164452\t| f1 score: 0.9953033178080617\n",
      "epoch: 24\t| Cnt: 121\t| Loss: 0.0050402453030983455\t| f1 score: 0.9945259042033235\n",
      "epoch: 24\t| Cnt: 161\t| Loss: 0.007764501323981677\t| f1 score: 0.9913993768328446\n",
      "epoch: 24\t| Cnt: 201\t| Loss: 0.0043579097393376285\t| f1 score: 0.9953079178885631\n",
      "epoch: 24\t| Cnt: 241\t| Loss: 0.00661035623998032\t| f1 score: 0.9937346903570813\n",
      "\n",
      "Average training loss: 0.01\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9632661714109723\n",
      "\n",
      "epoch: 25\t| Cnt: 1\t| Loss: 0.0014707837253808975\t| f1 score: 1.0\n",
      "epoch: 25\t| Cnt: 41\t| Loss: 0.005482542291065329\t| f1 score: 0.9937438905180841\n",
      "epoch: 25\t| Cnt: 81\t| Loss: 0.005417372174269986\t| f1 score: 0.9937454178885631\n",
      "epoch: 25\t| Cnt: 121\t| Loss: 0.0031285685141483554\t| f1 score: 0.9953079178885631\n",
      "epoch: 25\t| Cnt: 161\t| Loss: 0.005344135902851122\t| f1 score: 0.9945259042033235\n",
      "epoch: 25\t| Cnt: 201\t| Loss: 0.0031329941844887798\t| f1 score: 0.9960899315738025\n",
      "epoch: 25\t| Cnt: 241\t| Loss: 0.003932180710035027\t| f1 score: 0.9953079178885631\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9594150156723216\n",
      "\n",
      "epoch: 26\t| Cnt: 1\t| Loss: 0.027380816638469696\t| f1 score: 0.9687194525904204\n",
      "epoch: 26\t| Cnt: 41\t| Loss: 0.005239352345597581\t| f1 score: 0.9953079178885631\n",
      "epoch: 26\t| Cnt: 81\t| Loss: 0.0034499032961321065\t| f1 score: 0.9976539589442815\n",
      "epoch: 26\t| Cnt: 121\t| Loss: 0.005948621063726023\t| f1 score: 0.9937438905180841\n",
      "epoch: 26\t| Cnt: 161\t| Loss: 0.003917645268666092\t| f1 score: 0.9937454178885631\n",
      "epoch: 26\t| Cnt: 201\t| Loss: 0.004863567104621325\t| f1 score: 0.9937469452590421\n",
      "epoch: 26\t| Cnt: 241\t| Loss: 0.0014713582531840075\t| f1 score: 0.998435972629521\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:50\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9691532004166057\n",
      "\n",
      "epoch: 27\t| Cnt: 1\t| Loss: 0.0005449402378872037\t| f1 score: 1.0\n",
      "epoch: 27\t| Cnt: 41\t| Loss: 0.0029841197436326185\t| f1 score: 0.9968673451785406\n",
      "epoch: 27\t| Cnt: 81\t| Loss: 0.002510572337268968\t| f1 score: 0.9976539589442815\n",
      "epoch: 27\t| Cnt: 121\t| Loss: 0.007125861956592416\t| f1 score: 0.9913932493818642\n",
      "epoch: 27\t| Cnt: 161\t| Loss: 0.00634951680785889\t| f1 score: 0.9929572767523431\n",
      "epoch: 27\t| Cnt: 201\t| Loss: 0.0028704591506539144\t| f1 score: 0.996871945259042\n",
      "epoch: 27\t| Cnt: 241\t| Loss: 0.0048017225304647585\t| f1 score: 0.9945213041228221\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.02\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9658660705788922\n",
      "\n",
      "epoch: 28\t| Cnt: 1\t| Loss: 0.00039021248812787235\t| f1 score: 1.0\n",
      "epoch: 28\t| Cnt: 41\t| Loss: 0.004121534645310021\t| f1 score: 0.9953079178885631\n",
      "epoch: 28\t| Cnt: 81\t| Loss: 0.004355389075499261\t| f1 score: 0.9953079178885631\n",
      "epoch: 28\t| Cnt: 121\t| Loss: 0.004972542836549109\t| f1 score: 0.9929618768328445\n",
      "epoch: 28\t| Cnt: 161\t| Loss: 0.001834118058832246\t| f1 score: 0.9976539589442815\n",
      "epoch: 28\t| Cnt: 201\t| Loss: 0.008030125014556688\t| f1 score: 0.9906127630671037\n",
      "epoch: 28\t| Cnt: 241\t| Loss: 0.0029557877123806975\t| f1 score: 0.9960899315738025\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 0.99\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.01\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.9785843238462191\n",
      "\n",
      "epoch: 29\t| Cnt: 1\t| Loss: 0.0007987745339050889\t| f1 score: 1.0\n",
      "epoch: 29\t| Cnt: 41\t| Loss: 0.004618870160993538\t| f1 score: 0.9937438905180841\n",
      "epoch: 29\t| Cnt: 81\t| Loss: 0.0031708151336715673\t| f1 score: 0.9960853314933011\n",
      "epoch: 29\t| Cnt: 121\t| Loss: 0.0038784663391197684\t| f1 score: 0.9960899315738025\n",
      "epoch: 29\t| Cnt: 161\t| Loss: 0.003697509687481215\t| f1 score: 0.9960899315738025\n",
      "epoch: 29\t| Cnt: 201\t| Loss: 0.0031702194464742206\t| f1 score: 0.9953079178885631\n",
      "epoch: 29\t| Cnt: 241\t| Loss: 0.00344714277634921\t| f1 score: 0.9953094452590421\n",
      "\n",
      "Average training loss: 0.00\n",
      "Average training score: 1.00\n",
      "Training epoch took: 0:00:49\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.01\n",
      "Validation took: 0:00:17\n",
      "\n",
      "valid score: 0.974500698796267\n",
      "\n",
      "\n",
      "Training complete!\n",
      "Total training took 2:44:31 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    # Let's set a seed value to make this reproducible\n",
    "    set_seed()\n",
    "    train_skf = pd.concat([train, valid])\n",
    "    \n",
    "    train_f1_list, train_loss_list = [], []\n",
    "    valid_f1_list, valid_f1_list_tot, valid_loss_list, valid_roc_list = [], [], [], []\n",
    "    best_pre = 0.0\n",
    "    a = 0\n",
    "    n = 5\n",
    "    kf = KFold(n_splits=n)\n",
    "    train_results, valid_results, valid_results_tot, train_loss, valid_loss, valid_results_roc, training_stats_list  = [], [], [], [], [], [], []\n",
    "    \n",
    "\n",
    "    for train_idx, cross_val_idx in kf.split(train_skf):\n",
    "       \n",
    "        print(\"\",end=\"\\n\\n\")\n",
    "        print(f\"Generating Inputs for fold {a}\")\n",
    "        print(\"==\"*20)\n",
    "    \n",
    "        train_df = train_skf.iloc[train_idx]\n",
    "        train_df.index = range(train_df.shape[0])\n",
    "        train_df.patid = range(train_df.shape[0])\n",
    "        \n",
    "        cv_df = train_skf.iloc[cross_val_idx]\n",
    "        cv_df.index = range(cv_df.shape[0])\n",
    "        cv_df.patid = range(cv_df.shape[0])\n",
    "        \n",
    "        \n",
    "        X_tr = train_df['inputs_quantiles_cleaned']\n",
    "        y_tr = train_df['label']\n",
    "\n",
    "        Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=train_df, max_len=global_params['max_len_seq'], code='inputs_quantiles_cleaned', delay ='delays' )\n",
    "        hp_generator = {'batch_size': global_params['batch_size'], 'balanced': 'balanced', 'shuffle':True}\n",
    "        train_data = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  sampler = StratifiedSampler(X_tr, y_tr, batch_size=global_params['batch_size']) , **kwargs)\n",
    "    \n",
    "        \n",
    "        valid_Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=cv_df, max_len=global_params['max_len_seq'], code='inputs_quantiles_cleaned', delay ='delays')\n",
    "        valid_data = DataLoader(dataset= Dset, batch_size=global_params['batch_size'],  shuffle = True, **kwargs)\n",
    "        \n",
    "        model, optim = define_model(best_config)\n",
    "        \n",
    "        for e in range(200):   \n",
    "\n",
    "            valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats =  training(e, train_data, valid_data)       \n",
    "\n",
    "            train_f1_list.append(np.mean(train_f1))\n",
    "            train_loss_list.append(np.mean(train_loss))\n",
    "            valid_f1_list.append(np.mean(valid_f1))\n",
    "            valid_roc_list.append(np.mean(valid_roc))\n",
    "            valid_loss_list.append(np.mean(valid_loss))\n",
    "            \n",
    "            mean_f1 = np.mean(valid_f1)\n",
    "            \n",
    "            if mean_f1 > best_pre:\n",
    "                # Save a trained model\n",
    "                print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "                model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "                output_model_file = os.path.join(global_params['output_dir'],global_params['best_name'])\n",
    "                create_folder(global_params['output_dir'])\n",
    "\n",
    "                torch.save(model_to_save.state_dict(), output_model_file)\n",
    "                best_pre = mean_f1\n",
    "            print('valid score: {}'.format(np.mean(valid_f1)))\n",
    "          \n",
    "            \n",
    "            print()\n",
    "        \n",
    "        a+=1\n",
    "        \n",
    "    train_results.append(train_f1)\n",
    "    valid_results.append(valid_f1)\n",
    "    train_loss.append(train_loss)\n",
    "    valid_loss.append(valid_loss)\n",
    "    valid_results_roc.append(valid_roc)\n",
    "    training_stats_list.append(training_stats)\n",
    "    \n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(end-start)))\n",
    "\n",
    "# age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641fe13b-5d5b-4978-b52b-40cf7f540e3a",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba8c9e1-53a8-4acf-b09f-24c5334a0126",
   "metadata": {},
   "source": [
    "1. Plot model history  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d06d1b-2f88-4288-be28-a51aa235645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_stats(data):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Display floats with two decimal places.\n",
    "    pd.set_option('Average Train f1 score', 2)\n",
    "    pd.set_option('Average Valid f1 score', 2)\n",
    "    \n",
    "    # Create a DataFrame from our training statistics.\n",
    "    df_stats = pd.DataFrame(data=data)\n",
    "\n",
    "    # Use the 'epoch' as the row index.\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "    \n",
    "    hf._dump_pkl(df_stats, 'training_stats')    \n",
    "    # Display the table.\n",
    "    return df_stats\n",
    "\n",
    "def cal_mean(df_stats, feature, epochs):\n",
    "    return [np.mean(df_stats.loc[x, feature]) for x in range(1,epochs+1)]\n",
    "\n",
    "def cal_std(df_stats, feature, epochs):\n",
    "    return [np.std(df_stats.loc[x, feature]) for x in range(1,epochs+1)]\n",
    "     \n",
    "\n",
    "def plot_history(training_stats, epochs):\n",
    "    \n",
    "    \n",
    "    fig, ((ax1, ax2)) = plt.subplots(1,2, figsize = (20,7))\n",
    "    \n",
    "    mean_f1_train = cal_mean(display_training_stats(training_stats), 'Average Train f1 score', epochs)\n",
    "    std_f1_train = cal_std(display_training_stats(training_stats), 'Average Train f1 score', epochs)\n",
    "    \n",
    "    mean_f1_valid = cal_mean(display_training_stats(training_stats), 'Average Valid f1 score', epochs)\n",
    "    std_f1_valid = cal_std(display_training_stats(training_stats), 'Average Valid f1 score', epochs)\n",
    "    \n",
    "    mean_loss_train = cal_mean(display_training_stats(training_stats), 'Training Loss', epochs)\n",
    "    std_loss_train = cal_std(display_training_stats(training_stats), 'Training Loss', epochs)\n",
    "    \n",
    "    mean_loss_valid = cal_mean(display_training_stats(training_stats), 'Validation Loss', epochs)\n",
    "    std_loss_valid = cal_std(display_training_stats(training_stats), 'Validation Loss', epochs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax1.plot(range(epochs), mean_f1_train, 'b-', label='Train f1 score')\n",
    "    ax1.fill_between(range(epochs), np.array(mean_f1_train) - np.array(std_f1_train), np.array(mean_f1_train) + np.array(std_f1_train2), color='b', alpha=0.2)\n",
    "    ax1.plot(range(epochs), mean_f1_valid2, 'r--', label='Valid f1 score')\n",
    "    ax1.fill_between(range(epochs), np.array(mean_f1_valid2) - np.array(std_f1_valid2), np.array(mean_f1_valid2) + np.array(std_f1_valid2), color='r', alpha=0.2)\n",
    "   \n",
    "    ax2.plot(range(epochs), mean_loss_train2, 'b-', label='Train loss')\n",
    "    ax2.fill_between(range(epochs), np.array(mean_loss_train2) - np.array(std_loss_train2), np.array(mean_loss_train2) + np.array(std_loss_train2), color='b', alpha=0.2)\n",
    "    ax2.plot(range(epochs), mean_loss_valid2, 'r--', label='Valid loss')\n",
    "    ax2.fill_between(range(epochs), np.array(mean_loss_valid2) - np.array(std_loss_valid2), np.array(mean_loss_valid2) + np.array(std_loss_valid2), color='r', alpha=0.2)\n",
    "   \n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d7733-29a1-4f23-a1ae-80e716260850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = display_training_stats(training_stats)\n",
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6c3d6-aa7d-4cf9-93e2-d2b611f63e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(training_stats, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa8b36c-c824-42f2-83f4-6db21ea055c1",
   "metadata": {},
   "source": [
    "2. Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2428e9-be0f-4045-aa70-d7d48cedbec6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6aa72689-99fe-4e39-a9d0-edc9cf82de94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 4,545 test sequences...\n",
      "Validation Loss: 0.27\n",
      "Validation took: 0:00:09\n",
      "\n",
      "Test f1 score = 0.7349955368785289 and Test roc = 0.7656285894785205\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set ## 2nd run , cv and cleaned\n",
    "\n",
    "print('Predicting labels for {:,} test sequences...'.format(len(test)))\n",
    "f1, roc, loss, test_time = evaluation(testload)\n",
    "print('Test f1 score = {} and Test roc = {}'.format(np.mean(f1), np.mean(roc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91be0e8e-7399-4ecc-844f-0622dfed8ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def precision_test(logits, label):\n",
    "    \n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(logits)\n",
    "    label=np.argmax(label, axis=1)\n",
    "    output=np.argmax(output, axis=1)\n",
    "    roc = sklearn.metrics.roc_auc_score(label.numpy(),output.numpy(), average='samples')\n",
    "    f1 =  sklearn.metrics.f1_score(label.numpy(), output.numpy(), average=\"macro\")\n",
    "    recall = sklearn.metrics.recall_score(label.numpy(), output.numpy(), average=\"macro\")\n",
    "    precision = sklearn.metrics.precision_score(label.numpy(), output.numpy(), average=\"macro\")\n",
    " \n",
    "    return f1, roc, recall, precision, output, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ef1146e-abfe-488a-a7ea-247ddbcef515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_roc_auc(fpr, tpr, roc_auc):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import sklearn.metrics as metrics\n",
    "    \n",
    "   \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig,ax = plt.subplots(figsize=(13, 9))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, '#067562', label = 'AUC = %0.2f' % roc_auc)\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    #plt.savefig('ROC_12.png')\n",
    "    plt.show()\n",
    "\n",
    "def cm(true, predicted, fig_name, cmap = 'Purples'):\n",
    "    \n",
    "    cm = confusion_matrix(true, predicted)\n",
    "\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    try:\n",
    "        heatmap = sn.heatmap(df_cm, annot=True, cmap=cmap)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "    plt.ylabel('True labels')\n",
    "    plt.xlabel('Predicted labels')\n",
    "   #fig.savefig(fig_name+'.png')\n",
    "    return \n",
    "\n",
    "def print_report(model, data): \n",
    "     \n",
    "    y = []\n",
    "    y_label = []\n",
    "   # total_f1, total_roc, total_precision, total_recall = [], [], [], []\n",
    "\n",
    "    for step, batch in enumerate(data):\n",
    "        model.eval()\n",
    "        \n",
    "        age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
    "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        mod_ids = mod_ids.to(global_params['device'])\n",
    "        del_ids = del_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets, output_attentions=True)\n",
    "            \n",
    "        \n",
    "        logits = outputs.logits.cpu()\n",
    "        targets = targets.cpu()\n",
    "        \n",
    "        \n",
    "        y_label.append(targets)\n",
    "        y.append(logits)\n",
    "        \n",
    "     \n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "  \n",
    "     # Compute ROC curve and ROC area for each class\n",
    "    f1, roc, recall, precision, output, label = precision_test(y, y_label)\n",
    "    \n",
    "    label=np.argmax(y_label, axis=1)\n",
    "    \n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(y) \n",
    "\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(label, output[:,1])\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "   \n",
    "    ## Plot ##  \n",
    "    \n",
    "    target_names = ['Non relapse', 'Relapse']\n",
    "\n",
    "    print(\"f1 score is {:.4f}, Precision is {:.4f}, Recall is {:.4f}\".format(f1, precision, recall))\n",
    "    print(classification_report(label, np.argmax(output, axis=1), target_names=target_names))\n",
    "    cm(label, np.argmax(output, axis=1), 'cm')\n",
    "    plot_roc_auc(fpr, tpr, roc_auc)\n",
    "    \n",
    "    return y_label, y, fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5ce9401-fd6e-4fc8-82c1-200f5fed96bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is 0.7350, Precision is 0.7115, Recall is 0.7656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non relapse       0.98      0.97      0.97      4353\n",
      "     Relapse       0.44      0.56      0.50       192\n",
      "\n",
      "    accuracy                           0.95      4545\n",
      "   macro avg       0.71      0.77      0.73      4545\n",
      "weighted avg       0.96      0.95      0.95      4545\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGwCAYAAABLvHTgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArBklEQVR4nO3debxWZbnw8d8FOA8ghIqo6VEqrRSNlMLKIRXtHMERywpNI1PT49BRs5Nmx7T3OJzTKU0cjjhlzqDHBJzeHCJnTTRfUXMgRI8K5ix4vX88C33AvTcb3c8envv39bM+PM+97rXue/Fpty+u615rRWYiSZLUbHp19QQkSZIawSBHkiQ1JYMcSZLUlAxyJElSUzLIkSRJTckgR5IkNaU+XT2BlmwZP/G+dqkL3PD2sV09BalIfZbqHZ05Xkf+nr0lj+/UuS8JMzmSJKkpdctMjiRJapyIbpt86VBmciRJUlMykyNJUmnKSOQY5EiSVJroVUaUY7lKkiQ1JTM5kiQVppB1xwY5kiQVp5Aox3KVJElqSmZyJEkqTCGJHIMcSZJKU8rdVQY5kiSVppBUjmtyJElSUzKTI0lSYQpJ5BjkSJJUGl/QKUmS1EEiondE3BcR11bf142IP0XEjIj4XUQsXbUvU32fUe1fp+4cR1ftj0bE9osb0yBHkqTSRAdu7XcI8Ejd918Ap2Xm+sDLwL5V+77Ay1X7aVU/ImJDYE/g08BI4PSI6N3WgAY5kiQVJnpFh23tGi9iTeBrwNnV9wC2Bi6vukwARlefR1XfqfZvU/UfBVySmW9l5pPADGCztsY1yJEkSY32H8C/AO9W3wcAczJzXvX9WWBw9Xkw8AxAtX9u1f+99haOaZFBjiRJhYnoyC3GRcTdddu4hceKfwSez8x7Ovs6vbtKkqTSdODdVZk5HhjfRpcRwE4RsSOwLLAy8J9Av4joU2Vr1gRmVv1nAmsBz0ZEH6Av8GJd+wL1x7TITI4kSWqYzDw6M9fMzHWoLRy+KTP3Am4Gdqu6jQUmVp8nVd+p9t+UmVm171ndfbUuMAS4s62xzeRIklSYbvKYnCOBSyLi34D7gHOq9nOACyJiBvAStcCIzJweEZcCDwPzgAMzc35bAxjkSJJUmK56QWdm3gLcUn1+ghbujsrMN4HdWzn+BOCE9o5nuUqSJDUlMzmSJJWmm9SrGs0gR5KkwhQS41iukiRJzclMjiRJhSnlLeQGOZIklaaMGMdylSRJak5mciRJKkxXPSensxnkSJJUmjJiHMtVkiSpOZnJkSSpMN5dJUmSmlIpQY7lKkmS1JTM5EiSVJpCUhwGOZIkFcZylSRJUg9mJkeSpMIUksgxyJEkqTiFRDmWqyRJUlMykyNJUmEKSeQY5EiSVJpSXtBpuUqSJDUlMzmSJJWmkHqVQY4kSYUpJMaxXCVJkpqTmRxJkgpTymsdDHIkSSpNIXWcQi5TkiSVxkyOJEmFsVwlSZKaUilBjuUqSZLUlMzkSJJUmCgkxWGQI0lSaSxXSZIk9VxmciRJKkwhiRyDHEmSShO9yohyLFdJkqSmZJAjSVJpIjpuW+xQsWxE3BkRD0TE9Ij4adV+XkQ8GRH3V9vQqj0i4pcRMSMiHoyITevONTYiHqu2sYsb23KVJEmF6eQ1OW8BW2fmqxGxFHBbRPy+2vfDzLx8kf47AEOqbXPgDGDziOgPHAsMAxK4JyImZebLrQ1sJkeSJDVM1rxafV2q2rKNQ0YB51fHTQP6RcQgYHtgama+VAU2U4GRbY1tkCNJUmGiV3TY1q7xInpHxP3A89QClT9Vu06oSlKnRcQyVdtg4Jm6w5+t2lprb5VBjiRJpenANTkRMS4i7q7bxi06XGbOz8yhwJrAZhHxGeBo4FPA54H+wJEdfZkGOZIkFaYj1x1n5vjMHFa3jW9t3MycA9wMjMzMWVVJ6i3gv4HNqm4zgbXqDluzamutvVUGOZIkqWEiYmBE9Ks+LwdsC/ylWmdD1F6JPhp4qDpkEvDt6i6r4cDczJwFTAa2i4hVImIVYLuqrVXeXSVJUmE6+WGAg4AJEdGbWnLl0sy8NiJuioiBQAD3A/tX/a8DdgRmAK8D+wBk5ksR8TPgrqrf8Zn5UlsDG+RIklSaToxxMvNBYJMW2rdupX8CB7ay71zg3PaObblKkiQ1JTM5kiQVJgp5Q6dBjiRJhfEFnZIkST2YmRxJkgpTSLXKIEeSpOIUEuVYrpIkSU3JTI4kSYUpZeGxQY4kSYUppFpluUqSJDUnMzmSJJWmkFSOQY4kSYUp5YnHlqskSVJTMpMjSVJhopAUh0GOJEmlsVwlSZLUc5nJkSSpMIUkcgxyJEkqTSlPPG54uSoiDoiIJyPizYi4JyK+1OgxJUmSGhrkRMQY4D+BnwObAHcAv4+ItRs5rpZcr17BWfd+nxOv2esD+3Y/9IucN/0gznngAE65YW9WW7vvRx5vpVWW4+QpY7nw/x3CyVPGsmK/ZQEYsdOnOOeBAzj7vu9z5l3f47Mj/J+KmtePf3wMX/ryFowavVOb/f785z+z0cafZfKUyR95zDlz57Dffvuyw44j2W+/fZk7dy4A1157DTvvPJrRO49ir72+wV/+8pePPJa6sYiO27qxRmdyDgPOy8yzMvORzPwBMAv4foPH1RLa9ZAv8NQjL7S477H7ZvG9YWey78an838vn873/s927T7v0K+sw1H/vfMH2r9x1Je498Yn+OYn/pN7b3yCbxxVS/Dde+MT7Lvx6ey3yRn84jtX88OzR324C5J6gNGjd+bM34xvs8/8+fM59bRT+eIXv7hE577zzjv50TE/+kD72WefzebDh/P7665n8+HDOfucswEYPHhNzjtvAldfNZH999+f43567BKNp56lkBincUFORCwNfA6YssiuKcCS/bSqoQYOXpnhX/sE/3P2PS3uv/+WJ3nrjXcAeHjaMwxc8/1MzpgjRvCbO7/HOQ8cwN7HbdXuMUeM+hTXT7gPgOsn3McWozcA4I3X3n6vz7IrLE3mEl+O1GMMGzaMvn3bzoxedPFFbLvttvTvP2Ch9nPPPYc9xuzBzjuP5le/+q92j3nzzTcxetRoAEaPGs1NN90IwCabbPLeXDbaaGNmz569BFcidU+NzOR8DOgNLPqTMhtYvYHjagkd9B87cOa/TCbfXXxE8bV9P8edv38MgGHbrseaQwaw/2Znst/QM/jk59Zgoy99vF1j9l9tBV567lUAXnruVfqvtsJ7+7YYvQHnP/IDTvqfvfjFd65e8guSmsTs2bO58cYb2HPMngu133777Tz19NP87pLfccUVV/Lwww9z9913t+ucL774IgMHDgTgYx/7GC+++OIH+lx55RV8aQuXTzaz6BUdtnVn3l1VuC987RO8/Pxr/L97ZzH0K+u02XfbvTbik8PW4JCvnAvA57dbn89vtx5n31erPi634tKsOWQAD976FKdPG8fSy/RmuRWXZqX+y73X58wjp3LXlBkfOHd9xua2qx/htqsfYaMvfZx9f7Y1h287oWMuVuphTvrFiRx26OH06rXwv0fvuON27rjjdnbdbRcAXn/9dZ566imGDRvGnl8fw9tvv83rr7/O3Llz2WXXWrn4sMMOZ4sRWyx0noj4wDuM/nTnn7jyyiu54IILG3hl6nLdvc7UQRoZ5PwvMB9YbZH21YDnFu0cEeOAcQBD+BprsGkDp6YFPjNibUbs9EmG7ziEpZftw/IrL8MxF+zKCd+6YqF+n9vmH/jmMV/hkK+cyztvz681Blx04q1cM/6D/4I8YHhtncHQr6zDyL034aR9rlpo/0uzX6P/6ivWsjirr8jLz7/2gXM8eOtTDPqHVeg7YHnmvvh6B12x1HNMnz6dI354OAAvv/wyt976B/r07k2SfHe/77LHHmM+cMwlv/0dUFuTc/XEq/n5CT9faP+AAQN44YUXGDhwIC+88AL9+/d/b9+jjz7KsT/5Cb/5zZn069evcRcmdZKGlasy823gHmDbRXZtS+0uq0X7j8/MYZk5zACn85z1oxvYfa1T2HPd0zh+z8u476YnPxDgrD90dQ47cyd+tNNFzHnh/WDkrskz2OE7m7LcCksD8LE1VqLfwBVojzsm/YWRYzcBYOTYTbh9Yu1OjsHrvf9/uEM2GcRSy/QxwFGxpkyeytQpNzB1yg1st932/PjH/8o223yVEV/cgiuvupLXXq/9PM6ePbvFslNLttpyK66eeDUAV0+8mq222hqAv836G4f888GceOJJrLPOOo24HHUjpSw8bnS56lTggoi4E7gd2B9YA/hNg8fVR7TPT7fm0btncsc1j/L9f9+e5VZcmp9eVvtX4+yn53LMqIu5e+rjfHyDgfz6j98F4I1X3+aEb16+UCDUmotPupVjLx3Djvtuyuyn5nDcHpcC8OVdN2S7bw9l/jvzeeuNeRw/5tLGXaTUxY744RHcddedzJkzh6232YoDDziIefNqi/zHLLIOp96IESN44okn2GuvbwCw/PLLc9KJv2DAgAGtHrPAfvt9l8MOP5Qrr7yCNdZYg1NOORWA35xxBnPnzuVn/3Y8AH169+HSSy/7qJeobqq7r6XpKJENvn0lIg4A/gUYBDwEHJqZf2jrmC3jJ95TI3WBG972tmGpK/RZqnenRh0H7XZRh/2e/dXle3XbiKnhC48z83Tg9EaPI0mS2mfRBefNyrurJEkqTRkxTuPfXSVJktQVzORIklSYUhYeG+RIklSYUtbkWK6SJElNyUyOJEmlsVwlSZKaUSHVKstVkiSpORnkSJJUmAVvoO+IrR1jLRsRd0bEAxExPSJ+WrWvGxF/iogZEfG7iFi6al+m+j6j2r9O3bmOrtofjYjtFze2QY4kSaXpFR23Ld5bwNaZuTEwFBgZEcOBXwCnZeb6wMvAvlX/fYGXq/bTqn5ExIbAnsCngZHA6RHRu83LXNK/F0mSpPbKmlerr0tVWwJbA5dX7ROA0dXnUdV3qv3bRC1lNAq4JDPfyswngRnAZm2NbZAjSVJhIjpua9940Tsi7geeB6YCjwNzMnNe1eVZYHD1eTDwDEC1fy4woL69hWNa5N1VkiQVpiOfeBwR44BxdU3jM3N8fZ/MnA8MjYh+wFXApzpsAm0wyJEkSR9aFdCMX2zHWt85EXEz8AWgX0T0qbI1awIzq24zgbWAZyOiD9AXeLGufYH6Y1pkuUqSpNJ0Yr0qIgZWGRwiYjlgW+AR4GZgt6rbWGBi9XlS9Z1q/02ZmVX7ntXdV+sCQ4A72xrbTI4kSYXp5HdXDQImVHdC9QIuzcxrI+Jh4JKI+DfgPuCcqv85wAURMQN4idodVWTm9Ii4FHgYmAccWJXBWmWQI0mSGiYzHwQ2aaH9CVq4Oyoz3wR2b+VcJwAntHdsgxxJkgoThSxWMciRJKkwnVyu6jKFxHKSJKk0ZnIkSSpNIZkcgxxJkgrjmhxJktSUXJMjSZLUg5nJkSSpNB347qruzCBHkqTCWK6SJEnqwczkSJJUmEISOQY5kiQVp5A1OZarJElSUzKTI0lSYUpZeGyQI0lSYQqJcSxXSZKk5mQmR5Kk0hSy8NggR5KkwpSyJsdylSRJakpmciRJKkxYrpIkSU2pjBjHcpUkSWpOZnIkSSpMKQuPDXIkSSpMKWtyLFdJkqSmZCZHkqTCWK6SJEnNqYwYx3KVJElqTmZyJEkqjOUqSZLUlAqJcSxXSZKk5mQmR5KkwpSSyTHIkSSpMKWsybFcJUmSmpKZHEmSClNIIscgR5Kk0liukiRJ6sEMciRJKkxEx22LHyvWioibI+LhiJgeEYdU7cdFxMyIuL/adqw75uiImBERj0bE9nXtI6u2GRFx1OLGtlwlSVJhOrlcNQ84PDPvjYiVgHsiYmq177TMPHmRuW0I7Al8GlgDuCEiPlHt/jWwLfAscFdETMrMh1sb2CBHkiQ1TGbOAmZVn/8eEY8Ag9s4ZBRwSWa+BTwZETOAzap9MzLzCYCIuKTq22qQY7lKkqTCdGa5auFxYx1gE+BPVdNBEfFgRJwbEatUbYOBZ+oOe7Zqa629VQY5kiQVJjryv4hxEXF33TauxTEjVgSuAP45M18BzgDWA4ZSy/Sc0tHXablKkiR9aJk5HhjfVp+IWIpagHNRZl5ZHTe7bv9ZwLXV15nAWnWHr1m10UZ7i8zkSJJUmE6+uyqAc4BHMvPUuvZBdd12Bh6qPk8C9oyIZSJiXWAIcCdwFzAkItaNiKWpLU6e1NbYZnIkSSpMJz8LcATwLeDPEXF/1fYj4OsRMRRI4K/A9wAyc3pEXEptQfE84MDMnF+bdxwETAZ6A+dm5vS2BjbIkSRJDZOZtwEthVXXtXHMCcAJLbRf19ZxizLIkSSpMKW81mGJgpzq9q61MvPBBs1HkiQ1WCExzuIXHkfELRGxckT0B+4FzoqIUxd3nCRJUldqz91Vfav72XcBzs/MzYGvNnZakiSpYbrqaYCdrD1BTp/qNq89eP8edkmS1EMVEuO0K8g5ntrtWjMy866I+AfgscZOS5Ik6aNZ7MLjzLwMuKzu+xPAro2clCRJapzi766KiP+i9oCeFmXmwQ2ZkSRJaqhCYpw2Mzl3d9osJEmSOlirQU5mTqj/HhHLZ+brjZ+SJElqpFLKVe15Ts4XIuJh4C/V940j4vSGz0ySJDWEd1e97z+A7YEXATLzAeDLDZyTJEnSR9au1zpk5jOLpLbmN2Y6kiSp0bp5AqbDtCfIeSYivghkRCwFHAI80thpSZKkRillTU57gpz9gf8EBgN/o/ZgwAMbOSlJktQ4hcQ47XoY4P8Ce3XCXCRJkjpMe+6u+oeIuCYiXoiI5yNiYvVqB0mS1ANFRIdt3Vl77q66GLgUGASsQe0VD79t5KQkSVLjeAv5+5bPzAsyc161XQgs2+iJSZIkfRRtvbuqf/Xx9xFxFHAJtXdZjQGu64S5SZKkBujuZaaO0tbC43uoBTUL/ia+V7cvgaMbNSlJktQ4hcQ4bb67at3OnIgkSVJHatcTjyPiM8CG1K3FyczzGzUpSZLUOMVnchaIiGOBLakFOdcBOwC3AQY5kiT1QKWsyWnP3VW7AdsAz2XmPsDGQN+GzkqSJOkjak+56o3MfDci5kXEysDzwFoNnpckSWqQQhI57Qpy7o6IfsBZ1O64ehX4YyMnJUmSGqeUclV73l11QPXxNxFxPbByZj7YyEnd+M5xjTy9JEkqQFsPA9y0rX2ZeW9jpiRJkhqqjEROm5mcU9rYl8DWHTwXSZLUCYovV2XmVp05EUmSpI7UrocBSpKk5lF8JkeSJDWnQmKcdj0MUJIkqcdZbJATNd+MiJ9U39eOiM0aPzVJktQIEdFhW3fWnkzO6cAXgK9X3/8O/LphM5IkSQ0V0XFbd9aeNTmbZ+amEXEfQGa+HBFLN3hekiRJH0l7MjnvRERvas/GISIGAu82dFaSJKlhOrNcFRFrRcTNEfFwREyPiEOq9v4RMTUiHqv+XKVqj4j4ZUTMiIgH6x9OHBFjq/6PRcTYxY3dniDnl8BVwKoRcQJwG/DzdhwnSZK6oU5ekzMPODwzNwSGAwdGxIbAUcCNmTkEuLH6DrADMKTaxgFnVHPuDxwLbA5sBhy7IDBqTXveXXVRRNwDbEPtQdCjM/OR9lyVJEkqW2bOAmZVn/8eEY8Ag4FRwJZVtwnALcCRVfv5mZnAtIjoFxGDqr5TM/MlgIiYCowEftva2IsNciJibeB14Jr6tsx8eomuUpIkdQtdtWA4ItYBNgH+BKxWBUAAzwGrVZ8HA8/UHfZs1dZae6vas/D4f6itxwlgWWBd4FHg0+04VpIkdTMdeet3RIyjVlZaYHxmjm+h34rAFcA/Z+Yr9XPIzIyI7LBJVdpTrvrsIpPcFDigoyciSZJ6niqg+UBQUy8ilqIW4FyUmVdWzbMjYlBmzqrKUc9X7TOBteoOX7Nqm8n75a0F7be0Ne4SP/E4M++ltuhHkiT1QNErOmxb7Fi1lM05wCOZeWrdrknAgjukxgIT69q/Xd1lNRyYW5W1JgPbRcQq1YLj7aq2VrVnTc5hdV97AZsCf1vsVUmSpG6pk9fkjAC+Bfw5Iu6v2n4EnARcGhH7Ak8Be1T7rgN2BGZQWxO8D0BmvhQRPwPuqvodv2ARcmvasyZnpbrP86it0bmiHcdJkqTCZeZt1Nb1tmSbFvoncGAr5zoXOLe9Y7cZ5FQPAVwpM49o7wklSVL31t3fOdVRWg1yIqJPZs6LiBGdOSFJktRYhcQ4bWZy7qS2/ub+iJgEXAa8tmBn3epoSZKkbqc9a3KWBV4Etub95+UkYJAjSVIPVHy5itq7qg4DHuL94GaBDn9gjyRJ6hwGOdAbWJGWV0Qb5EiSpG6trSBnVmYe32kzkSRJnaKQRE6bQU4hfwWSJBWmkCinrdc6fOABPZIkST1Fq5mcxT0qWZIk9UwuPJYkSU2pkBhnyd9CLkmS1BOYyZEkqTDRq4xUjkGOJEmFsVwlSZLUg5nJkSSpMN5dJUmSmlIpQY7lKkmS1JTM5EiSVJhCEjkGOZIklcZylSRJUg9mJkeSpMKUkskxyJEkqTCFxDgGOZIklaaUTI5rciRJUlMykyNJUmFKyeQY5EiSVJhCYhzLVZIkqTmZyZEkqTDRq4xUjkGOJEmFsVwlSZLUg5nJkSSpMEEZqRyDHEmSSlNGjGO5SpIkNSczOZIkFcaHAUqSpKZUSIxjuUqSJDUngxxJkgoTER22tXO8cyPi+Yh4qK7tuIiYGRH3V9uOdfuOjogZEfFoRGxf1z6yapsREUctblyDHEmSChPRcVs7nQeMbKH9tMwcWm3X1eYWGwJ7Ap+ujjk9InpHRG/g18AOwIbA16u+rXJNjiRJaqjM/ENErNPO7qOASzLzLeDJiJgBbFbtm5GZTwBExCVV34dbO5GZHEmSCtPZ5ao2HBQRD1blrFWqtsHAM3V9nq3aWmtvlUGOJEmF6chyVUSMi4i767Zx7ZzGGcB6wFBgFnBKR1+n5SpJkvShZeZ4YPyHOG72gs8RcRZwbfV1JrBWXdc1qzbaaG+RmRxJkgrTHcpVETGo7uvOwII7ryYBe0bEMhGxLjAEuBO4CxgSEetGxNLUFidPamsMMzmSJBWmsx8GGBG/BbYEPhYRzwLHAltGxFAggb8C3wPIzOkRcSm1BcXzgAMzc351noOAyUBv4NzMnN7muJnZiOv5SObPe7f7TUqSpAbp3adXp4Ydf5z2dIf9nv3C8LW77fOTzeRIklSYUl7rYJAjSVJhgjKiHBceS5KkpmQmR5KkwliukiRJTakDnlTcI1iukiRJTclMjiRJhSkkkWOQI0lSaSxXSZIk9WBmciRJKkwhiRyDHEmSSmO5SpIkqQczkyNJUmnKSOQY5EiSVBrLVZIkST2YmRxJkgpTSCLHIEeSpNJYrpIkSerBzORIklSYMvI4BjmSJBXHcpUkSVIPZiZHkqTCFJLIMciRJKk0lqskSZJ6MDM5kiQVppBETmMzORHx5YiYFBEzIyIjYu9GjidJkhYvouO27qzR5aoVgYeAQ4A3GjyWusCECefxTzv9IzuN+ieOOOJw3nrrrff2nfDzE/jcsM914eyk7uuYHx/DFl8awU6j/qnF/U888QRf/8aebDx0I87973M7ZMy3336bww4/lO1Hbs+YPccwc+ZMAO6443Z2231XRo3eid1235Vp06Z1yHhSV2tokJOZ12XmjzLzcuDdRo6lzjd79mwuvOhCLrv0ciZNvIb5777LddddB8BDDz3EK6/M7eIZSt3XzqNHM/7M8a3u79u3Lz86+hj22ec7S3zumTNnMnbvb3+g/YorLmfllfsy+frJjP32tznl1JMB6LfKKpz+6zOYePUkTvz5iRx19JFLPKZ6lojosK07c+GxPpL58+fz5ptvMm/ePN588w1WXXVV5s+fz8kn/ztHHH5EV09P6raGDfs8ffv2a3X/gAED+OxnP0ufPh9cOjnpmkmMGbMHO++yM8cedyzz589v15g33XQTo0eNAmC77bZn2rRpZCYbbrAhq666KgDrrz+EN998i7fffnvJL0o9huUqaTFWW2019tl7H7b56jZ8Zcsvs+KKKzFixAguvvgittpqKwYOXLWrpyg1nccff5zrf/97LrzwIq668ip69+rFtdde065jZz8/m9VXHwRAnz59WGmllZgzZ85CfaZMmcKGG27A0ksv3dFTlzpdt7m7KiLGAeMAzjj9DL773XFdPCMtzty5c7npppuYOmUqK620EocedigTJ17N5MmTOe+8CV09PakpTZs2jekPT2ePMXsA8NZbb9J/wAAAfnDwQTz77EzeeecdZs2axc677AzAt771LXbZeZfFnvuxGY9x6mmncNb4sxt3AeoWunuZqaN0myAnM8cD4wHmz3s3u3g6aoc/Tvsjg9ccTP/+/QHY9qtf5Ve//hVvvvkWI3fYHoA333yD7Uduz+TrJ3flVKWmkSSjRo3msEMP+8C+//rlr4DampwfHXM0E847f6H9q626Gs89N4vVV1+defPm8fe//51+/foB8Nxzz3HwwT/gxJ+fxNprr93w65A6g+UqfWiDBg3igQce4I033iAzmTZtGmPH7s2tf7iVG6beyA1Tb2TZZZczwJE60PDNhzNlymRefPFFAObMmcPMv81s17FbbbUVV0+cCMCUKZPZfPPhRASvvPIK3//+/hx26GFsuummDZu7uo9SFh43NJMTESsC61dfewFrR8RQ4KXMfLqRY6vxNt5oY7bbbnt2231XevfuzQYbbMAeu+/R1dOSeoQjjjicO++6kzlz5rDV1lty0IEH8c68eQDsOWZPXnjhBfYYszuvvvoqvXr14oILzueaSdey/vrrc8jBh7Dfd/cj81369OnDv/74Xxm8xuDFjrnrrrtx5FFHsv3I7enXty8nn3wKABdffBFPP/M0p59xBqefcQYAZ591NgOqMpjUU0Vm4ypDEbElcHMLuyZk5t6tHWe5SpJUkt59enVqSuTxx1/ssN+z6603oNumcxqaycnMW4Bue/GSJKl5uSZHkiQ1JYMcSZIK09kPA4yIcyPi+Yh4qK6tf0RMjYjHqj9XqdojIn4ZETMi4sGI2LTumLFV/8ciYuzixjXIkSSpMNGB/7XTecDIRdqOAm7MzCHAjdV3gB2AIdU2DjgDakERcCywObAZcOyCwKg1BjmSJKmhMvMPwEuLNI8CFjw5dgIwuq79/KyZBvSLiEHA9sDUzHwpM18GpvLBwGkh3eZhgJIkqZN0j1uCVsvMWdXn54DVqs+DgWfq+j1btbXW3iozOZIkFaYj1+RExLiIuLtuW+L3MmXteTYd/vgYMzmSJOlDq38t0xKaHRGDMnNWVY56vmqfCaxV12/Nqm0msOUi7be0NYCZHEmSCtMFC49bMglYcIfUWGBiXfu3q7ushgNzq7LWZGC7iFilWnC8XdXWKjM5kiSVppPX5ETEb6llYT4WEc9Su0vqJODSiNgXeApY8F6g64AdgRnA68A+AJn5UkT8DLir6nd8Zi66mHnhcRv5WocPy9c6SJJK0tmvdXjqqZc77Pfsxz++SvdYxtwCMzmSJBWm20YlHcwgR5KkwkR7H1Xcw7nwWJIkNSUzOZIklaaMRI5BjiRJpSkkxrFcJUmSmpOZHEmSCuPCY0mSpB7MIEeSJDUly1WSJBWmkGqVQY4kSaVxTY4kSVIPZpAjSZKakuUqSZIKU0i1ykyOJElqTmZyJEkqTBTyYgeDHEmSSlNGjGO5SpIkNSczOZIkFaaUhccGOZIkFaaQGMdylSRJak5mciRJKk0h9SqDHEmSClNGiGO5SpIkNSkzOZIkFaaQapVBjiRJxSkkyrFcJUmSmpKZHEmSClNGHscgR5Kk4hRSrbJcJUmSmpOZHEmSilNGKscgR5KkwliukiRJ6sEMciRJUlOyXCVJUmEsV0mSJPVgZnIkSSpOGakcMzmSJBUmouO29o0Xf42IP0fE/RFxd9XWPyKmRsRj1Z+rVO0REb+MiBkR8WBEbPphr9MgR5IkdYatMnNoZg6rvh8F3JiZQ4Abq+8AOwBDqm0ccMaHHdAgR5IkdYVRwITq8wRgdF37+VkzDegXEYM+zAAGOZIklSY6cGufBKZExD0RMa5qWy0zZ1WfnwNWqz4PBp6pO/bZqm2JufBYkqTCRAcuPK6ClnF1TeMzc/wi3bbIzJkRsSowNSL+Ur8zMzMissMmVTHIkSRJH1oV0Cwa1CzaZ2b15/MRcRWwGTA7IgZl5qyqHPV81X0msFbd4WtWbUvMcpUkSWqYiFghIlZa8BnYDngImASMrbqNBSZWnycB367ushoOzK0ray0RMzmSJBWmk594vBpwVdQG7QNcnJnXR8RdwKURsS/wFLBH1f86YEdgBvA6sM+HHTgyO7wE9pHNn/du95uUJEkN0rtPr04NO1595c0O+z274srLdtsnC1qukiRJTclylSRJpSnkDZ1mciRJUlMykyNJUmHKyOMY5EiSVJ5CohzLVZIkqSmZyZEkqTCFJHIMciRJKo53V0mSJPVcBjmSJKkpWa6SJKkwZRSrzORIkqQmZSZHkqTSFJLKMciRJKkwUUiUY7lKkiQ1JTM5kiSVpoxEjkGOJEmlKSTGsVwlSZKak5kcSZJKU0gqxyBHkqTilBHlWK6SJElNyUyOJEmFKSOPY5AjSVJ5ColyLFdJkqSmZCZHkqTCFJLIMciRJKk4UUaYY7lKkiQ1JYMcSZLUlCxXSZJUmEKqVWZyJElSczLIkSRJTclylSRJhYlC6lVmciRJUlMyyJEkSU0pMrOr56AmExHjMnN8V89DKo0/e9LCzOSoEcZ19QSkQvmzJ9UxyJEkSU3JIEeSJDUlgxw1gmsCpK7hz55Ux4XHkiSpKZnJkSRJTckgR5IkNSWDHEmS1JQMcrRYEdEnIpbq6nlIkrQkDHLUpojYELgIuCki/jsivt7Vc5JKERG+RFn6CAxy1KqI+ARwB/AOcCPwCeDIiDi3SycmFaD6+fvXiBjS1XOReipvIVeLIiKAnwGfyszdqrblge9W2/TMHNOFU5SaVkSsD/wRGAD8F3BaZv61Sycl9UBmctSirEW/g4FBdW2vA2cBvwQ+GRE/76LpSU0rIlYAjgKuA74P7Af8MCLW6cp5ST2RQY4+oMriANwL9ImIzyzYVwU6l1ArX301IlbtgilKzexd4D7g+sw8E9gL2BsDHWmJWa5SqyJiPWAatX9RHpKZc+r2DQJmAjtn5sSumaHUnCJihcx8re77LsAFwATgF5n5VET0Aj6emU921Tyl7s6V+2pVZj4eEXsAvwfeiIjjMvO5avc7wP3A3K6an9SsFgQ4EdEbeDczr6wyrOcDGRH/AewPrBMR36oyrJIWYZCjNmXmzRGxO3AZMCgiLqcW3HwTWAN4vAunJzW1zJwfNb0y84qISOBcYCSwNvB5AxypdZar1C4RsSlwCrAetSzOO8DXM/O+Lp2YVIiIiMzMiJgCfA74SmY+1NXzkrozgxy1W0SsDPQHVgSey8z/7eIpScWoSlf/DvwzMDQzH+zaGUndn+UqtVtmvgK80tXzkAo2HdjUAEdqHzM5ktRDLChZdfU8pJ7CIEeSJDUlHwYoSZKakkGOJElqSgY5kiSpKRnkSJKkpmSQI3WyiJgfEfdHxEMRcVlELP8RznVeROxWfT47IjZso++WEfHFDzHGXyPiY+1tX6TPq0s41nERccSSzlGSWmKQI3W+NzJzaGZ+Bnib2juI3hMRH+r5VZm5X2Y+3EaXLYElDnIkqacyyJG61q3A+lWW5daImAQ8HBG9I+LfI+KuiHgwIr4HteekRMSvIuLRiLgBWHXBiSLilogYVn0eGRH3RsQDEXFjRKxDLZg6tMoifSkiBkbEFdUYd0XEiOrYARExJSKmR8TZQCzuIiLi6oi4pzpm3CL7Tqvab4yIgVXbehFxfXXMrRHxqRbOeXBEPFxd/yUf8u9XUsF84rHURaqMzQ7A9VXTpsBnMvPJKlCYm5mfj4hlgNurdxZtAnwS2BBYDXiY2gsb6887EDgL+HJ1rv6Z+VJE/AZ4NTNPrvpdDJyWmbdFxNrAZGAD4Fjgtsw8PiK+Buzbjsv5TjXGcsBdEXFFZr4IrADcnZmHRsRPqnMfBIwH9s/MxyJic+B0YOtFznkUsG5mvhUR/drzdypJ9QxypM63XETcX32+FTiHWhnpzsx8smrfDthowXoboC8wBPgy8NvMnA/8LSJuauH8w4E/LDhXZr7Uyjy+CmwY8V6iZuWIWLEaY5fq2P+JiJfbcU0HR8TO1ee1qrm+CLwL/K5qvxC4shrji8BldWMv08I5HwQuioirgavbMQdJWohBjtT53sjMofUN1S/71+qbgB9k5uRF+u3YgfPoBQzPzDdbmEu7RcSW1AKmL2Tm6xFxC7BsK92zGnfOon8HLfgatYDrn4BjIuKzmTlviSYnqWiuyZG6p8nA9yNiKYCI+ERErAD8ARhTrdkZBGzVwrHTgC9HxLrVsf2r9r8DK9X1mwL8YMGXiBhaffwD8I2qbQdglcXMtS/wchXgfIpaJmmBXsCCbNQ3qJXBXgGejIjdqzEiIjauP2FE9ALWysybgSOrMVZczDwkaSEGOVL3dDa19Tb3RsRDwJnUMq9XAY9V+84H/rjogZn5AjCOWmnoAd4vF10D7Lxg4TFwMDCsWtj7MO/f5fVTakHSdGplq6cXM9frgT4R8QhwErUga4HXgM2qa9gaOL5q3wvYt5rfdGDUIufsDVwYEX8G7gN+mZlzFjMPSVqIL+iUJElNyUyOJElqSgY5kiSpKRnkSJKkpmSQI0mSmpJBjiRJakoGOZIkqSkZ5EiSpKZkkCNJkprS/wd07H8HIVrVwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_label, y, fpr, tpr, roc_auc = print_report(model, testload)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
