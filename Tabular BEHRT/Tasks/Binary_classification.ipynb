{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78498f0b-e7b4-4fbe-9e40-827fdf2025eb",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a24a8dd-3d4b-47fd-b884-6924e46f061a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 04:47:15.593041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 04:47:16.746643: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-28 04:47:16.746762: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-28 04:47:16.746774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('BEHRT/Early_integration/')\n",
    "sys.path.append('BEHRT/')\n",
    "\n",
    "\n",
    "from Utils.common import *\n",
    "from Utils.pytorch import load_model\n",
    "from Utils.utils import age_vocab, input_vocab, mod_vocab, delay_vocab\n",
    "from Utils.optimiser import adam\n",
    "import random\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from Utils.dataLoader_utils import seq_padding, random_mask, code2index,label2index, position_idx, index_seg\n",
    "from Utils.add_endpoints import add_endp\n",
    "from Utils.handle_file import handle_file\n",
    "\n",
    "hf = handle_file()\n",
    "from Utils.preprocessing import cal_age, cal_therapies, spark_init, cal_subtherapies, int_to_list, flatten_list, int_to_str, cal_therapies_fr, divide_frame\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import math\n",
    "import datetime \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from Utils import optimiser\n",
    "from Utils.dataLoader_utils import ImbSampler, OverSampler, StratifiedSampler\n",
    "from Utils.NextXVisit_v2 import NextVisit\n",
    "from Models.BertForClassification import BertForClassification\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from collections import Counter\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2d10a-8a1e-4c27-9da8-53b4c6ae1611",
   "metadata": {},
   "source": [
    "#### Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7581d49-b80f-4d70-b73f-0da8b8dbd6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NextVisit(Dataset):\n",
    "    def __init__(self, token2idx, label2idx, dataframe,  max_len, patid='patid', code='inputs', age='age', label = 'label', bio='biological features', delay = 'delays_in_months', NPI='NPI'):\n",
    "        # dataframe preproecssing\n",
    "        # filter out the patient with number of visits less than min_visit\n",
    "        self.vocab = token2idx\n",
    "        self.label_vocab = label2idx\n",
    "        self.max_len = max_len\n",
    "        self.code = dataframe[code]\n",
    "        self.age = dataframe[age]\n",
    "        self.label = dataframe[label]\n",
    "        self.patid = dataframe[patid]\n",
    "        self.bio = dataframe[bio]\n",
    "        self.NPI = dataframe[NPI]\n",
    "        self.delay = dataframe[delay]\n",
    "     \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        return: age, code, position, segmentation, mask, label\n",
    "        \"\"\"\n",
    "        # cut data\n",
    "        age = self.age[index]\n",
    "        code = self.code[index]\n",
    "        label = self.label[index]\n",
    "        patid = self.patid[index]\n",
    "        delay = self.delay[index]\n",
    "        bio = self.bio[index]\n",
    "        NPI = self.NPI[index]\n",
    "        \n",
    "        # change id type to list\n",
    "        patid = [patid]\n",
    "\n",
    "        # extract data\n",
    "        age = age[(-self.max_len+1):]\n",
    "        code = code[(-self.max_len+1):]\n",
    "        delay = delay[(-self.max_len+1):]\n",
    "        bio = bio[(-self.max_len+1):]\n",
    "        NPI = NPI[(-self.max_len+1):]\n",
    "\n",
    "        # mask 0:len(code) to 1, padding to be 0\n",
    "        mask = np.ones(self.max_len)\n",
    "        mask[len(code):] = 0\n",
    "\n",
    "        # pad age seque once and code sequence\n",
    "        age = seq_padding(age, self.max_len, symbol=0)\n",
    "        delay = seq_padding(delay, self.max_len, symbol=0)\n",
    "        bio = seq_padding(bio, self.max_len, symbol=[0]*5)\n",
    "        NPI = seq_padding(NPI, self.max_len, symbol=0)\n",
    "        \n",
    "        \n",
    "        tokens, code = code2index(code, self.vocab)\n",
    "        _, label = label2index(label, self.label_vocab)\n",
    "\n",
    "        # get position code and segment code\n",
    "        tokens = seq_padding(tokens, self.max_len)\n",
    "        position = position_idx(tokens)\n",
    "        segment = index_seg(tokens)\n",
    "\n",
    "        # pad code and label\n",
    "        code = seq_padding(code, self.max_len, symbol=self.vocab['PAD'])\n",
    "      #  label = seq_padding(label, self.max_len, symbol=-1)\n",
    "        \n",
    "\n",
    "        return torch.LongTensor(age).to(torch.float32), torch.LongTensor(code), torch.LongTensor(bio).to(torch.float32), torch.LongTensor(delay).to(torch.float32), torch.LongTensor(NPI).to(torch.float32), \\\n",
    "                torch.LongTensor(position), torch.LongTensor(segment), \\\n",
    "               torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(patid)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.code)\n",
    "    \n",
    "    \n",
    " \n",
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, segment, age\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, feature_dict=None):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "\n",
    "        if feature_dict is None:\n",
    "            self.feature_dict = {\n",
    "                'word': True,\n",
    "                'bio_features' : True,\n",
    "                'seg': True,\n",
    "                'age': True,\n",
    "                'delays':True,\n",
    "                'NPI':True,\n",
    "                'position': True,\n",
    "            }\n",
    "        else:\n",
    "            self.feature_dict = feature_dict\n",
    "\n",
    "        if feature_dict['word']:\n",
    "            self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "\n",
    "        if feature_dict['seg']:\n",
    "            self.segment_embeddings = nn.Embedding(config.seg_vocab_size, config.hidden_size)\n",
    "        \n",
    "        if feature_dict['bio_features']:\n",
    "            self.bio_embeddings = LinearActivation(config.bio_vocab_size, config.hidden_size)\n",
    "            \n",
    "        if feature_dict['age']:\n",
    "            self.age_embeddings = SineActivation(config.age_vocab_size, config.hidden_size)#.  \\\n",
    "         #   from_pretrained(self.SineActivation(config.age_vocab_size, config.hidden_size))\n",
    "            \n",
    "        if feature_dict['delays']:\n",
    "            self.delays_embeddings = SineActivation(config.delay_vocab_size, config.hidden_size)#. \\\n",
    "            #from_pretrained(self.SineActivation(config.delay_vocab_size, config.hidden_size))\n",
    "\n",
    "        if feature_dict['NPI']:\n",
    "            self.NPI_embeddings = LinearActivation(config.NPI_vocab_size, config.hidden_size)\n",
    "\n",
    "        if feature_dict['position']:\n",
    "            self.posi_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size). \\\n",
    "            from_pretrained(embeddings=self._init_posi_embedding(config.max_position_embeddings, config.hidden_size))\n",
    "\n",
    "        self.LayerNorm = Bert.modeling.BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "    def forward(self, word_ids, bio_ids, age_ids, delays_ids, seg_ids, posi_ids, NPI_ids):\n",
    "        embeddings = self.word_embeddings(word_ids)\n",
    "        \n",
    "      #  print(delays_ids)\n",
    "        if self.feature_dict['seg']:\n",
    "            segment_embed = self.segment_embeddings(seg_ids)\n",
    "            embeddings = embeddings + segment_embed\n",
    "        \n",
    "        if self.feature_dict['bio_features']:\n",
    "            bio_embed = self.bio_embeddings(bio_ids)\n",
    "            embeddings = embeddings + bio_embed\n",
    "            \n",
    "        if self.feature_dict['age']:\n",
    "       \n",
    "            age_embed = self.age_embeddings(age_ids)\n",
    "            embeddings = embeddings + age_embed\n",
    "          #  embeddings = torch.tensordot(embeddings, age_embed)\n",
    "            \n",
    "        if self.feature_dict['delays']:\n",
    "            delays_embed = self.delays_embeddings(delays_ids)\n",
    "            embeddings = embeddings + delays_embed\n",
    "         #   embeddings = torch.tensordot(embeddings, delays_embed)\n",
    "            \n",
    "        \n",
    "        if self.feature_dict['NPI']:\n",
    "            NPI_embed = self.NPI_embeddings(NPI_ids)\n",
    "            embeddings = embeddings + NPI_embed\n",
    "           # embeddings = torch.tensordot(embeddings, NPI_embed)\n",
    "            \n",
    "\n",
    "        if self.feature_dict['position']:\n",
    "            posi_embeddings = self.posi_embeddings(posi_ids)\n",
    "            embeddings = embeddings + posi_embeddings\n",
    "        \n",
    "    \n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings      \n",
    "    \n",
    "      \n",
    "    def SineActivation(self, in_features, out_features, max_position_embedding= 512):\n",
    "       \n",
    "        w0 = nn.parameter.Parameter(torch.randn(in_features, 1))\n",
    "        b0 = nn.parameter.Parameter(torch.randn(1))\n",
    "        w = nn.parameter.Parameter(torch.randn(in_features, out_features-1))\n",
    "        b = nn.parameter.Parameter(torch.randn(out_features-1))\n",
    "        f = torch.sin\n",
    "        \n",
    "        def t2v(tau, f, out_features, w, b, w0, b0, arg=None):\n",
    "            if arg:\n",
    "                v1 = f(torch.matmul(tau, w) + b, arg)\n",
    "            else:\n",
    "                #print(w.shape, t1.shape, b.shape)\n",
    "                v1 = f(torch.matmul(tau, w) + b)\n",
    "            v2 = torch.matmul(tau, w0) + b0\n",
    "            #print(v1.shape)\n",
    "            return torch.cat([v1, v2], -1)\n",
    "        \n",
    "        tau = np.ones(max_position_embedding, dtype=np.float32)\n",
    "        out_list = list()\n",
    "        \n",
    "        for pos in tau: \n",
    "            pos = torch.tensor(pos.reshape(-1,1))\n",
    "            out = t2v(pos, f, out_features, w, b, w0, b0)\n",
    "            out_list.append(torch.flatten(out))\n",
    "        return torch.stack(out_list, 0)\n",
    "    \n",
    "\n",
    "    def _init_posi_embedding(self, max_position_embedding, hidden_size):\n",
    "        def even_code(pos, idx):\n",
    "            return np.sin(pos / (10000 ** (2 * idx / hidden_size)))\n",
    "\n",
    "        def odd_code(pos, idx):\n",
    "            return np.cos(pos / (10000 ** (2 * idx / hidden_size)))\n",
    "\n",
    "        # initialize position embedding table\n",
    "        lookup_table = np.zeros((max_position_embedding, hidden_size), dtype=np.float32)\n",
    "\n",
    "        # reset table parameters with hard encoding\n",
    "        # set even dimension\n",
    "        for pos in range(max_position_embedding):\n",
    "            for idx in np.arange(0, hidden_size, step=2):\n",
    "                lookup_table[pos, idx] = even_code(pos, idx)\n",
    "        # set odd dimension\n",
    "        for pos in range(max_position_embedding):\n",
    "            for idx in np.arange(1, hidden_size, step=2):\n",
    "                lookup_table[pos, idx] = odd_code(pos, idx)\n",
    "\n",
    "        return torch.tensor(lookup_table)\n",
    "        \n",
    "def t2v(tau, f, out_features, w, b, w0, b0, arg=None):\n",
    "    if arg:\n",
    "        v1 = f(torch.matmul(tau, w) + b, arg)\n",
    "    else:\n",
    "        #print(w.shape, t1.shape, b.shape)\n",
    "        v1 = f(torch.matmul(tau, w) + b)\n",
    "    v2 = torch.matmul(tau, w0) + b0\n",
    "    #print(v1.shape)\n",
    "    return torch.cat([v1, v2], -1)\n",
    "\n",
    "class SineActivation(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SineActivation, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.w0 = nn.parameter.Parameter(torch.randn(in_features, 1))\n",
    "        self.b0 = nn.parameter.Parameter(torch.randn(1))\n",
    "        self.w = nn.parameter.Parameter(torch.randn(in_features, out_features-1))\n",
    "        self.b = nn.parameter.Parameter(torch.randn(out_features-1))\n",
    "        self.f = torch.sin\n",
    "      #  self.fc1 = nn.Linear(out_features, out_features)\n",
    "\n",
    "\n",
    "    def forward(self, tau):\n",
    "        out_list = list()\n",
    "        for pos in tau: \n",
    "            pos = torch.tensor(np.expand_dims(pos.cpu(), axis=1))\n",
    "            out = t2v(pos.to(global_params['device']), self.f, self.out_features, self.w, self.b, self.w0, self.b0)\n",
    "        #    out = self.fc1(x)\n",
    "            out_list.append(out)\n",
    "\n",
    "        return torch.stack(out_list, 0)\n",
    "\n",
    "class LinearActivation(nn.Module):\n",
    "    def __init__(self, in_features, hidden_size):\n",
    "        super(LinearActivation, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        out_list = list()\n",
    "        LinearLayer = nn.Linear(self.in_features, self.hidden_size)\n",
    "        LinearLayer = LinearLayer.to(global_params['device'])   ### move layer to device because all the inputs are in the gpu\n",
    "       \n",
    "        for idx in inp:\n",
    "          \n",
    "          ## if dim of idx is >= than 1 -> when number of biological features is more than one\n",
    "            try:   \n",
    "                out = LinearLayer(idx)\n",
    "            except RuntimeError:\n",
    "               # print('linearlayer {}'.format(LinearLayer.weight.dtype))\n",
    "                 ## if we need to expand dimension move it to cpu first then remove it to gpu (next line)\n",
    "                out = LinearLayer(idx.reshape(-1,1).to(global_params['device']))\n",
    "            out_list.append(out)\n",
    "        return torch.stack(out_list, 0)\n",
    "\n",
    "    \n",
    "class BertModel(Bert.modeling.BertPreTrainedModel):\n",
    "    def __init__(self, config, feature_dict,  add_pooling_layer=True):\n",
    "        super(BertModel, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.embeddings = BertEmbeddings(config=config, feature_dict = feature_dict)\n",
    "        self.encoder = BertEncoder(config=config)\n",
    "        self.pooler = BertPooler(config)\n",
    "        self.apply(self.init_bert_weights)\n",
    "       \n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, input_ids, bio_ids, age_ids, delays_ids, seg_ids, posi_ids,  NPI_ids, attention_mask, output_attentions= None, output_hidden_states = None, return_dict = None)-> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "        \n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions \n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        \n",
    "\n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
    "        # this attention mask is more simple than the triangular masking of causal attention\n",
    "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(input_ids, bio_ids, age_ids, delays_ids, seg_ids, posi_ids, NPI_ids)\n",
    "        encoder_outputs = self.encoder(embedding_output,\n",
    "                                      attention_mask = extended_attention_mask, output_attentions = output_attentions, output_hidden_states = output_hidden_states, return_dict = return_dict)\n",
    "        \n",
    "       # sequence_output = encoded_layers[-1]\n",
    "         \n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None \n",
    "        \n",
    "     #   if not output_all_encoded_layers:\n",
    "    #        encoded_layers = encoded_layers[-1]\n",
    "            \n",
    "        if not return_dict: \n",
    "            return (sequence_output, pooled_output) + encoded_layers[1:]\n",
    "         #   return encoded_layers, pooled_output\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=sequence_output,\n",
    "            pooler_output=pooled_output,\n",
    "            past_key_values = encoder_outputs.past_key_values,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "            cross_attentions=encoder_outputs.cross_attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "class BertForClassification(Bert.modeling.BertPreTrainedModel):\n",
    "    def __init__(self, config,  num_labels, feature_dict, class_weights):\n",
    "        super(BertForClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config, feature_dict)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "        self.class_weights = class_weights\n",
    "        self.apply(self.init_bert_weights)\n",
    "        \n",
    "    def forward(self, input_ids=None, bio_ids=None, age_ids=None, delays_ids = None, seg_ids=None, posi_ids=None,  NPI_ids =None, attention_mask=None, labels=None, output_attentions = True, output_hidden_states = True, return_dict = True)-> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        outputs = self.bert(input_ids, bio_ids, age_ids, delays_ids, seg_ids, posi_ids,  NPI_ids , attention_mask,  output_attentions = output_attentions, output_hidden_states=output_hidden_states, return_dict = return_dict)\n",
    "       \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "\n",
    "        if labels is not None:\n",
    "            \n",
    "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.class_weights)\n",
    "            loss = loss_fct(logits, labels)#.unsqueeze(1))\n",
    "  \n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "    \n",
    "def calculate_pos_weights(class_counts):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    neg_counts = [len(data)-pos_count for pos_count in class_counts]\n",
    "    for cdx, pos_count, neg_count in enumerate(zip(class_counts,  neg_counts)):\n",
    "        pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b0fd5-3da5-445c-bfa1-e35e9a256223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_pretrained_bert as Bert\n",
    "import numpy as np\n",
    "from typing import Optional, Tuple, Union\n",
    "from transformers.models.bert.modeling_bert import *\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, BaseModelOutputWithPoolingAndCrossAttentions\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "#P/¨%from dataLoader.utils import seq_padding,code2index,label2index, position_idx, index_seg\n",
    "import torch\n",
    "\n",
    "\n",
    "class NextVisit(Dataset):\n",
    "    def __init__(self, token2idx, label2idx, mod2idx, age2idx, del2idx, NPI2idx, dataframe,  max_len, patid='patid', code='inputs', age='age', label = 'label', mod = 'modalities', delay = 'delays_in_months', NPI='NPI6'):\n",
    "        # dataframe preproecssing\n",
    "        # filter out the patient with number of visits less than min_visit\n",
    "        self.vocab = token2idx\n",
    "        self.mod2idx = mod2idx\n",
    "        self.age2idx = age2idx\n",
    "        self.del2idx = del2idx\n",
    "        self.NPI2idx = NPI2idx\n",
    "        self.label_vocab = label2idx\n",
    "        self.max_len = max_len\n",
    "        self.code = dataframe[code]\n",
    "        self.age = dataframe[age]\n",
    "        self.label = dataframe[label]\n",
    "        self.patid = dataframe[patid]\n",
    "        self.modalities = dataframe[mod]\n",
    "        self.NPI = dataframe[NPI]\n",
    "        self.delay = dataframe[delay]\n",
    "     \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        return: age, code, position, segmentation, mask, label\n",
    "        \"\"\"\n",
    "        # cut data\n",
    "        age = self.age[index]\n",
    "        code = self.code[index]\n",
    "        label = self.label[index]\n",
    "        patid = self.patid[index]\n",
    "        delay = self.delay[index]\n",
    "        modalities = self.modalities[index]\n",
    "        NPI = self.NPI[index]\n",
    "        \n",
    "        # change id type to list\n",
    "        patid = [patid]\n",
    "\n",
    "        # extract data\n",
    "        age = age[(-self.max_len+1):]\n",
    "        code = code[(-self.max_len+1):]\n",
    "        delay = delay[(-self.max_len+1):]\n",
    "        modalities = modalities[(-self.max_len+1):]\n",
    "        NPI = NPI[(-self.max_len+1):]\n",
    "\n",
    "        # mask 0:len(code) to 1, padding to be 0\n",
    "        mask = np.ones(self.max_len)\n",
    "        mask[len(code):] = 0\n",
    "\n",
    "        # pad age seque once and code sequence\n",
    "        age = seq_padding(age, self.max_len, token2idx=self.age2idx)\n",
    "        delay = seq_padding(delay, self.max_len, token2idx=self.del2idx)\n",
    "        modalities = seq_padding(modalities, self.max_len, token2idx=self.mod2idx)\n",
    "        NPI = seq_padding(NPI, self.max_len, token2idx=self.NPI2idx)\n",
    "      \n",
    "        tokens, code = code2index(code, self.vocab)\n",
    "        _, label = label2index(label, self.label_vocab)\n",
    "\n",
    "        # get position code and segment code\n",
    "        tokens = seq_padding(tokens, self.max_len)\n",
    "        position = position_idx(tokens)\n",
    "        segment = index_seg(tokens)\n",
    "\n",
    "        # pad code and label\n",
    "        code = seq_padding(code, self.max_len, symbol=self.vocab['PAD'])\n",
    "      #  label = seq_padding(label, self.max_len, symbol=-1)\n",
    "        \n",
    "\n",
    "        return torch.LongTensor(age), torch.LongTensor(code), torch.LongTensor(modalities), torch.LongTensor(delay), torch.LongTensor(NPI), \\\n",
    "                torch.LongTensor(position), torch.LongTensor(segment), \\\n",
    "               torch.LongTensor(mask), torch.LongTensor(label), torch.LongTensor(patid)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.code)\n",
    "    \n",
    "    \n",
    " \n",
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, segment, age\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, feature_dict=None):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "\n",
    "        if feature_dict is None:\n",
    "            self.feature_dict = {\n",
    "                'word': True,\n",
    "                'modalities' : True,\n",
    "                'seg': True,\n",
    "                'age': True,\n",
    "                'delays':True,\n",
    "                'NPI':True,\n",
    "                'position': True,\n",
    "            }\n",
    "        else:\n",
    "            self.feature_dict = feature_dict\n",
    "\n",
    "        if feature_dict['word']:\n",
    "            self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
    "\n",
    "        if feature_dict['seg']:\n",
    "            self.segment_embeddings = nn.Embedding(config.seg_vocab_size, config.hidden_size)\n",
    "        \n",
    "        if feature_dict['modalities']:\n",
    "            self.modalities_embeddings = nn.Embedding(config.modalities_vocab_size, config.hidden_size)\n",
    "\n",
    "        if feature_dict['age']:\n",
    "            self.age_embeddings = nn.Embedding(config.age_vocab_size, config.hidden_size)\n",
    "            \n",
    "        if feature_dict['delays']:\n",
    "            self.delays_embeddings = nn.Embedding(config.delays_vocab_size, config.hidden_size)\n",
    "\n",
    "        if feature_dict['NPI']:\n",
    "            self.NPI_embeddings = nn.Embedding(config.NPI_vocab_size, config.hidden_size)\n",
    "\n",
    "        if feature_dict['position']:\n",
    "            self.posi_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size). \\\n",
    "            from_pretrained(embeddings=self._init_posi_embedding(config.max_position_embeddings, config.hidden_size))\n",
    "\n",
    "        self.LayerNorm = Bert.modeling.BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "    \n",
    "\n",
    "    def forward(self, word_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids, NPI_ids):\n",
    "        embeddings = self.word_embeddings(word_ids)\n",
    "        \n",
    "        if self.feature_dict['seg']:\n",
    "            segment_embed = self.segment_embeddings(seg_ids)\n",
    "            embeddings = embeddings + segment_embed\n",
    "        \n",
    "        if self.feature_dict['modalities']:\n",
    "            modalities_embed = self.modalities_embeddings(modalities_ids)\n",
    "            embeddings = embeddings + modalities_embed\n",
    "\n",
    "        if self.feature_dict['age']:\n",
    "            age_embed = self.age_embeddings(age_ids)\n",
    "            embeddings = embeddings + age_embed\n",
    "            \n",
    "        if self.feature_dict['delays']:\n",
    "            delays_embed = self.delays_embeddings(delays_ids)\n",
    "            embeddings = embeddings + delays_embed\n",
    "        \n",
    "        if self.feature_dict['NPI']:\n",
    "            NPI_embed = self.delays_embeddings(NPI_ids)\n",
    "            embeddings = embeddings + NPI_embed\n",
    "\n",
    "        if self.feature_dict['position']:\n",
    "            posi_embeddings = self.posi_embeddings(posi_ids)\n",
    "            embeddings = embeddings + posi_embeddings\n",
    "\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings        \n",
    "\n",
    "    def _init_posi_embedding(self, max_position_embedding, hidden_size):\n",
    "        def even_code(pos, idx):\n",
    "            return np.sin(pos / (10000 ** (2 * idx / hidden_size)))\n",
    "\n",
    "        def odd_code(pos, idx):\n",
    "            return np.cos(pos / (10000 ** (2 * idx / hidden_size)))\n",
    "\n",
    "        # initialize position embedding table\n",
    "        lookup_table = np.zeros((max_position_embedding, hidden_size), dtype=np.float32)\n",
    "\n",
    "        # reset table parameters with hard encoding\n",
    "        # set even dimension\n",
    "        for pos in range(max_position_embedding):\n",
    "            for idx in np.arange(0, hidden_size, step=2):\n",
    "                lookup_table[pos, idx] = even_code(pos, idx)\n",
    "        # set odd dimension\n",
    "        for pos in range(max_position_embedding):\n",
    "            for idx in np.arange(1, hidden_size, step=2):\n",
    "                lookup_table[pos, idx] = odd_code(pos, idx)\n",
    "\n",
    "        return torch.tensor(lookup_table)\n",
    "    \n",
    "\n",
    "class BertModel(Bert.modeling.BertPreTrainedModel):\n",
    "    def __init__(self, config, feature_dict,  add_pooling_layer=True):\n",
    "        super(BertModel, self).__init__(config)\n",
    "        self.config = config\n",
    "        self.embeddings = BertEmbeddings(config=config, feature_dict = feature_dict)\n",
    "        self.encoder = BertEncoder(config=config)\n",
    "        self.pooler = BertPooler(config)\n",
    "        self.apply(self.init_bert_weights)\n",
    "       \n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, input_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids,  NPI_ids, attention_mask, output_attentions= None, output_hidden_states = None, return_dict = None)-> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "        \n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions \n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        \n",
    "\n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
    "        # this attention mask is more simple than the triangular masking of causal attention\n",
    "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(input_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids, NPI_ids)\n",
    "        encoder_outputs = self.encoder(embedding_output,\n",
    "                                      attention_mask = extended_attention_mask, output_attentions = output_attentions, output_hidden_states = output_hidden_states, return_dict = return_dict)\n",
    "        \n",
    "       # sequence_output = encoded_layers[-1]\n",
    "         \n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None \n",
    "        \n",
    "     #   if not output_all_encoded_layers:\n",
    "    #        encoded_layers = encoded_layers[-1]\n",
    "            \n",
    "        if not return_dict: \n",
    "            return (sequence_output, pooled_output) + encoded_layers[1:]\n",
    "         #   return encoded_layers, pooled_output\n",
    "\n",
    "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "            last_hidden_state=sequence_output,\n",
    "            pooler_output=pooled_output,\n",
    "            past_key_values = encoder_outputs.past_key_values,\n",
    "            hidden_states=encoder_outputs.hidden_states,\n",
    "            attentions=encoder_outputs.attentions,\n",
    "            cross_attentions=encoder_outputs.cross_attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "class BertForClassification(Bert.modeling.BertPreTrainedModel):\n",
    "    def __init__(self, config,  num_labels, feature_dict, class_weights):\n",
    "        super(BertForClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config, feature_dict)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "        self.class_weights = class_weights\n",
    "        self.apply(self.init_bert_weights)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids=None, modalities_ids = None, age_ids=None, delays_ids = None, seg_ids=None, posi_ids=None,  NPI_ids =None, attention_mask=None, labels=None, output_attentions = True, output_hidden_states = True, return_dict = True)-> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        outputs = self.bert(input_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids,  NPI_ids , attention_mask,  output_attentions = output_attentions, output_hidden_states=output_hidden_states, return_dict = return_dict)\n",
    "       \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "\n",
    "        if labels is not None:\n",
    "            \n",
    "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.class_weights)\n",
    "            loss = loss_fct(logits, labels)#.unsqueeze(1))\n",
    "  \n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "    \n",
    "def calculate_pos_weights(class_counts):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    neg_counts = [len(data)-pos_count for pos_count in class_counts]\n",
    "    for cdx, pos_count, neg_count in enumerate(zip(class_counts,  neg_counts)):\n",
    "        pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a1bbe8-b49c-47d4-a822-6c044c03c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot results\n",
    "def display_training_stats(data):\n",
    "    import pandas as pd\n",
    "\n",
    "    \n",
    "    # Create a DataFrame from our training statistics.\n",
    "    df_stats = pd.DataFrame(data=data)\n",
    "    \n",
    "    # Display floats with two decimal places.\n",
    " #   pd.set_option('Average Train f1 score', 2)\n",
    " #   pd.set_option('Average Valid f1 score', 2)\n",
    " #   \n",
    "    # Use the 'epoch' as the row index.\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "    \n",
    " #   hf._dump_pkl(df_stats, 'training_stats')    \n",
    "    # Display the table.\n",
    "    return df_stats\n",
    "\n",
    "def cal_mean(df_stats, feature, epochs):\n",
    "    return [np.mean(df_stats.loc[x, feature]) for x in range(1,epochs+1)]\n",
    "\n",
    "def cal_std(df_stats, feature, epochs):\n",
    "    return [np.std(df_stats.loc[x, feature]) for x in range(1,epochs+1)]\n",
    "     \n",
    "\n",
    "def plot_history(training_stats, epochs):\n",
    "    \n",
    "    sn.set(style=\"whitegrid\")\n",
    "    fig, ((ax1, ax2)) = plt.subplots(1,2, figsize = (20,7))\n",
    "    \n",
    "    mean_f1_train = cal_mean(display_training_stats(training_stats), 'Average Train f1 score', epochs)\n",
    "    std_f1_train = cal_std(display_training_stats(training_stats), 'Average Train f1 score', epochs)\n",
    "    \n",
    "    mean_f1_valid = cal_mean(display_training_stats(training_stats), 'Average Valid f1 score', epochs)\n",
    "    std_f1_valid = cal_std(display_training_stats(training_stats), 'Average Valid f1 score', epochs)\n",
    "    \n",
    "    mean_loss_train = cal_mean(display_training_stats(training_stats), 'Training Loss', epochs)\n",
    "    std_loss_train = cal_std(display_training_stats(training_stats), 'Training Loss', epochs)\n",
    "    \n",
    "    mean_loss_valid = cal_mean(display_training_stats(training_stats), 'Validation Loss', epochs)\n",
    "    std_loss_valid = cal_std(display_training_stats(training_stats), 'Validation Loss', epochs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax1.plot(range(epochs), mean_f1_train, 'b-', label='Train f1 score')\n",
    "    ax1.fill_between(range(epochs), np.array(mean_f1_train) - np.array(std_f1_train), np.array(mean_f1_train) + np.array(std_f1_train), color='b', alpha=0.2)\n",
    "    ax1.plot(range(epochs), mean_f1_valid, 'r--', label='Valid f1 score')\n",
    "    ax1.fill_between(range(epochs), np.array(mean_f1_valid) - np.array(std_f1_valid), np.array(mean_f1_valid) + np.array(std_f1_valid), color='r', alpha=0.2)\n",
    "   \n",
    "    ax2.plot(range(epochs), mean_loss_train, 'b-', label='Train loss')\n",
    "    ax2.fill_between(range(epochs), np.array(mean_loss_train) - np.array(std_loss_train), np.array(mean_loss_train) + np.array(std_loss_train), color='b', alpha=0.2)\n",
    "    ax2.plot(range(epochs), mean_loss_valid, 'r--', label='Valid loss')\n",
    "    ax2.fill_between(range(epochs), np.array(mean_loss_valid) - np.array(std_loss_valid), np.array(mean_loss_valid) + np.array(std_loss_valid), color='r', alpha=0.2)\n",
    "   \n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def precision_test(output, label):\n",
    "    \n",
    "  #  sig = nn.Sigmoid()\n",
    "  #  output=sig(logits)\n",
    "    label=np.argmax(label, axis=1)#.flatten().numpy()\n",
    "    output=np.argmax(output, axis=1)#.flatten().numpy()\n",
    "  #  output = np.argmax(np.where(output >= 0.5, 1, 0), axis=1).flatten()\n",
    "    roc = sklearn.metrics.roc_auc_score(label ,output, average='macro')\n",
    "    f1 =  sklearn.metrics.f1_score(label, output, average=\"macro\")\n",
    "    recall = sklearn.metrics.recall_score(label, output, average=\"macro\")\n",
    "    precision = sklearn.metrics.precision_score(label, output, average=\"macro\")\n",
    " \n",
    "    return f1, roc, recall, precision, output, label\n",
    "\n",
    "\n",
    "def plot_roc_auc(fpr, tpr, roc_auc):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import sklearn.metrics as metrics\n",
    "    \n",
    "   \n",
    "    sn.set_style(\"whitegrid\")\n",
    "    fig,ax = plt.subplots(figsize=(13, 9))\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, '#067062', label = 'AUC = %0.2f' % roc_auc)\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    #plt.savefig('ROC_12.png')\n",
    "    plt.show()\n",
    "\n",
    "def cm(true, predicted, fig_name, cmap = 'Purples'):\n",
    "    \n",
    "    cm = confusion_matrix(true, predicted)\n",
    "\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    try:\n",
    "        heatmap = sn.heatmap(df_cm, annot=True, cmap=cmap)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "    plt.ylabel('True labels')\n",
    "    plt.xlabel('Predicted labels')\n",
    "   #fig.savefig(fig_name+'.png')\n",
    "    return \n",
    "\n",
    "def print_report(model, data): \n",
    "     \n",
    "    y = []\n",
    "    y_label = []\n",
    "    total_f1, total_roc, total_precision, total_recall = [], [], [], []\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for step, batch in enumerate(data):\n",
    "\n",
    "\n",
    "        age_ids, input_ids, mod_ids, del_ids, NPI_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
    "       \n",
    "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        mod_ids = mod_ids.to(global_params['device'])\n",
    "        del_ids = del_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        NPI_ids = NPI_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids, NPI_ids, attention_mask=attMask, labels=targets, output_attentions=True)\n",
    "        \n",
    "\n",
    "        logits = outputs.logits.cpu()\n",
    "        targets = targets.cpu()\n",
    "\n",
    "        y_label.append(targets)\n",
    "        y.append(logits)\n",
    "        \n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "\n",
    "     # Compute ROC curve and ROC area for each class\n",
    "    f1, roc, recall, precision, output, label = precision_test(y, y_label)\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    label = np.argmax(y_label, axis=1)\n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(y)\n",
    "\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(label, output[:,1])\n",
    " #   fpr, tpr, _ = sklearn.metrics.roc_curve(label, y_label[:,1])\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "    ## Plot ##  \n",
    "    target_names = ['Non relapse', 'Relapse']\n",
    "\n",
    "    print(\"f1 score is {:.4f}, Precision is {:.4f}, Recall is {:.4f}\".format(f1, precision, recall))\n",
    "    print(classification_report(label,  np.argmax(output, axis=1), target_names=target_names))\n",
    "   # cm(label,  np.argmax(np.where(output >= 0.5, 1, 0), axis=1), 'cm')\n",
    "    cm(label, np.argmax(output, axis=1), 'cm')\n",
    "    \n",
    "    plot_roc_auc(fpr, tpr, roc_auc)\n",
    "  #  probs = F.softmax(y, dim=1).cpu().numpy()\n",
    "  #  return probs, label\n",
    "    return y_label, y, fpr, tpr, roc_auc  \n",
    "\n",
    "\n",
    "def load_data(data, config, sampling = True, X_tr=None , y_tr = None):\n",
    "    Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, NPI2idx=NPIVocab, dataframe= data, max_len=global_params['max_len_seq'], code='inputs_normal_range_preprocessed_100_therap_removed', delay ='delays_100_therap_removed',\n",
    "                         age = \"age_100_therap_removed\", mod ='modalities_100_therap_removed', NPI= 'NPI6')\n",
    "    if sampling:\n",
    "        return DataLoader(dataset= Dset, batch_size=config.batch_size,  sampler = StratifiedSampler(X_tr, y_tr, batch_size=config.batch_size))\n",
    "    else:\n",
    "        return DataLoader(dataset= Dset, batch_size=config.batch_size, shuffle=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f35671-38c1-43e7-b8bd-f338b0e65c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = sklearn.metrics.roc_curve(y_true, preds)\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.9, 1, 0)\n",
    "    accuracy = sklearn.metrics.f1_score(y_true, y_pred, average=\"macro\")\n",
    "   # accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd337188-4d02-4014-9ca2-7ac4c670566c",
   "metadata": {},
   "source": [
    "#### Performing checks for the resources available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b818176c-4bd1-46a8-b0e0-ae4b7a20affe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available. \n",
      "We will use the GPU: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Check if the gpu is available \"\"\"\n",
    "if torch.cuda.is_available():\n",
    "   \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"There are %d GPU(s) available. \" %torch.cuda.device_count())\n",
    "    print(\"We will use the GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
    "    \n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e7bf9af-82be-4781-98cb-0d05d22b729a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Empty the cache to enable the use of the gpu \"\"\"\n",
    "\n",
    "def empty_cuda():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b25f0b-c2eb-468e-82ee-d47069a8a9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "def report_gpu():\n",
    "    print(torch.cuda.list_gpu_processes())\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5d53c-cceb-4938-af9c-fc7df79fc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "os.environ['https_proxy'] = \"\"\n",
    "os.environ['http_proxy'] = \"\"\n",
    "os.environ['no_proxy']= \"\"\n",
    "os.environ['HTTPS_PROXY']= \"\"\n",
    "os.environ['HTTP_PROXY']= \"\"\n",
    "os.environ['NO_PROXY']= \"\"\n",
    "\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'BEHRT/Early_integration/Tasks/Binary_clf_3y.ipynb'\n",
    "os.environ['WANDB_API_KEY'] = \"4944e153a8b0f45a64d749b14d6916d253a54426\"\n",
    "os.environ['WANDB_NAME'] = \"Binary_clf_npi\"\n",
    "os.environ['WANDB_NOTES'] = \"Hyperparameters tuning using wandb for binary clf: Bayesian and hyperband scheduler\"\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a691f96-f00a-4748-9f42-2cb9d22a8033",
   "metadata": {},
   "source": [
    "#### Run Binary classification \n",
    "1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5adc5959-e763-4719-8d36-25c616420c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model_path =  'BEHRT/Early_integration/Tasks/Output/Second_run/MLM_npi_final.pkl'   # pretrained MLM path\n",
    "\n",
    "file_config = { 'data':'BEHRT/Early_integration/Files/data_preprocessed_1y_not_chunked_NPI.pkl',\n",
    "               'index_to_delete': 'BEHRT/Early_integration/Files/index_to_delete.pkl',\n",
    "                'labels' : 'BEHRT/Early_integration/Files/relapses.csv', \n",
    "                'test_idx' : 'BEHRT/Early_integration/Files/test_idx.pkl', \n",
    "                }\n",
    "\n",
    "\n",
    "global_params = {\n",
    "    'device': device,\n",
    "    'output_dir': 'BEHRT/Early_integration/Tasks/Output/clf_npi', # output folder\n",
    "    'best_name': 'clf_npi_3y', #'clf_quantiles_3',  # output model name\n",
    "    'max_len_seq': 512, #100,\n",
    "    'max_age': 110,\n",
    "    'max_delay': 30, ## = 30years\n",
    "    'age_month': 12,\n",
    "    'delay_month': 0.25,\n",
    "    'age_year': False,\n",
    "    'age_symbol': None,\n",
    "    'min_visit': 3,\n",
    "    \n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_len_seq'],\n",
    "    'device': device,\n",
    "}\n",
    "\n",
    "feature_dict = {\n",
    "    'word':True,\n",
    "    'seg':True,\n",
    "    'age':True,\n",
    "    'modalities': True,\n",
    "    'delays': True,\n",
    "    'position': True, \n",
    "    'NPI' : True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294488fe-1f32-4538-9bfc-759d10af5a9a",
   "metadata": {},
   "source": [
    "2. Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "647f6751-a91a-4de1-8acf-2a57473e7f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs_quantiles_preprocessed</th>\n",
       "      <th>inputs_normal_range_preprocessed</th>\n",
       "      <th>inputs_curve_intersections_preprocessed</th>\n",
       "      <th>modalities</th>\n",
       "      <th>age</th>\n",
       "      <th>delays</th>\n",
       "      <th>report</th>\n",
       "      <th>inputs_quantiles_preprocessed_10</th>\n",
       "      <th>inputs_normal_range_preprocessed_10</th>\n",
       "      <th>inputs_curve_intersections_preprocessed_10</th>\n",
       "      <th>...</th>\n",
       "      <th>status_rfs_5y</th>\n",
       "      <th>status_drfs_5y</th>\n",
       "      <th>status_rfs_surg_18mo</th>\n",
       "      <th>status_drfs_surg_18mo</th>\n",
       "      <th>status_rfs_surg_2y</th>\n",
       "      <th>status_drfs_surg_2y</th>\n",
       "      <th>status_rfs_surg_3y</th>\n",
       "      <th>status_drfs_surg_3y</th>\n",
       "      <th>label</th>\n",
       "      <th>status_drfs_surg_5y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_dossier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00002f6df9cfcb97985c88f5787ba874</th>\n",
       "      <td>[CLS, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[CLS, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[CLS, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[DEB, biologique, biologique, biologique, biol...</td>\n",
       "      <td>[61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 6...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[\\nCorps du document\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n16/07/...</td>\n",
       "      <td>[CLS, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[CLS, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[CLS, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      inputs_quantiles_preprocessed  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [CLS, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                   inputs_normal_range_preprocessed  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [CLS, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            inputs_curve_intersections_preprocessed  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [CLS, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                                         modalities  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [DEB, biologique, biologique, biologique, biol...   \n",
       "\n",
       "                                                                                age  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 6...   \n",
       "\n",
       "                                                                             delays  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                                             report  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [\\nCorps du document\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n16/07/...   \n",
       "\n",
       "                                                   inputs_quantiles_preprocessed_10  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [CLS, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                inputs_normal_range_preprocessed_10  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [CLS, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         inputs_curve_intersections_preprocessed_10  \\\n",
       "Num_dossier                                                                           \n",
       "00002f6df9cfcb97985c88f5787ba874  [CLS, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                  ... status_rfs_5y status_drfs_5y  \\\n",
       "Num_dossier                       ...                                \n",
       "00002f6df9cfcb97985c88f5787ba874  ...             0              0   \n",
       "\n",
       "                                 status_rfs_surg_18mo status_drfs_surg_18mo  \\\n",
       "Num_dossier                                                                   \n",
       "00002f6df9cfcb97985c88f5787ba874                    0                     0   \n",
       "\n",
       "                                 status_rfs_surg_2y status_drfs_surg_2y  \\\n",
       "Num_dossier                                                               \n",
       "00002f6df9cfcb97985c88f5787ba874                  0                   0   \n",
       "\n",
       "                                 status_rfs_surg_3y status_drfs_surg_3y label  \\\n",
       "Num_dossier                                                                     \n",
       "00002f6df9cfcb97985c88f5787ba874                  0                   0     0   \n",
       "\n",
       "                                 status_drfs_surg_5y  \n",
       "Num_dossier                                           \n",
       "00002f6df9cfcb97985c88f5787ba874                   0  \n",
       "\n",
       "[1 rows x 86 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Import train data \"\"\"\n",
    "data =  hf._load_pkl(file_config['data'])\n",
    "\n",
    "\"\"\"Import labels \"\"\"\n",
    "labels = hf._load_csv(file_config['labels'])\n",
    "#labels.drop(['Unnamed: 0', 'status_drfs_5y'], axis='columns', inplace = True)\n",
    "labels.rename(columns={'status_rfs_surg_3y': 'label'}, inplace=True)\n",
    "\n",
    "\"\"\"Merge label and data \"\"\"\n",
    "data = pd.merge(data, labels, on=['Num_dossier'])\n",
    "data.set_index('Num_dossier', inplace=True)\n",
    "\n",
    "# Display 3 first rows\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef4909e-bbee-4d65-aa79-8015f9a65c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10029"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Delete censored patients and relapsed before 18months post surgery\n",
    "\n",
    "index_to_del = hf._load_pkl(file_config['index_to_delete'])  # 0: 12mo, 1:18mo, 2:24mo, 3:36mo, 4:60mo\n",
    "list_of_index = index_to_del['list_of_relapses_before_12mo']+index_to_del['list_of_censored_before_3y']\n",
    "len(list_of_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04fea36-3474-440f-82e0-12f94dfe0c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data = data.loc[~data['Num_dossier'].isin(list(list_of_index))] #I lost 3722 patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8991f600-12b3-46f1-bba8-a44351cb55ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We lost 0 patient\n"
     ]
    }
   ],
   "source": [
    "# remove patients with visits less than min visit\n",
    "previous_shape = data.shape[0]\n",
    "\n",
    "data['length'] = data['inputs_normal_range_preprocessed_100_therap_removed'].apply(lambda x: len([i for i in range(len(x)) if x[i] == 'SEP']))\n",
    "data = data[data['length'] >= global_params['min_visit']]\n",
    "#data = data.reset_index(drop=True)\n",
    "\n",
    "print(\"We lost {} patient\".format(previous_shape - data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff1b5cd-e187-49c8-b148-cb68eae6b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the vocabulary from the MLM\n",
    "\n",
    "whole_seq = hf._load_pkl('BEHRT/Early_integration/Files/whole_seq_preprocessed_NPI.pkl')\n",
    "tokenVocab, _ = input_vocab(inputs = whole_seq.inputs_normal_range_preprocessed_100_therap_removed, symbol=global_params['age_symbol'])\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], mon = global_params['age_month'], symbol=global_params['age_symbol'])\n",
    "modalitiesVocab, _ = mod_vocab(whole_seq.modalities_100_therap_removed, symbol=global_params['age_symbol'])\n",
    "delayVocab, _ = delay_vocab(max_delay=global_params['max_delay'], mon = global_params['delay_month'], symbol=global_params['age_symbol'])\n",
    "NPIVocab = {'PAD':0, 'UNK':1, 1.0:2, 2.0:3, 3.0:4, 4.0:5, 5.0:6, 6.0:7}\n",
    "\n",
    "del whole_seq\n",
    "\n",
    "# Binary classification \n",
    "labelVocab = {0:0, 1:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ed32d-08af-404b-8c4b-7735a076dbfa",
   "metadata": {},
   "source": [
    "4. Prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0305355d-39a6-461c-bc16-a34e41b1e04a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b1/jf_78yv56k71f696t4mbm2jw0000gn/T/ipykernel_39909/2547664180.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hf' is not defined"
     ]
    }
   ],
   "source": [
    "test_idx = hf._load_pkl(file_config['test_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b5e008-351f-4d1d-8644-bd2afc5dde2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data['Num_dossier'].isin([i for i in data['Num_dossier'] if i not in test_idx.values])]\n",
    "test = data.loc[data['Num_dossier'].isin(test_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2944d57-9d7a-43dd-94ab-463a5c87d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['patid'] = range(len(train))\n",
    "test['patid'] = range(len(test))\n",
    "\n",
    "train.index =  range(len(train))\n",
    "test.index =  range(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc00590-e26b-4490-9791-d5b12c425181",
   "metadata": {},
   "source": [
    "3. Config and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a45ebf2f-3251-435a-94ef-511de41b830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, model):\n",
    "    # load pretrained model and update weights\n",
    "    pretrained_dict = torch.load(path)\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    \n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    \n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb8b4a3-52ff-4dc8-86c9-5fdc3f5dc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Config for MLM with sweep (wandb)\n",
    "\n",
    "config = {'method' : 'bayes', \n",
    "                'metric' : {'name' : 'valid_f1', 'goal': 'maximize'},\n",
    "                'parameters' : {'hidden_size': {'value': 432},       # word embedding and seg embedding hidden size\n",
    "                'intermediate_size': {'value': 560},                # the size of the \"intermediate\" layer in the transformer encoder\n",
    "                'hidden_dropout_prob': {'values': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},                    # dropout rate\n",
    "                'num_hidden_layers': {'distribution': 'int_uniform', 'min':1, 'max':12},                   # number of multi-head attention layers required\n",
    "                'num_attention_heads': {'values': [1, 3, 6, 9, 12]},                  # number of attention heads\n",
    "                'attention_probs_dropout_prob': {'values': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
    "                'hidden_act': {'value' :'gelu'},                                                 # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "                'vocab_size': {'value': len(tokenVocab)},                                                  # number of disease + symbols for word embedding\n",
    "                'seg_vocab_size': {'value':2},                                                             # number of vocab for seg embedding\n",
    "                'modalities_vocab_size': {'value':len(modalitiesVocab)}, \n",
    "                'age_vocab_size': {'value':len(ageVocab)},                                                 # number of vocab for age embedding\n",
    "                'delay_vocab_size': {'value':len(delayVocab)},\n",
    "                'NPI_vocab_size' : {'value': len(NPIVocab)},\n",
    "                'epochs': {'value': 100},\n",
    "                'max_position_embeddings': {'value': train_params['max_len_seq']},                          # maximum number of tokens\n",
    "                'initializer_range': {'value' : 0.02},                                                     # parameter weight initializer range\n",
    "                'lr' : {'values': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3]},                      # a flat distribution between 0 and 0.1\n",
    "                'warmup_proportion': {'value': 0.1}, \n",
    "                'weight_decay' : {'values': [0, 0.0001, 0.0005, 0.001, 0.005, 0.01,]}, \n",
    "                'class_weights': {'value': 1},\n",
    "                'batch_size': {'values' : [16, 32, 64]},   # integers between 8 and 32 # with evenly-distributed logarithms\n",
    "                'gradient_accumulation_steps': {'distribution': 'int_uniform', 'min':1, 'max':10},\n",
    "                'chunk_size_feed_forward' : {'value':0},\n",
    "                'max_position_embeddings': {'value' : train_params['max_len_seq']},                          # maximum number of tokens\n",
    "                'output_attentions' : {'value':True},\n",
    "                'is_decoder' : {'value':False},\n",
    "                'add_cross_attention':{'value': False},\n",
    "                'vocab_size': {'value':len(tokenVocab)},                                                  # number of disease + symbols for word embedding\n",
    "                'seg_vocab_size':{'value':2},                                                             # number of vocab for seg embedding\n",
    "                'modalities_vocab_size' :{'value':len(modalitiesVocab)}, \n",
    "                'age_vocab_size': {'value': len(ageVocab)},                                                 # number of vocab for age embedding\n",
    "                'delays_vocab_size': {'value': len(delayVocab)},\n",
    "                'layer_norm_eps' : {'value':  1e-5}},     \n",
    "                'early_terminate': {'type': 'hyperband', 's': 2, 'eta': 3, 'max_iter': 27},\n",
    "          \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae6c72-8d3a-44c5-a38b-c2b7702980c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embeddings'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "            \n",
    "        )\n",
    "        self.delays_vocab_size = config.get('delays_vocab_size')\n",
    "        self.modalities_vocab_size = config.get('modalities_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.NPI_vocab_size = config.get('NPI_vocab_size')\n",
    "        self.output_attentions = config.get('output_attentions')\n",
    "        self.chunk_size_feed_forward = config.get('chunk_size_feed_forward')\n",
    "        self.is_decoder = config.get('is_decoder')\n",
    "        self.layer_norm_eps = config.get('layer_norm_eps')\n",
    "        self.add_cross_attention = config.get('add_cross_attention')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d5da258-6a63-4818-a027-bc746f5e80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(config):\n",
    "    \n",
    "    # del model\n",
    "    \n",
    "    class_weights = torch.FloatTensor([1,config.class_weights]).cuda()\n",
    "    conf = BertConfig(config)\n",
    "    model = BertForClassification(conf, num_labels=len(labelVocab.keys()), feature_dict=feature_dict, class_weights = class_weights)\n",
    "    model = load_model(pretrain_model_path, model)   \n",
    "    model = model.to(global_params['device'])\n",
    "    optim = optimiser.adam(params=list(model.named_parameters()), config=config)\n",
    " \n",
    "    return model, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdacdaa-e7dd-4ca5-bf82-c08b160bd764",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sweep_id = wandb.sweep(config, project='Binary_clf_npi_3y_run2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef59cb-b33b-4867-9da4-f4285ed91dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model \n",
    "1. Utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb79caa0-2866-4e22-841f-7d4b4d0b7928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer(classes=[0, 1])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer(classes=[0, 1])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer(classes=[0, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=list(labelVocab.values()))\n",
    "mlb.fit([[each] for each in list(labelVocab.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e053993-b36a-4fec-a4a4-bc305c4f6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scores \n",
    "\n",
    "import sklearn\n",
    "def precision(logits, label):\n",
    "\n",
    "    label, logits = label.cpu(), logits.detach().cpu()\n",
    "    label=np.argmax(label, axis=1)\n",
    "    logits=np.argmax(logits, axis=1)\n",
    "    f1 =  sklearn.metrics.f1_score(label.numpy(), logits.numpy(), average=\"macro\")\n",
    "    \n",
    "    return f1, logits, label\n",
    "\n",
    "def precision_valid(logits, label):\n",
    "    label=np.argmax(label, axis=1)\n",
    "    logits=np.argmax(logits, axis=1)   \n",
    "    f1 =  sklearn.metrics.f1_score(label.numpy(), logits.numpy(), average=\"macro\")\n",
    "    roc = sklearn.metrics.roc_auc_score(label.numpy(),logits.numpy(), average='macro')\n",
    "    \n",
    "    \n",
    "    return f1, roc, logits, label\n",
    "\n",
    "\n",
    "\n",
    "def precision_test(output, label):\n",
    "    label=np.argmax(label, axis=1)#.flatten().numpy()\n",
    "    output=np.argmax(output, axis=1)#.flatten().numpy()\n",
    "    roc = sklearn.metrics.roc_auc_score(label ,output, average='macro')\n",
    "    f1 =  sklearn.metrics.f1_score(label, output, average=\"macro\")\n",
    "    recall = sklearn.metrics.recall_score(label, output, average=\"macro\")\n",
    "    precision = sklearn.metrics.precision_score(label, output, average=\"macro\")\n",
    " \n",
    "    return f1, roc, recall, precision, output, label\n",
    "\n",
    "\n",
    "def test_scores(model, data): \n",
    "     \n",
    "    y = []\n",
    "    y_label = []\n",
    "    total_f1, total_roc, total_precision, total_recall = [], [], [], []\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for step, batch in enumerate(data):\n",
    "\n",
    "        age_ids, input_ids, mod_ids, del_ids, NPI_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
    "       \n",
    "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        mod_ids = mod_ids.to(global_params['device'])\n",
    "        del_ids = del_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "        NPI_ids = NPI_ids.to(global_params['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids, NPI_ids, attention_mask=attMask, labels=targets, output_attentions=True)\n",
    "        \n",
    "\n",
    "        logits = outputs.logits.cpu()\n",
    "        targets = targets.cpu()\n",
    "\n",
    "        y_label.append(targets)\n",
    "        y.append(logits)\n",
    "        \n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "\n",
    "     # Compute ROC curve and ROC area for each class\n",
    "    f1, roc, recall, precision, output, label = precision_test(y, y_label)\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    label = np.argmax(y_label, axis=1)\n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(y)\n",
    "\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(label, output[:,1])\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "    return f1, recall, precision, fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "429e6394-9904-4c6e-b9d9-ec2c755c823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    \n",
    "   \n",
    "def training_per_epoch(e, loader, validloader, model , optim, config):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Reset the loss at each epoch\n",
    "    temp_loss, temp_f1 = [], []\n",
    "    train_f1, train_loss = [], []\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    train_targets, train_masks = [], []\n",
    "    \n",
    "    ## Count the number of batches\n",
    "    cnt = 0\n",
    "    count = 0\n",
    "    # Training\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    for step, batch in enumerate(loader):\n",
    "        \n",
    "        cnt +=1\n",
    "        age_ids, input_ids, mod_ids, del_ids, NPI_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
    " \n",
    "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "    \n",
    "        ## Load batch to gpu \n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        mod_ids = mod_ids.to(global_params['device'])\n",
    "        del_ids = del_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        NPI_ids = NPI_ids.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "        \n",
    "        \n",
    "        ## Compute output (loss, logits and attentions scores) \n",
    "        output = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids, NPI_ids, attention_mask=attMask, labels=targets, output_attentions = True)\n",
    "      \n",
    "        loss = output.loss\n",
    "        logits  = output.logits\n",
    "        attentions = output.attentions\n",
    "        \n",
    "        if config.gradient_accumulation_steps >1:\n",
    "            loss = loss/config.gradient_accumulation_steps\n",
    "        \n",
    "\n",
    "        temp_loss.append(loss.item())\n",
    "        train_loss.append(loss.item())\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        f1, a, b = precision(logits, targets)\n",
    "       \n",
    "        temp_f1.append(f1)\n",
    "   \n",
    "\n",
    "        \n",
    "        if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "        train_f1.append(f1)\n",
    "        count+=1\n",
    "        \n",
    "        train_targets.append(targets)\n",
    "        train_masks.append(attMask)\n",
    "        logits = logits.cpu()\n",
    "        targets = targets.cpu()\n",
    "        loss = loss.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    train_hidden_states = output.hidden_states[1:]\n",
    "\n",
    "        \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - start)\n",
    "                   \n",
    "    print(\"\")\n",
    "    print(\"Average training loss: {0:.2f}\".format(np.mean(train_loss)))\n",
    "    print(\"Average training score: {0:.2f}\".format(np.mean(train_f1)))\n",
    "    print(\"Training epoch took: {:}\".format(training_time))\n",
    "    \n",
    "          \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    valid_f1, valid_roc, valid_loss, valid_time, valid_hidden_states, valid_targets, valid_masks = evaluate(validloader, model)\n",
    "    \n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append({'epoch': e+1, \n",
    "                               'Training Loss': np.mean(train_loss) ,\n",
    "                               'Training Time' : training_time,\n",
    "                               'Average Train f1 score' : np.mean(train_f1),\n",
    "                               'Validation Loss': np.mean(valid_loss), \n",
    "                               'Validating Time' : valid_time, \n",
    "                               'Average Valid f1 score' : np.mean(valid_f1),\n",
    "                               'Average Valid ROC' : np.mean(valid_roc)\n",
    "                                })  \n",
    "        \n",
    "    return valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats, train_hidden_states, valid_hidden_states, train_targets, valid_targets, train_masks, valid_masks\n",
    "    \n",
    "\n",
    "def evaluate(loader, model):\n",
    "                               \n",
    "    start = time.time()\n",
    "                               \n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    val_loss, total_f1, total_roc = [], [], []\n",
    "    val_loss_tot, tot_f1, tot_roc = [], [], []\n",
    "    targets_list, masks = [], []\n",
    "    \n",
    "    for step, batch in enumerate(loader):\n",
    "        \n",
    "        age_ids, input_ids, mod_ids, del_ids, NPI_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
    " \n",
    "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "    \n",
    "        ## Load batch to gpu \n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        mod_ids = mod_ids.to(global_params['device'])\n",
    "        del_ids = del_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        NPI_ids = NPI_ids.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "        \n",
    "      \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids, NPI_ids, attention_mask=attMask, labels=targets, output_attentions=True)\n",
    "        \n",
    "        val_loss.append(outputs.loss.item())\n",
    "        \n",
    "        logits = outputs.logits.cpu()\n",
    "        targets = targets.cpu()\n",
    "        \n",
    "        y_label.append(targets)\n",
    "        y.append(logits)\n",
    "        \n",
    "        masks.append(attMask)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    hidden_states = outputs.hidden_states[1:]\n",
    "    targets_list = y_label\n",
    "    \n",
    "    \n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0) \n",
    "    \n",
    "    tot_f1, tot_roc, output, label = precision_valid(y, y_label)\n",
    "   \n",
    "    # Measure how long this epoch took.\n",
    "    validation_time = format_time(time.time() - start)\n",
    "    \n",
    "    return tot_f1, tot_roc, val_loss, validation_time, hidden_states, targets_list, masks\n",
    "\n",
    "def training(config=None):\n",
    "    \n",
    "    with wandb.init(config=config) as run:\n",
    "        \n",
    "        config = wandb.config\n",
    "        \n",
    "        train_hidden_states_per_epoch, train_targets_per_epoch, train_mask_per_epoch =  [] , [], []\n",
    "        valid_hidden_states_per_epoch, valid_targets_per_epoch, valid_mask_per_epoch = [], [], []  \n",
    "        train_results, valid_results, valid_results_tot, train_loss, valid_loss, valid_results_roc, training_stats_list  = [], [], [], [], [], [], []\n",
    "        train_f1_list, train_loss_list = [], []\n",
    "        valid_f1_list, valid_f1_list_tot, valid_loss_list, valid_roc_list = [], [], [], []\n",
    "        best_pre = 0.0\n",
    "        \n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(train.drop(['label'], axis=1), train['label'], test_size=0.1, random_state=42, stratify=train['label'])\n",
    "        \n",
    "        train_df = pd.concat([X_train, y_train], axis=1)\n",
    "        cv_df = pd.concat([X_valid, y_valid], axis=1)\n",
    "      \n",
    "            \n",
    "        train_df.index = range(train_df.shape[0])\n",
    "        train_df.patid = range(train_df.shape[0])\n",
    "        X_tr = train_df['inputs_normal_range_preprocessed_100_therap_removed']\n",
    "        y_tr = train_df['label']\n",
    "\n",
    "        cv_df.index = range(cv_df.shape[0])\n",
    "        cv_df.patid = range(cv_df.shape[0])\n",
    "\n",
    "        train_loader = load_data(train_df, config, X_tr=X_tr, y_tr=y_tr)\n",
    "        valid_loader = load_data(cv_df, config, sampling=False)\n",
    "\n",
    "        model, optim = define_model(config)\n",
    "\n",
    "        for e in range(config.epochs):   \n",
    "\n",
    "            valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats, train_hidden_states, valid_hidden_states, train_targets, valid_targets, train_masks, valid_masks =  training_per_epoch(e, train_loader, valid_loader, model, optim, config)       \n",
    "\n",
    "            mean_f1 = np.mean(valid_f1)\n",
    "\n",
    "            if mean_f1 > best_pre:\n",
    "                print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "                model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "                output_model_file = os.path.join(global_params['output_dir'],global_params['best_name'])\n",
    "                create_folder(global_params['output_dir'])\n",
    "\n",
    "                torch.save(model_to_save.state_dict(), output_model_file)\n",
    "                best_pre = mean_f1\n",
    "\n",
    "            wandb.log({'f1' : np.mean(train_f1), 'loss': np.mean(train_loss), 'valid_f1': valid_f1, 'valid_roc':valid_roc,\n",
    "                      'valid_loss':np.mean(valid_loss), 'best_f1':best_pre})\n",
    "        \n",
    "        test.index = range(test.shape[0])\n",
    "        test.patid = range(test.shape[0])\n",
    "        test_loader = load_data(test, config, sampling=False)\n",
    "        test_f1, test_recall, test_precision, fpr, tpr, test_roc  = test_scores(model, test_loader)\n",
    "    #    test_f1, test_roc, test_loss, test_time, test_hidden_states, test_targets, test_masks = evaluate(test_loader, model)\n",
    "        wandb.log({'test_f1':test_f1, 'test_roc': test_roc, 'test_recall': test_recall, 'test_precision':test_precision})\n",
    "        \n",
    "        art = wandb.Artifact(f'clf_npi_3y_{wandb.run.id}', type='model')\n",
    "        art.add_file(output_model_file)\n",
    "        run.log_artifact(art)\n",
    "        \n",
    "        if test_f1 >= 0.65:\n",
    "            wandb.alert(\n",
    "            title=\"Higher f1\", \n",
    "            text=f\"3years: You reach your higher f1: {test_f1}\",\n",
    "            )\n",
    "            torch.save(model_to_save.state_dict(), 'BEHRT/Early_integration/Tasks/Output/clf_npi/Above_baselines_3y')\n",
    "  \n",
    "        wandb.finish()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212d9b7-5925-47d7-8a0b-48c9a6cb40ef",
   "metadata": {},
   "source": [
    "2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b06887ce-2df1-4e89-880b-8e69fbfd4b46",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating Inputs for fold 0\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| Cnt: 1\t| Loss: 0.5719892978668213\t| f1 score: 0.5465587044534412\n",
      "\n",
      "Average training loss: 0.31\n",
      "Average training score: 0.34\n",
      "Training epoch took: 0:00:09\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 1.44\n",
      "Validation took: 0:00:03\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.09651307596513076\n",
      "\n",
      "epoch: 1\t| Cnt: 1\t| Loss: 0.2754223048686981\t| f1 score: 0.3333333333333333\n",
      "\n",
      "Average training loss: 0.27\n",
      "Average training score: 0.33\n",
      "Training epoch took: 0:00:09\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 1.40\n",
      "Validation took: 0:00:03\n",
      "\n",
      "valid score: 0.09651307596513076\n",
      "\n",
      "epoch: 2\t| Cnt: 1\t| Loss: 0.2739230990409851\t| f1 score: 0.3333333333333333\n",
      "\n",
      "Average training loss: 0.27\n",
      "Average training score: 0.33\n",
      "Training epoch took: 0:00:10\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 1.40\n",
      "Validation took: 0:00:03\n",
      "\n",
      "valid score: 0.09651307596513076\n",
      "\n",
      "epoch: 3\t| Cnt: 1\t| Loss: 0.2679360508918762\t| f1 score: 0.3333333333333333\n",
      "\n",
      "Average training loss: 0.27\n",
      "Average training score: 0.35\n",
      "Training epoch took: 0:00:10\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 1.46\n",
      "Validation took: 0:00:03\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.12965722232410293\n",
      "\n",
      "epoch: 4\t| Cnt: 1\t| Loss: 0.2555195689201355\t| f1 score: 0.3333333333333333\n",
      "\n",
      "Average training loss: 0.26\n",
      "Average training score: 0.38\n",
      "Training epoch took: 0:00:10\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 1.29\n",
      "Validation took: 0:00:03\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.13311128077877457\n",
      "\n",
      "epoch: 5\t| Cnt: 1\t| Loss: 0.22386664152145386\t| f1 score: 0.3992490613266583\n",
      "\n",
      "Average training loss: 0.25\n",
      "Average training score: 0.38\n",
      "Training epoch took: 0:00:10\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 1.29\n",
      "Validation took: 0:00:03\n",
      "\n",
      "valid score: 0.09651307596513076\n",
      "\n",
      "epoch: 6\t| Cnt: 1\t| Loss: 0.24547246098518372\t| f1 score: 0.3333333333333333\n",
      "\n",
      "Average training loss: 0.25\n",
      "Average training score: 0.35\n",
      "Training epoch took: 0:00:10\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 1.30\n",
      "Validation took: 0:00:03\n",
      "\n",
      "valid score: 0.12595041764831869\n",
      "\n",
      "epoch: 7\t| Cnt: 1\t| Loss: 0.23783273994922638\t| f1 score: 0.3992490613266583\n",
      "\n",
      "Average training loss: 0.23\n",
      "Average training score: 0.42\n",
      "Training epoch took: 0:00:10\n",
      "\n",
      "Running Validation...\n",
      "Validation Loss: 1.23\n",
      "Validation took: 0:00:03\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "valid score: 0.23878030045398657\n",
      "\n",
      "epoch: 8\t| Cnt: 1\t| Loss: 0.21625609695911407\t| f1 score: 0.6101882613510521\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 31.75 GiB total capacity; 29.86 GiB already allocated; 83.69 MiB free; 30.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m model, optim \u001b[38;5;241m=\u001b[39m define_model(class_weights)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m70\u001b[39m):   \n\u001b[0;32m---> 68\u001b[0m     valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats, train_hidden_states, valid_hidden_states, train_targets, valid_targets, train_masks, valid_masks \u001b[38;5;241m=\u001b[39m  \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m)\u001b[49m       \n\u001b[1;32m     71\u001b[0m     train_hidden_states_per_epoch\u001b[38;5;241m.\u001b[39mappend(train_hidden_states)\n\u001b[1;32m     72\u001b[0m     valid_hidden_states_per_epoch\u001b[38;5;241m.\u001b[39mappend(valid_hidden_states)\n",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(e, train_dataloader, valid_dataloader)\u001b[0m\n\u001b[1;32m     54\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(global_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m## Compute output (loss, logits and attentions scores) \u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdel_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposi_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNPI_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattMask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m loss \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     61\u001b[0m logits  \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/Workdir/Secondment_1/Secondment 1/models/BEHRT_Models_v2/BertForClassification.py:194\u001b[0m, in \u001b[0;36mBertForClassification.forward\u001b[0;34m(self, input_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids, NPI_ids, attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, modalities_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, age_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delays_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, seg_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, posi_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  NPI_ids \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_attentions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, output_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor], SequenceClassifierOutput]:\n\u001b[1;32m    192\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 194\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelays_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposi_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mNPI_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    197\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/work/Workdir/Secondment_1/Secondment 1/models/BEHRT_Models_v2/BertForClassification.py:153\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids, NPI_ids, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    150\u001b[0m  extended_attention_mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m extended_attention_mask) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10000.0\u001b[39m\n\u001b[1;32m    152\u001b[0m  embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids, modalities_ids, age_ids, delays_ids, seg_ids, posi_ids, NPI_ids)\n\u001b[0;32m--> 153\u001b[0m  encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# sequence_output = encoded_layers[-1]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m  sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:609\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    600\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    601\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    602\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    424\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 425\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    435\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:357\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    353\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 31.75 GiB total capacity; 29.86 GiB already allocated; 83.69 MiB free; 30.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "\n",
    "   ## Run hyperparameters tuning 5times for the training\n",
    "    start = time.time()\n",
    "    \n",
    "    wandb.agent(sweep_id, training, count=50)\n",
    "    \n",
    "    print()\n",
    "    print('Elapsed time for sweep hyperparameters tuning = {}\"'.format(time.time() - start))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
