{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78498f0b-e7b4-4fbe-9e40-827fdf2025eb",
      "metadata": {
        "id": "78498f0b-e7b4-4fbe-9e40-827fdf2025eb"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a24a8dd-3d4b-47fd-b884-6924e46f061a",
      "metadata": {
        "id": "9a24a8dd-3d4b-47fd-b884-6924e46f061a",
        "outputId": "24433d98-ab6b-48dc-e720-f9a3790b6542"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-06 14:47:06.774350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('BEHRT/Early_integration/')\n",
        "sys.path.append('BEHRT/')\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_pretrained_bert as Bert\n",
        "import sklearn\n",
        "\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray import tune\n",
        "\n",
        "from Utils import optimiser\n",
        "from Utils.common import create_folder\n",
        "import sklearn.metrics as skm\n",
        "import math\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from Utils.utils import *\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from Utils.dataLoader_utils import ImbSampler, OverSampler, StratifiedSampler\n",
        "from Utils.NextXVisit_v2 import NextVisit\n",
        "from Models.BertForClassification import BertForClassification\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "#### ## ROC\n",
        "import sklearn.metrics as metrics\n",
        "import seaborn as sns\n",
        "## Plot results\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "from Utils.add_endpoints import add_endp\n",
        "from Utils.handle_file import handle_file\n",
        "\n",
        "hf = handle_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd337188-4d02-4014-9ca2-7ac4c670566c",
      "metadata": {
        "id": "dd337188-4d02-4014-9ca2-7ac4c670566c"
      },
      "source": [
        "#### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89488d8a-aee0-4ef7-8876-b078312f00be",
      "metadata": {
        "id": "89488d8a-aee0-4ef7-8876-b078312f00be"
      },
      "outputs": [],
      "source": [
        "def get_train_test_valid_idx(dataset):\n",
        "    patient_idx = dataset.index\n",
        "\n",
        "    train_idx = hf._load_pkl(file_config['train_idx'])\n",
        "    train_idx = [idx for idx in train_idx if idx in patient_idx]\n",
        "\n",
        "    test_idx = hf._load_pkl(file_config['test_idx'])\n",
        "    test_idx = [idx for idx in test_idx if idx in patient_idx]\n",
        "\n",
        "    valid_idx = hf._load_pkl(file_config['valid_idx'])\n",
        "    valid_idx = [idx for idx in valid_idx if idx in patient_idx]\n",
        "\n",
        "    return train_idx, test_idx, valid_idx\n",
        "\n",
        "def split_data(dataset):\n",
        "    train_idx, test_idx, valid_idx = get_train_test_valid_idx(dataset)\n",
        "\n",
        "\n",
        "    train = dataset.loc[train_idx ,:]\n",
        "    valid = dataset.loc[valid_idx ,:]\n",
        "    test = dataset.loc[test_idx ,:]\n",
        "\n",
        "    train = train.rename_axis('patid')\n",
        "    valid = valid.rename_axis('patid')\n",
        "    test = test.rename_axis('patid')\n",
        "\n",
        "    train.reset_index(inplace=True)\n",
        "    valid.reset_index(inplace=True)\n",
        "    test.reset_index(inplace=True)\n",
        "\n",
        "    train['patid'] = train['patid'].replace(train.patid.values,range(len(train.patid.values)))\n",
        "    valid['patid'] = valid['patid'].replace(valid.patid.values,range(len(valid.patid.values)))\n",
        "    test['patid'] = test['patid'].replace(test.patid.values,range(len(test.patid.values)))\n",
        "\n",
        "    return train, test, valid\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e82e60-8092-4381-b351-af72bde3905b",
      "metadata": {
        "id": "c0e82e60-8092-4381-b351-af72bde3905b"
      },
      "source": [
        "#### Performing checks for the resources available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff028d4d-d7da-48d4-81f4-33f8e04ecb04",
      "metadata": {
        "id": "ff028d4d-d7da-48d4-81f4-33f8e04ecb04"
      },
      "outputs": [],
      "source": [
        "# Check if there is a gpu available\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"There are %d GPU(s) available. \" %torch.cuda.device_count())\n",
        "    print(\"We will use the GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
        "\n",
        "else:\n",
        "    print(\"No GPU available, using the CPU instead\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\"\"\" Empty the cache to enable the use of the gpu \"\"\"\n",
        "\n",
        "def empty_cuda():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a691f96-f00a-4748-9f42-2cb9d22a8033",
      "metadata": {
        "id": "9a691f96-f00a-4748-9f42-2cb9d22a8033"
      },
      "source": [
        "#### Run Binary Classification\n",
        "1. Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5adc5959-e763-4719-8d36-25c616420c25",
      "metadata": {
        "id": "5adc5959-e763-4719-8d36-25c616420c25"
      },
      "outputs": [],
      "source": [
        "## Embeddings used for the classification\n",
        "\n",
        "pretrain_model_path =  ''   # pretrained MLM path\n",
        "\n",
        "file_config = { 'data':'',\n",
        "                'labels' : '',\n",
        "                'train_idx' : '',\n",
        "                'valid_idx' : '',\n",
        "                'test_idx' : '',\n",
        "                }\n",
        "\n",
        "optim_config = {\n",
        "    'lr': 5e-5,\n",
        "    'warmup_proportion': 0.1,\n",
        "    'weight_decay': 0.01\n",
        "}\n",
        "\n",
        "global_params = {\n",
        "    'batch_size': 32,\n",
        "    'gradient_accumulation_steps': 4,\n",
        "    'device': device ,\n",
        "    'output_dir': 'BEHRT/Early_integration/Tasks/Output', # output folder\n",
        "    'best_name': 'CLF_model',  # output model name\n",
        "    'max_len_seq': 512, #100,\n",
        "    'max_age': 110,\n",
        "    'max_delay': 30, ## = 30years\n",
        "    'age_month': 12,\n",
        "    'delay_month': 0.25,\n",
        "    'age_year': False,\n",
        "    'age_symbol': None,\n",
        "    'min_visit': 2,\n",
        "}\n",
        "\n",
        "feature_dict = {\n",
        "            'word':True,\n",
        "            'seg':True,\n",
        "            'age':True,\n",
        "            'modalities': True,\n",
        "            'delays': True,\n",
        "            'position': True\n",
        "                }\n",
        "\n",
        "class BertConfig(Bert.modeling.BertConfig):\n",
        "    def __init__(self, config):\n",
        "        super(BertConfig, self).__init__(\n",
        "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
        "            hidden_size=config['hidden_size'],\n",
        "            num_hidden_layers=config.get('num_hidden_layers'),\n",
        "            num_attention_heads=config.get('num_attention_heads'),\n",
        "            intermediate_size=config.get('intermediate_size'),\n",
        "            hidden_act=config.get('hidden_act'),\n",
        "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
        "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
        "            max_position_embeddings = config.get('max_position_embedding'),\n",
        "            initializer_range=config.get('initializer_range'),\n",
        "        )\n",
        "        self.delays_vocab_size = config.get('delays_vocab_size')\n",
        "        self.modalities_vocab_size = config.get('modalities_vocab_size')\n",
        "        self.age_vocab_size = config.get('age_vocab_size')\n",
        "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
        "        self.output_attentions = config.get('output_attentions')\n",
        "        self.chunk_size_feed_forward = config.get('chunk_size_feed_forward')\n",
        "        self.is_decoder = config.get('is_decoder')\n",
        "        self.layer_norm_eps = config.get('layer_norm_eps')\n",
        "        self.add_cross_attention = config.get('add_cross_attention')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "294488fe-1f32-4538-9bfc-759d10af5a9a",
      "metadata": {
        "id": "294488fe-1f32-4538-9bfc-759d10af5a9a"
      },
      "source": [
        "2. Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4155f7bd-c876-45c7-a8ec-037820362032",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "4155f7bd-c876-45c7-a8ec-037820362032",
        "outputId": "20373191-c447-4ece-d8bb-f81e7768bc92"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/Users/maguette/opt/anaconda3/lib/python3.7/site-packages/pandas/_libs/internals.cpython-37m-darwin.so'>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/b1/jf_78yv56k71f696t4mbm2jw0000gn/T/ipykernel_4976/537303923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Import train data \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\"\"\"Import labels \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/Cluster/BEHRT/Early_integration/Utils/handle_file.py\u001b[0m in \u001b[0;36m_load_pkl\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from '/Users/maguette/opt/anaconda3/lib/python3.7/site-packages/pandas/_libs/internals.cpython-37m-darwin.so'>"
          ]
        }
      ],
      "source": [
        "\"\"\"Import train data \"\"\"\n",
        "data =  hf._load_pkl(file_config['data'])\n",
        "\n",
        "\n",
        "\"\"\"Import labels \"\"\"\n",
        "labels = hf._load_csv(file_config['labels'])\n",
        "labels.rename(columns={'status_rfs_surg_5y': 'label'}, inplace=True)\n",
        "\n",
        "\"\"\"Merge label and data \"\"\"\n",
        "data = pd.merge(data, labels, on=['Num_dossier'])\n",
        "data.set_index('Num_dossier', inplace=True)\n",
        "\n",
        "# Display 3 first rows\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78566f80-bdd7-4676-8526-ea41e4f81076",
      "metadata": {
        "id": "78566f80-bdd7-4676-8526-ea41e4f81076"
      },
      "outputs": [],
      "source": [
        "# remove patients with visits less than min visit\n",
        "previous_shape = data.shape[0]\n",
        "\n",
        "data['length'] = data['inputs_quantiles_preprocessed_100_therap_removed_tolist'].apply(lambda x: len([i for i in range(len(x)) if x[i] == 'SEP']))\n",
        "data = data[data['length'] >= global_params['min_visit']]\n",
        "#data = data.reset_index(drop=True)\n",
        "\n",
        "print(\"We lost {} patient\".format(previous_shape - data.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ea25fbf-a06e-48be-91fd-95154426e1f0",
      "metadata": {
        "id": "8ea25fbf-a06e-48be-91fd-95154426e1f0"
      },
      "outputs": [],
      "source": [
        "whole_seq = hf._load_pkl('') #data with the entire history\n",
        "\n",
        "tokenVocab, _ = input_vocab(inputs = data.inputs, symbol=global_params['age_symbol'])\n",
        "ageVocab, _ = age_vocab(max_age=global_params['max_age'], mon = global_params['age_month'], symbol=global_params['age_symbol'])\n",
        "modalitiesVocab, _ = mod_vocab(data.modalities_100_therap_removed, symbol=global_params['age_symbol'])\n",
        "delayVocab, _ = delay_vocab(max_delay=global_params['max_delay'], mon = global_params['delay_month'], symbol=global_params['age_symbol'])\n",
        "\n",
        "# Binary classification\n",
        "labelVocab = {0:0, 1:1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8555749-2489-4391-8d79-e49d95cead84",
      "metadata": {
        "id": "a8555749-2489-4391-8d79-e49d95cead84"
      },
      "outputs": [],
      "source": [
        "model_config = {\n",
        "    'vocab_size': len(tokenVocab), # number of disease + symbols for word embedding\n",
        "    'hidden_size': 288, # word embedding and seg embedding hidden size\n",
        "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
        "    'modalities_vocab_size': len(modalitiesVocab),\n",
        "    'age_vocab_size': len(ageVocab), # number of vocab for age embedding\n",
        "    'delays_vocab_size': len(delayVocab),\n",
        "    'max_position_embedding':global_params['max_len_seq'],  # maximum number of tokens\n",
        "    'hidden_dropout_prob': 0.3, # dropout rate\n",
        "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
        "    'num_attention_heads': 12, # number of attention heads\n",
        "    'attention_probs_dropout_prob': 0.2, # multi-head attention dropout rate\n",
        "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
        "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
        "    'initializer_range': 0.02, # parameter weight initializer range\n",
        "    'chunk_size_feed_forward' : 0,\n",
        "    'use_return_dict': True,\n",
        "    'output_attentions': True,\n",
        "    'output_hidden_states':True,\n",
        "    'is_decoder': False,\n",
        "    'layer_norm_eps' : 1e-12,  #1e-5\n",
        "    'add_cross_attention' : False\n",
        "}\n",
        "\n",
        "feature_dict = {\n",
        "    'word':True,\n",
        "    'seg':True,\n",
        "    'age':True,\n",
        "    'modalities': True,\n",
        "    'delays': True,\n",
        "    'position': True\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4740134a-9c2e-46b3-90f8-5ac1679fe422",
      "metadata": {
        "id": "4740134a-9c2e-46b3-90f8-5ac1679fe422"
      },
      "source": [
        "3. Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b491ef3-6c1c-4e33-861e-316113f5db51",
      "metadata": {
        "id": "5b491ef3-6c1c-4e33-861e-316113f5db51"
      },
      "outputs": [],
      "source": [
        "train, test, valid = split_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e9ce80-339f-429e-ac8d-78ceb6e3112e",
      "metadata": {
        "id": "86e9ce80-339f-429e-ac8d-78ceb6e3112e"
      },
      "outputs": [],
      "source": [
        "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda:0' else {'num_workers': 5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f20a3c-dd46-448b-ad4b-560d8c5fc5b2",
      "metadata": {
        "id": "32f20a3c-dd46-448b-ad4b-560d8c5fc5b2"
      },
      "outputs": [],
      "source": [
        "X_train = train['inputs_curve_intersections_preprocessed_100_therap_removed_tolist']\n",
        "y_train = train['label']\n",
        "\n",
        "Dset = FinetuneDataset(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=train, max_len=global_params['max_len_seq'],  code='inputs_curve_intersections_preprocessed_100_therap_removed_tolist', delay ='delays_100_therap_removed_into_chunks_tolist'\n",
        "                              , age = \"age_100_therap_removed_into_chunks_tolist\", mod='modalities_100_therap_removed_into_chunks_tolist' )\n",
        "hp_generator = {'batch_size': global_params['batch_size'], 'balanced': 'balanced', 'shuffle':True}\n",
        "trainload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  sampler = StratifiedSampler(X_train, y_train, batch_size=global_params['batch_size']) , **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d60f4a-2d04-446e-bb91-70d9cb0cec11",
      "metadata": {
        "id": "50d60f4a-2d04-446e-bb91-70d9cb0cec11"
      },
      "outputs": [],
      "source": [
        "\n",
        "Dset = FinetuneDataset(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=valid, max_len=global_params['max_len_seq'],  code='inputs_curve_intersections_preprocessed_100_therap_removed_tolist', delay ='delays_100_therap_removed_into_chunks_tolist'\n",
        "                              , age = \"age_100_therap_removed_into_chunks_tolist\", mod='modalities_100_therap_removed_into_chunks_tolist' )\n",
        "validload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  shuffle = True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bb5045c-9b2c-4d6f-9378-267b39351135",
      "metadata": {
        "id": "5bb5045c-9b2c-4d6f-9378-267b39351135"
      },
      "outputs": [],
      "source": [
        "Dset = FinetuneDataset(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=test, max_len=global_params['max_len_seq'], code='inputs_curve_intersections_preprocessed_100_therap_removed_tolist', delay ='delays_100_therap_removed_into_chunks_tolist'\n",
        "                              , age = \"age_100_therap_removed_into_chunks_tolist\", mod='modalities_100_therap_removed_into_chunks_tolist' )\n",
        "testload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  shuffle = False, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd1ed32d-08af-404b-8c4b-7735a076dbfa",
      "metadata": {
        "id": "dd1ed32d-08af-404b-8c4b-7735a076dbfa"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "433d467b-5f86-4d26-b739-0ff3799ac042",
      "metadata": {
        "id": "433d467b-5f86-4d26-b739-0ff3799ac042"
      },
      "source": [
        "1. Model settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d54f911d-c46d-48db-829a-a06113bc316f",
      "metadata": {
        "tags": [],
        "id": "d54f911d-c46d-48db-829a-a06113bc316f"
      },
      "outputs": [],
      "source": [
        "def load_model(path, model):\n",
        "    # load pretrained model and update weights\n",
        "    pretrained_dict = torch.load(path)\n",
        "    model_dict = model.state_dict()\n",
        "\n",
        "    # 1. filter out unnecessary keys\n",
        "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "\n",
        "    # 2. overwrite entries in the existing state dict\n",
        "    model_dict.update(pretrained_dict)\n",
        "\n",
        "    # 3. load the new state dict\n",
        "    model.load_state_dict(model_dict)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25c5654-01b7-478a-bce7-77e80da53b0f",
      "metadata": {
        "id": "e25c5654-01b7-478a-bce7-77e80da53b0f"
      },
      "outputs": [],
      "source": [
        "def define_model(model_config):\n",
        "    # del model\n",
        "\n",
        "    class_weights = torch.tensor(config['class_weights'])\n",
        "    conf = BertConfig(model_config)\n",
        "    model = BertForClassification(conf, num_labels=len(labelVocab.keys()), feature_dict=feature_dict, class_weights = class_weights)\n",
        "    model = load_model(pretrain_model_path, model)\n",
        "    model = model.to(global_params['device'])\n",
        "    optim = optimiser.adam(params=list(model.named_parameters()), config=model_config)\n",
        "\n",
        "    return model, optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ac5f34-2937-4ea6-81e0-afdf1aeedd2c",
      "metadata": {
        "id": "82ac5f34-2937-4ea6-81e0-afdf1aeedd2c"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer(classes=list(labelVocab.values()))\n",
        "mlb.fit([[each] for each in list(labelVocab.values())])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab9f06d-10e8-471d-b99e-2d6117ef8abf",
      "metadata": {
        "id": "3ab9f06d-10e8-471d-b99e-2d6117ef8abf"
      },
      "source": [
        "2. Model development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "429e6394-9904-4c6e-b9d9-ec2c755c823a",
      "metadata": {
        "id": "429e6394-9904-4c6e-b9d9-ec2c755c823a"
      },
      "outputs": [],
      "source": [
        "training_stats = []\n",
        "\n",
        "def training(e, train_dataloader, valid_dataloader):\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Reset the loss at each epoch\n",
        "    temp_loss, temp_f1 = [], []\n",
        "    train_f1, train_loss = [], []\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    cnt = 0\n",
        "    count = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        cnt +=1\n",
        "        age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
        "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
        "\n",
        "        ## Load batch to gpu\n",
        "        age_ids = age_ids.to(global_params['device'])\n",
        "        input_ids = input_ids.to(global_params['device'])\n",
        "        mod_ids = mod_ids.to(global_params['device'])\n",
        "        del_ids = del_ids.to(global_params['device'])\n",
        "        posi_ids = posi_ids.to(global_params['device'])\n",
        "        segment_ids = segment_ids.to(global_params['device'])\n",
        "        attMask = attMask.to(global_params['device'])\n",
        "        targets = targets.to(global_params['device'])\n",
        "\n",
        "\n",
        "        ## Compute output (loss, logits and attentions scores)\n",
        "        output = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets, output_attentions = True)\n",
        "\n",
        "        loss = output.loss\n",
        "        logits  = output.logits\n",
        "        attentions = output.attentions\n",
        "\n",
        "        if global_params['gradient_accumulation_steps'] >1:\n",
        "            loss = loss/global_params['gradient_accumulation_steps']\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        temp_loss.append(loss.item())\n",
        "        train_loss.append(loss.item())\n",
        "        nb_tr_examples += input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "        f1, a, b = scoring_for_train(logits, targets)\n",
        "\n",
        "        temp_f1.append(f1)\n",
        "\n",
        "        # Progress update every 50 batches\n",
        "        if step % 50 == 0:\n",
        "            print(\"epoch: {}\\t| Cnt: {}\\t| Loss: {}\\t| f1 score: {}\".format(e, cnt, np.mean(temp_loss), np.mean(temp_f1)))\n",
        "            temp_loss, temp_f1 = [], []\n",
        "\n",
        "\n",
        "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
        "\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "        train_f1.append(f1)\n",
        "        count+=1\n",
        "\n",
        "\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - start)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Average training loss: {0:.2f}\".format(np.mean(train_loss)))\n",
        "    print(\"Average training score: {0:.2f}\".format(np.mean(train_f1)))\n",
        "    print(\"Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    valid_f1, valid_roc, valid_loss, valid_time = evaluation(valid_dataloader)\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append({'epoch': e+1,\n",
        "                               'Training Loss': np.mean(train_loss) ,\n",
        "                               'Training Time' : training_time,\n",
        "                               'Average Train f1 score' : np.mean(train_f1),\n",
        "                               'Validation Loss': np.mean(valid_loss),\n",
        "                               'Validating Time' : valid_time,\n",
        "                               'Average Valid f1 score' : np.mean(valid_f1),\n",
        "                               'Average Valid ROC' : np.mean(valid_roc)\n",
        "                                })\n",
        "\n",
        "    return valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats\n",
        "\n",
        "\n",
        "def evaluation(data):\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    model.eval()\n",
        "    y = []\n",
        "    y_label = []\n",
        "    val_loss, total_f1, total_roc = [], [], []\n",
        "    val_loss_tot, tot_f1, tot_roc = [], [], []\n",
        "\n",
        "    for step, batch in enumerate(data):\n",
        "\n",
        "        age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
        "        targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
        "\n",
        "\n",
        "        age_ids = age_ids.to(global_params['device'])\n",
        "        input_ids = input_ids.to(global_params['device'])\n",
        "        mod_ids = mod_ids.to(global_params['device'])\n",
        "        del_ids = del_ids.to(global_params['device'])\n",
        "        posi_ids = posi_ids.to(global_params['device'])\n",
        "        segment_ids = segment_ids.to(global_params['device'])\n",
        "        attMask = attMask.to(global_params['device'])\n",
        "        targets = targets.to(global_params['device'])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets, output_attentions=True)\n",
        "\n",
        "        val_loss.append(outputs.loss.item())\n",
        "\n",
        "        logits = outputs.logits.cpu()\n",
        "        targets = targets.cpu()\n",
        "\n",
        "        y_label.append(targets)\n",
        "        y.append(logits)\n",
        "\n",
        "\n",
        "    y_label = torch.cat(y_label, dim=0)\n",
        "    y = torch.cat(y, dim=0)\n",
        "\n",
        "    tot_f1, tot_roc, output, label = precision_valid(y, y_label)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    validation_time = format_time(time.time() - start)\n",
        "\n",
        "    print(\"Validation Loss: {0:.2f}\".format(np.mean(val_loss)))\n",
        "    print(\"Validation took: {:}\".format(validation_time))\n",
        "    print()\n",
        "\n",
        "    #output_path = 'BEHRT/Early_integration/Tasks/Output/binary_clf'\n",
        "    #os.makedirs(output_path, exist_ok=True)\n",
        "    #torch.save(model.state_dict(), optim.state_dict()), output_path+'/checkpoint.pt')\n",
        "    #session.report({'loss':np.mean(val_loss), 'f1_score':np.mean(tot_f1)}, checkpoint=checkpoint)\n",
        "\n",
        "    return tot_f1, tot_roc, val_loss, validation_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b76f5e0b-f4a4-4dbb-978b-194f56d42bdf",
      "metadata": {
        "id": "b76f5e0b-f4a4-4dbb-978b-194f56d42bdf"
      },
      "outputs": [],
      "source": [
        "def train_BEHRT(config, epochs=range(2), inputs='inputs_quantiles_preprocessed_100_therap_removed_tolist', age = \"age_100_therap_removed_into_chunks_tolist\",\n",
        "         modalities = 'modalities_100_therap_removed_into_chunks_tolist', delay ='delays_100_therap_removed_into_chunks_tolist'):\n",
        "\n",
        "    set_seed()\n",
        "    train_skf = pd.concat([train, valid])\n",
        "    X_train_skf = train_skf['inputs_quantiles_preprocessed_100_therap_removed_tolist']\n",
        "    y_train_skf = train_skf['label']\n",
        "\n",
        "    n = 5\n",
        "    skf = StratifiedKFold(n_splits = n)\n",
        "\n",
        "\n",
        "    for i, (train_idx, cross_val_idx) in enumerate(skf.split(X_train_skf, y_train_skf)):\n",
        "        train_df = train_skf.iloc[train_idx]\n",
        "        train_df.index = range(train_df.shape[0])\n",
        "        train_df.patid = range(train_df.shape[0])\n",
        "\n",
        "        cv_df = train_skf.iloc[cross_val_idx]\n",
        "        cv_df.index = range(cv_df.shape[0])\n",
        "        cv_df.patid = range(cv_df.shape[0])\n",
        "\n",
        "        ## Load train and valid data\n",
        "\n",
        "        X_tr = train_df[inputs]\n",
        "        y_tr = train_df['label']\n",
        "\n",
        "        Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=train_df, max_len=global_params['max_len_seq'], code= inputs, delay = delay, age = age, mod=modalities)\n",
        "        hp_generator = {'batch_size': config['batch_size'], 'balanced': 'balanced', 'shuffle':True}\n",
        "        train_data = DataLoader(dataset=Dset, batch_size=config['batch_size'],  sampler = StratifiedSampler(X_tr, y_tr, batch_size=config['batch_size']) , **kwargs)\n",
        "\n",
        "        Dset = NextVisit(token2idx = tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=cv_df, max_len=global_params['max_len_seq'], code= inputs, delay = delay, age = age, mod=modalities)\n",
        "        valid_data = DataLoader(dataset = Dset, batch_size=config['batch_size'],  shuffle = True, **kwargs)\n",
        "\n",
        "        model, optimizer = define_model(config)\n",
        "        model.to(global_params['device'])\n",
        "\n",
        "    ## To restore checkpoint, use 'checkpoint.get_checkpoint()'\n",
        "        loaded_checkpoint = session.get_checkpoint()\n",
        "        if loaded_checkpoint:\n",
        "            with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
        "                model_state, optimizer_state = torch.load(os.pathe.join(loaded_checkpoint_dir, \"checkpoint_test.pt\"))\n",
        "\n",
        "        model.load_state_dict(model_state)\n",
        "        optim.load_state_dict(optimizer_state)\n",
        "\n",
        "        for e in range(epochs):\n",
        "            valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats = training(e, train_data, valid_data)\n",
        "            mean_f1 = np.mean(valid_f1)\n",
        "\n",
        "            if mean_f1 > best_pre:\n",
        "                ## Save a trained model\n",
        "                model_to_save = model.module if hasattr(model, 'module') else model\n",
        "                output_module_file = os.path.join(global_params['output_dir'])\n",
        "                create_folder(global_params['output_dir'])\n",
        "                torch.save(model_to_save.state_dict(), output_model_file)\n",
        "                best_pre = mean_f1\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21db18ce-52a2-45f2-84ea-e0e1179166c6",
      "metadata": {
        "id": "21db18ce-52a2-45f2-84ea-e0e1179166c6"
      },
      "outputs": [],
      "source": [
        "def test_BEHRT(best_result, inputs='inputs_curve_intersections_preprocessed_100_therap_removed_tolist', age= \"age_100_therap_removed_into_chunks_tolist\",\n",
        "              delay='delays_100_therap_removed_into_chunks_tolist', mod = 'modalities_100_therap_removed_into_chunks_tolist'):\n",
        "\n",
        "    Dset = NextVisit(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=test, max_len=global_params['max_len_seq'],\n",
        "                     code = inputs, delay = delay, age = age, mod=mod )\n",
        "    testload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  shuffle = False, **kwargs)\n",
        "\n",
        "    model = define_model(best_result)\n",
        "    model.to(global_params['device'])\n",
        "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), 'checkpoint_test.pt')\n",
        "\n",
        "    model_state, optimizer_state = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(model_state)\n",
        "\n",
        "    y, y_label = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, batch in enumerate(testload):\n",
        "            model.eval()\n",
        "\n",
        "            age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch\n",
        "            targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
        "\n",
        "            age_ids = age_ids.to(global_params['device'])\n",
        "            mod_ids = mod_ids.to(global_params['device'])\n",
        "            del_ids = del_ids.to(global_params['device'])\n",
        "            input_ids = input_ids.to(global_params['device'])\n",
        "            posi_ids = posi_ids.to(global_params['device'])\n",
        "            segment_ids = segment_ids.to(global_params['device'])\n",
        "            attMask = attMask.to(global_params['device'])\n",
        "            targets = targets.to(global_params['device'])\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids, mod_ids, age_ids, del_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets, output_attentions=True)\n",
        "\n",
        "            logits = outputs.logits.cpu()\n",
        "            targets = targets.cpu()\n",
        "\n",
        "            y_label.append(targets)\n",
        "            y.append(logits)\n",
        "\n",
        "\n",
        "    y_label = torch.cat(y_label, dim=0)\n",
        "    y = torch.cat(y, dim=0)\n",
        "\n",
        "     # Compute ROC curve and ROC area for each class\n",
        "    f1, roc, recall, precision, output, label, = precision_test(y, y_label)\n",
        "\n",
        "    print(\"Best trial test set scores: f1: {}, roc: {}, recall: {} and precision: {}.\".format(f1, roc, recall, precision))\n",
        "\n",
        "    return y, y_label\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c0f8f2-54c3-44c0-b119-d9185898c5f0",
      "metadata": {
        "id": "68c0f8f2-54c3-44c0-b119-d9185898c5f0"
      },
      "outputs": [],
      "source": [
        "## Training with best config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d529ce6e-2f76-4315-a4fa-683cca69709e",
      "metadata": {
        "id": "d529ce6e-2f76-4315-a4fa-683cca69709e"
      },
      "outputs": [],
      "source": [
        "best_config = best_result.config\n",
        "hf._dump_pkl(best_config, 'best_config')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06887ce-2df1-4e89-880b-8e69fbfd4b46",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "b06887ce-2df1-4e89-880b-8e69fbfd4b46",
        "outputId": "fbdeee12-30b8-4630-f1cd-5fb46e6f384a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Generating Inputs for fold 0\n",
            "========================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\t| Cnt: 1\t| Loss: 0.1737854778766632\t| f1 score: 0.5844155844155844\n",
            "epoch: 0\t| Cnt: 41\t| Loss: 0.15901452172547578\t| f1 score: 0.6177494428544216\n",
            "epoch: 0\t| Cnt: 81\t| Loss: 0.11556752566248178\t| f1 score: 0.7947555179884922\n",
            "epoch: 0\t| Cnt: 121\t| Loss: 0.11486855605617166\t| f1 score: 0.7910052163360064\n",
            "epoch: 0\t| Cnt: 161\t| Loss: 0.1013754797168076\t| f1 score: 0.8284525325452066\n",
            "epoch: 0\t| Cnt: 201\t| Loss: 0.10122865634039044\t| f1 score: 0.8372725148053333\n",
            "epoch: 0\t| Cnt: 241\t| Loss: 0.08832060117274523\t| f1 score: 0.8564316148687878\n",
            "\n",
            "Average training loss: 0.11\n",
            "Average training score: 0.80\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.30\n",
            "Validation took: 0:00:16\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.6556818181818181\n",
            "\n",
            "epoch: 1\t| Cnt: 1\t| Loss: 0.06098473072052002\t| f1 score: 0.9372549019607843\n",
            "epoch: 1\t| Cnt: 41\t| Loss: 0.07418443919159472\t| f1 score: 0.8869125171574993\n",
            "epoch: 1\t| Cnt: 81\t| Loss: 0.07386575150303543\t| f1 score: 0.8846724294068565\n",
            "epoch: 1\t| Cnt: 121\t| Loss: 0.06334008174017072\t| f1 score: 0.9049157323368252\n",
            "epoch: 1\t| Cnt: 161\t| Loss: 0.07049072296358645\t| f1 score: 0.8928876076960549\n",
            "epoch: 1\t| Cnt: 201\t| Loss: 0.06817240882664918\t| f1 score: 0.8898673703971667\n",
            "epoch: 1\t| Cnt: 241\t| Loss: 0.0664209860842675\t| f1 score: 0.8952895764048598\n",
            "\n",
            "Average training loss: 0.07\n",
            "Average training score: 0.89\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.30\n",
            "Validation took: 0:00:16\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.6584553156303964\n",
            "\n",
            "epoch: 2\t| Cnt: 1\t| Loss: 0.05056744068861008\t| f1 score: 0.906158357771261\n",
            "epoch: 2\t| Cnt: 41\t| Loss: 0.047201320878230035\t| f1 score: 0.9300387770869272\n",
            "epoch: 2\t| Cnt: 81\t| Loss: 0.03907805907074362\t| f1 score: 0.945168096880273\n",
            "epoch: 2\t| Cnt: 121\t| Loss: 0.0447546886978671\t| f1 score: 0.9371434149082107\n",
            "epoch: 2\t| Cnt: 161\t| Loss: 0.043640522146597506\t| f1 score: 0.9388593115137315\n",
            "epoch: 2\t| Cnt: 201\t| Loss: 0.04149127730634063\t| f1 score: 0.9521463926750439\n",
            "epoch: 2\t| Cnt: 241\t| Loss: 0.046138294017873706\t| f1 score: 0.9340084357108175\n",
            "\n",
            "Average training loss: 0.04\n",
            "Average training score: 0.94\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.27\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.6887841549402048\n",
            "\n",
            "epoch: 3\t| Cnt: 1\t| Loss: 0.03751026839017868\t| f1 score: 0.906158357771261\n",
            "epoch: 3\t| Cnt: 41\t| Loss: 0.03807493806816638\t| f1 score: 0.9490189934722668\n",
            "epoch: 3\t| Cnt: 81\t| Loss: 0.03155179450986907\t| f1 score: 0.9616027295486909\n",
            "epoch: 3\t| Cnt: 121\t| Loss: 0.03712550919735804\t| f1 score: 0.9451310564717005\n",
            "epoch: 3\t| Cnt: 161\t| Loss: 0.03542033793637529\t| f1 score: 0.9521275793957656\n",
            "epoch: 3\t| Cnt: 201\t| Loss: 0.03470048118615523\t| f1 score: 0.9521954742813297\n",
            "epoch: 3\t| Cnt: 241\t| Loss: 0.03174283526604995\t| f1 score: 0.9544735118404393\n",
            "\n",
            "Average training loss: 0.03\n",
            "Average training score: 0.95\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.30\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.6738318471108554\n",
            "\n",
            "epoch: 4\t| Cnt: 1\t| Loss: 0.037710368633270264\t| f1 score: 0.9372549019607843\n",
            "epoch: 4\t| Cnt: 41\t| Loss: 0.03445082845864818\t| f1 score: 0.9482697118984784\n",
            "epoch: 4\t| Cnt: 81\t| Loss: 0.032819464313797654\t| f1 score: 0.955328328355814\n",
            "epoch: 4\t| Cnt: 121\t| Loss: 0.02467094254679978\t| f1 score: 0.9718367618308321\n",
            "epoch: 4\t| Cnt: 161\t| Loss: 0.021712886221939696\t| f1 score: 0.972598847823587\n",
            "epoch: 4\t| Cnt: 201\t| Loss: 0.024834045208990574\t| f1 score: 0.9702276954281224\n",
            "epoch: 4\t| Cnt: 241\t| Loss: 0.025918083399301396\t| f1 score: 0.9679021656316487\n",
            "\n",
            "Average training loss: 0.03\n",
            "Average training score: 0.96\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.13\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.8098157112738068\n",
            "\n",
            "epoch: 5\t| Cnt: 1\t| Loss: 0.010936887934803963\t| f1 score: 1.0\n",
            "epoch: 5\t| Cnt: 41\t| Loss: 0.02113882965641096\t| f1 score: 0.9718229615893279\n",
            "epoch: 5\t| Cnt: 81\t| Loss: 0.017273560317698868\t| f1 score: 0.9780760163302858\n",
            "epoch: 5\t| Cnt: 121\t| Loss: 0.017824013257632033\t| f1 score: 0.9741658392930436\n",
            "epoch: 5\t| Cnt: 161\t| Loss: 0.019950372370658442\t| f1 score: 0.9748982498036799\n",
            "epoch: 5\t| Cnt: 201\t| Loss: 0.01953466628328897\t| f1 score: 0.978092871312748\n",
            "epoch: 5\t| Cnt: 241\t| Loss: 0.01768150061252527\t| f1 score: 0.9780451618532944\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.13\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.8196428571428571\n",
            "\n",
            "epoch: 6\t| Cnt: 1\t| Loss: 0.011996705085039139\t| f1 score: 0.9687194525904204\n",
            "epoch: 6\t| Cnt: 41\t| Loss: 0.020209870685357602\t| f1 score: 0.9780882712322466\n",
            "epoch: 6\t| Cnt: 81\t| Loss: 0.02444001934491098\t| f1 score: 0.9702511707863447\n",
            "epoch: 6\t| Cnt: 121\t| Loss: 0.015777654462726786\t| f1 score: 0.9851232490164638\n",
            "epoch: 6\t| Cnt: 161\t| Loss: 0.020883691345807164\t| f1 score: 0.9764888072733392\n",
            "epoch: 6\t| Cnt: 201\t| Loss: 0.018866439152043314\t| f1 score: 0.9804358576275085\n",
            "epoch: 6\t| Cnt: 241\t| Loss: 0.015626114804763346\t| f1 score: 0.9812147986027255\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.15\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8001312534706446\n",
            "\n",
            "epoch: 7\t| Cnt: 1\t| Loss: 0.014290688559412956\t| f1 score: 0.9687194525904204\n",
            "epoch: 7\t| Cnt: 41\t| Loss: 0.014519436849514022\t| f1 score: 0.9851401946409062\n",
            "epoch: 7\t| Cnt: 81\t| Loss: 0.019696836051298305\t| f1 score: 0.9757252665830212\n",
            "epoch: 7\t| Cnt: 121\t| Loss: 0.015585745830321684\t| f1 score: 0.9796538439422691\n",
            "epoch: 7\t| Cnt: 161\t| Loss: 0.012381937424652278\t| f1 score: 0.9874785808751654\n",
            "epoch: 7\t| Cnt: 201\t| Loss: 0.015523729362757876\t| f1 score: 0.9843335625407004\n",
            "epoch: 7\t| Cnt: 241\t| Loss: 0.012902538548223675\t| f1 score: 0.9866965671899258\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.13\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.8210869875546674\n",
            "\n",
            "epoch: 8\t| Cnt: 1\t| Loss: 0.010059630498290062\t| f1 score: 1.0\n",
            "epoch: 8\t| Cnt: 41\t| Loss: 0.013045468367636204\t| f1 score: 0.9851432673509286\n",
            "epoch: 8\t| Cnt: 81\t| Loss: 0.012058301529032178\t| f1 score: 0.9859237536656892\n",
            "epoch: 8\t| Cnt: 121\t| Loss: 0.011412960782763548\t| f1 score: 0.9882528311279006\n",
            "epoch: 8\t| Cnt: 161\t| Loss: 0.012932428671047092\t| f1 score: 0.9843489807946639\n",
            "epoch: 8\t| Cnt: 201\t| Loss: 0.01661906109075062\t| f1 score: 0.9843535808751653\n",
            "epoch: 8\t| Cnt: 241\t| Loss: 0.016299005405744537\t| f1 score: 0.9820136852394917\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.09\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.8605163439674514\n",
            "\n",
            "epoch: 9\t| Cnt: 1\t| Loss: 0.006283922120928764\t| f1 score: 1.0\n",
            "epoch: 9\t| Cnt: 41\t| Loss: 0.012982575356727467\t| f1 score: 0.9874693807141626\n",
            "epoch: 9\t| Cnt: 81\t| Loss: 0.011123678481089883\t| f1 score: 0.9867026946409062\n",
            "epoch: 9\t| Cnt: 121\t| Loss: 0.01155781657435\t| f1 score: 0.9859206809556668\n",
            "epoch: 9\t| Cnt: 161\t| Loss: 0.01615923779318109\t| f1 score: 0.9804373849979875\n",
            "epoch: 9\t| Cnt: 201\t| Loss: 0.010907208334538154\t| f1 score: 0.9890487356966247\n",
            "epoch: 9\t| Cnt: 241\t| Loss: 0.012039867509156466\t| f1 score: 0.9827895535046863\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.11\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.84786697741241\n",
            "\n",
            "epoch: 10\t| Cnt: 1\t| Loss: 0.002883103210479021\t| f1 score: 1.0\n",
            "epoch: 10\t| Cnt: 41\t| Loss: 0.021117435846826994\t| f1 score: 0.9772816391320408\n",
            "epoch: 10\t| Cnt: 81\t| Loss: 0.018748978173243815\t| f1 score: 0.979658426053706\n",
            "epoch: 10\t| Cnt: 121\t| Loss: 0.016920375055633485\t| f1 score: 0.9812255261342073\n",
            "epoch: 10\t| Cnt: 161\t| Loss: 0.014462154993088916\t| f1 score: 0.9851279397389454\n",
            "epoch: 10\t| Cnt: 201\t| Loss: 0.013806924995151348\t| f1 score: 0.9866734761454385\n",
            "epoch: 10\t| Cnt: 241\t| Loss: 0.013244077100534924\t| f1 score: 0.9843367258927032\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.14\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8136191890928506\n",
            "\n",
            "epoch: 11\t| Cnt: 1\t| Loss: 0.06734278798103333\t| f1 score: 0.9372549019607843\n",
            "epoch: 11\t| Cnt: 41\t| Loss: 0.017252639689831994\t| f1 score: 0.9819875214849819\n",
            "epoch: 11\t| Cnt: 81\t| Loss: 0.011603003955679014\t| f1 score: 0.9874893084066472\n",
            "epoch: 11\t| Cnt: 121\t| Loss: 0.01470451383793261\t| f1 score: 0.9843381626212018\n",
            "epoch: 11\t| Cnt: 161\t| Loss: 0.006871271473937668\t| f1 score: 0.9945213041228221\n",
            "epoch: 11\t| Cnt: 201\t| Loss: 0.007913736451882869\t| f1 score: 0.9921752630671037\n",
            "epoch: 11\t| Cnt: 241\t| Loss: 0.011938265805656555\t| f1 score: 0.9874785808751654\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.15\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8185665519109312\n",
            "\n",
            "epoch: 12\t| Cnt: 1\t| Loss: 0.0030980652663856745\t| f1 score: 1.0\n",
            "epoch: 12\t| Cnt: 41\t| Loss: 0.011356578397681005\t| f1 score: 0.9882728494623656\n",
            "epoch: 12\t| Cnt: 81\t| Loss: 0.010717545539955608\t| f1 score: 0.9906066356161233\n",
            "epoch: 12\t| Cnt: 121\t| Loss: 0.00935357342241332\t| f1 score: 0.9898292220113852\n",
            "epoch: 12\t| Cnt: 161\t| Loss: 0.011269089611596428\t| f1 score: 0.9898168584983796\n",
            "epoch: 12\t| Cnt: 201\t| Loss: 0.009017628734000027\t| f1 score: 0.9905646872629795\n",
            "epoch: 12\t| Cnt: 241\t| Loss: 0.0063143055944237855\t| f1 score: 0.9937438905180841\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9055800770077946\n",
            "\n",
            "epoch: 13\t| Cnt: 1\t| Loss: 0.042849116027355194\t| f1 score: 0.9375\n",
            "epoch: 13\t| Cnt: 41\t| Loss: 0.013576833839761094\t| f1 score: 0.986687367028923\n",
            "epoch: 13\t| Cnt: 81\t| Loss: 0.014177407664828934\t| f1 score: 0.987473980794664\n",
            "epoch: 13\t| Cnt: 121\t| Loss: 0.011828006413998083\t| f1 score: 0.9874785808751654\n",
            "epoch: 13\t| Cnt: 161\t| Loss: 0.010941676638321952\t| f1 score: 0.9890441356161233\n",
            "epoch: 13\t| Cnt: 201\t| Loss: 0.0134131173719652\t| f1 score: 0.9851186489359623\n",
            "epoch: 13\t| Cnt: 241\t| Loss: 0.010103169607464223\t| f1 score: 0.9898261493013628\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9188187459607335\n",
            "\n",
            "epoch: 14\t| Cnt: 1\t| Loss: 0.041038867086172104\t| f1 score: 0.9687194525904204\n",
            "epoch: 14\t| Cnt: 41\t| Loss: 0.008604481929796747\t| f1 score: 0.9913978494623656\n",
            "epoch: 14\t| Cnt: 81\t| Loss: 0.008488575815863441\t| f1 score: 0.9921333147139599\n",
            "epoch: 14\t| Cnt: 121\t| Loss: 0.01158184930391144\t| f1 score: 0.9882651946409062\n",
            "epoch: 14\t| Cnt: 161\t| Loss: 0.009225808281917125\t| f1 score: 0.9913978494623656\n",
            "epoch: 14\t| Cnt: 201\t| Loss: 0.011462393720285036\t| f1 score: 0.9866980945604048\n",
            "epoch: 14\t| Cnt: 241\t| Loss: 0.004928658148855902\t| f1 score: 0.9953033178080617\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.918054392153817\n",
            "\n",
            "epoch: 15\t| Cnt: 1\t| Loss: 0.001188954571262002\t| f1 score: 1.0\n",
            "epoch: 15\t| Cnt: 41\t| Loss: 0.010117251102929003\t| f1 score: 0.9913932493818642\n",
            "epoch: 15\t| Cnt: 81\t| Loss: 0.011176847296883351\t| f1 score: 0.9890333174426612\n",
            "epoch: 15\t| Cnt: 121\t| Loss: 0.007492580790130887\t| f1 score: 0.9913978494623656\n",
            "epoch: 15\t| Cnt: 161\t| Loss: 0.007806619633629453\t| f1 score: 0.9921706629866023\n",
            "epoch: 15\t| Cnt: 201\t| Loss: 0.008979013431235217\t| f1 score: 0.9906158357771261\n",
            "epoch: 15\t| Cnt: 241\t| Loss: 0.00966833563434193\t| f1 score: 0.9890518084066471\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8987116284570289\n",
            "\n",
            "epoch: 16\t| Cnt: 1\t| Loss: 0.032956480979919434\t| f1 score: 0.9687194525904204\n",
            "epoch: 16\t| Cnt: 41\t| Loss: 0.009219336591195315\t| f1 score: 0.9898292220113852\n",
            "epoch: 16\t| Cnt: 81\t| Loss: 0.006077039045339916\t| f1 score: 0.9937392904375827\n",
            "epoch: 16\t| Cnt: 121\t| Loss: 0.0052958074869820845\t| f1 score: 0.9945259042033235\n",
            "epoch: 16\t| Cnt: 161\t| Loss: 0.00830406563836732\t| f1 score: 0.9890487356966247\n",
            "epoch: 16\t| Cnt: 201\t| Loss: 0.006578365821042098\t| f1 score: 0.9906112356966247\n",
            "epoch: 16\t| Cnt: 241\t| Loss: 0.006662974488426699\t| f1 score: 0.9913932493818642\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8910342261904762\n",
            "\n",
            "epoch: 17\t| Cnt: 1\t| Loss: 0.012070396915078163\t| f1 score: 0.9687194525904204\n",
            "epoch: 17\t| Cnt: 41\t| Loss: 0.005383373294898774\t| f1 score: 0.9921798631476051\n",
            "epoch: 17\t| Cnt: 81\t| Loss: 0.011570076999487356\t| f1 score: 0.9858556415580356\n",
            "epoch: 17\t| Cnt: 121\t| Loss: 0.007500215737672988\t| f1 score: 0.9937392904375827\n",
            "epoch: 17\t| Cnt: 161\t| Loss: 0.007575853305752389\t| f1 score: 0.9913932493818642\n",
            "epoch: 17\t| Cnt: 201\t| Loss: 0.006631410220870748\t| f1 score: 0.9921798631476051\n",
            "epoch: 17\t| Cnt: 241\t| Loss: 0.009525628589472035\t| f1 score: 0.9906158357771261\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:16\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9220581247267682\n",
            "\n",
            "epoch: 18\t| Cnt: 1\t| Loss: 0.0012768814340233803\t| f1 score: 1.0\n",
            "epoch: 18\t| Cnt: 41\t| Loss: 0.003811000060522929\t| f1 score: 0.996871945259042\n",
            "epoch: 18\t| Cnt: 81\t| Loss: 0.01622016853070818\t| f1 score: 0.9819982490164637\n",
            "epoch: 18\t| Cnt: 121\t| Loss: 0.009560660617717076\t| f1 score: 0.9906066356161233\n",
            "epoch: 18\t| Cnt: 161\t| Loss: 0.008527648162271362\t| f1 score: 0.9913932493818642\n",
            "epoch: 18\t| Cnt: 201\t| Loss: 0.005085278763726819\t| f1 score: 0.9937469452590421\n",
            "epoch: 18\t| Cnt: 241\t| Loss: 0.005447254453611094\t| f1 score: 0.9945259042033235\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9280747373176004\n",
            "\n",
            "epoch: 19\t| Cnt: 1\t| Loss: 0.0010089441202580929\t| f1 score: 1.0\n",
            "epoch: 19\t| Cnt: 41\t| Loss: 0.004554948287841398\t| f1 score: 0.9976539589442815\n",
            "epoch: 19\t| Cnt: 81\t| Loss: 0.004060880749602802\t| f1 score: 0.9960853314933011\n",
            "epoch: 19\t| Cnt: 121\t| Loss: 0.0063617128900659735\t| f1 score: 0.9953033178080617\n",
            "epoch: 19\t| Cnt: 161\t| Loss: 0.008083198837994132\t| f1 score: 0.9914009042033236\n",
            "epoch: 19\t| Cnt: 201\t| Loss: 0.007155078781943302\t| f1 score: 0.9929634042033235\n",
            "epoch: 19\t| Cnt: 241\t| Loss: 0.004976864636410028\t| f1 score: 0.9953033178080617\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:16\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9377004687885517\n",
            "\n",
            "epoch: 20\t| Cnt: 1\t| Loss: 0.0017544386209920049\t| f1 score: 1.0\n",
            "epoch: 20\t| Cnt: 41\t| Loss: 0.006727539928397164\t| f1 score: 0.9937438905180841\n",
            "epoch: 20\t| Cnt: 81\t| Loss: 0.004874735257908469\t| f1 score: 0.9960899315738025\n",
            "epoch: 20\t| Cnt: 121\t| Loss: 0.003973224395303987\t| f1 score: 0.9960899315738025\n",
            "epoch: 20\t| Cnt: 161\t| Loss: 0.005146894609788432\t| f1 score: 0.9937438905180841\n",
            "epoch: 20\t| Cnt: 201\t| Loss: 0.010815507541701663\t| f1 score: 0.9882667220113852\n",
            "epoch: 20\t| Cnt: 241\t| Loss: 0.007428284120396711\t| f1 score: 0.9921752630671037\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9414102848686645\n",
            "\n",
            "epoch: 21\t| Cnt: 1\t| Loss: 0.0016338629648089409\t| f1 score: 1.0\n",
            "epoch: 21\t| Cnt: 41\t| Loss: 0.0064898050521151164\t| f1 score: 0.9929634042033235\n",
            "epoch: 21\t| Cnt: 81\t| Loss: 0.007584059771033935\t| f1 score: 0.9929618768328445\n",
            "epoch: 21\t| Cnt: 121\t| Loss: 0.006540193093678681\t| f1 score: 0.9929618768328445\n",
            "epoch: 21\t| Cnt: 161\t| Loss: 0.007499318789632526\t| f1 score: 0.9913978494623656\n",
            "epoch: 21\t| Cnt: 201\t| Loss: 0.005705893777485471\t| f1 score: 0.9960899315738025\n",
            "epoch: 21\t| Cnt: 241\t| Loss: 0.007100394999724813\t| f1 score: 0.9929572767523431\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9334422210836502\n",
            "\n",
            "epoch: 22\t| Cnt: 1\t| Loss: 0.0009496726561337709\t| f1 score: 1.0\n",
            "epoch: 22\t| Cnt: 41\t| Loss: 0.008877424943784717\t| f1 score: 0.9906127630671037\n",
            "epoch: 22\t| Cnt: 81\t| Loss: 0.007285896410758141\t| f1 score: 0.9937408178080617\n",
            "epoch: 22\t| Cnt: 121\t| Loss: 0.002937709796970012\t| f1 score: 0.996871945259042\n",
            "epoch: 22\t| Cnt: 161\t| Loss: 0.003472630208125338\t| f1 score: 0.9960899315738025\n",
            "epoch: 22\t| Cnt: 201\t| Loss: 0.008445498855871847\t| f1 score: 0.9913886493013628\n",
            "epoch: 22\t| Cnt: 241\t| Loss: 0.004596760062122484\t| f1 score: 0.9976539589442815\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "epoch: 23\t| Cnt: 41\t| Loss: 0.0043768083989562\t| f1 score: 0.9960899315738025\n",
            "epoch: 23\t| Cnt: 81\t| Loss: 0.004113519732345594\t| f1 score: 0.9976539589442815\n",
            "epoch: 23\t| Cnt: 121\t| Loss: 0.0038441743861767465\t| f1 score: 0.9960899315738025\n",
            "epoch: 23\t| Cnt: 161\t| Loss: 0.00700598668991006\t| f1 score: 0.9945259042033235\n",
            "epoch: 23\t| Cnt: 201\t| Loss: 0.006289197888690978\t| f1 score: 0.9937438905180841\n",
            "epoch: 23\t| Cnt: 241\t| Loss: 0.005457229811872822\t| f1 score: 0.9953033178080617\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.936768989413914\n",
            "\n",
            "epoch: 24\t| Cnt: 1\t| Loss: 0.006445278879255056\t| f1 score: 1.0\n",
            "epoch: 24\t| Cnt: 41\t| Loss: 0.006745391681033652\t| f1 score: 0.9913978494623656\n",
            "epoch: 24\t| Cnt: 81\t| Loss: 0.005918943502911134\t| f1 score: 0.9929588041228221\n",
            "epoch: 24\t| Cnt: 121\t| Loss: 0.005159155211003963\t| f1 score: 0.9945259042033235\n",
            "epoch: 24\t| Cnt: 161\t| Loss: 0.012766873327927896\t| f1 score: 0.985911480794664\n",
            "epoch: 24\t| Cnt: 201\t| Loss: 0.010966324524633819\t| f1 score: 0.9898307493818642\n",
            "epoch: 24\t| Cnt: 241\t| Loss: 0.010303525323979556\t| f1 score: 0.9890472083261457\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9013291686050375\n",
            "\n",
            "epoch: 25\t| Cnt: 1\t| Loss: 0.0011492359917610884\t| f1 score: 1.0\n",
            "epoch: 25\t| Cnt: 41\t| Loss: 0.0042542469207546675\t| f1 score: 0.9960899315738025\n",
            "epoch: 25\t| Cnt: 81\t| Loss: 0.005237807206867728\t| f1 score: 0.9945259042033235\n",
            "epoch: 25\t| Cnt: 121\t| Loss: 0.003501149125077063\t| f1 score: 0.9960899315738025\n",
            "epoch: 25\t| Cnt: 161\t| Loss: 0.005997059788933256\t| f1 score: 0.9953033178080617\n",
            "epoch: 25\t| Cnt: 201\t| Loss: 0.009442577524168883\t| f1 score: 0.9882605945604048\n",
            "epoch: 25\t| Cnt: 241\t| Loss: 0.00617580972466385\t| f1 score: 0.9953079178885631\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9420340629687232\n",
            "\n",
            "epoch: 26\t| Cnt: 1\t| Loss: 0.0011115462984889746\t| f1 score: 1.0\n",
            "epoch: 26\t| Cnt: 41\t| Loss: 0.00281526885664789\t| f1 score: 0.9976539589442815\n",
            "epoch: 26\t| Cnt: 81\t| Loss: 0.004846651686966652\t| f1 score: 0.9945259042033235\n",
            "epoch: 26\t| Cnt: 121\t| Loss: 0.0007536168908700347\t| f1 score: 1.0\n",
            "epoch: 26\t| Cnt: 201\t| Loss: 0.0032083908226923086\t| f1 score: 0.9953079178885631\n",
            "epoch: 26\t| Cnt: 241\t| Loss: 0.0063864753999951064\t| f1 score: 0.9945259042033235\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9490013975925342\n",
            "\n",
            "epoch: 27\t| Cnt: 1\t| Loss: 0.0011999417329207063\t| f1 score: 1.0\n",
            "epoch: 27\t| Cnt: 41\t| Loss: 0.002652802399097709\t| f1 score: 0.996871945259042\n",
            "epoch: 27\t| Cnt: 81\t| Loss: 0.0017842255059804303\t| f1 score: 0.9976539589442815\n",
            "epoch: 27\t| Cnt: 121\t| Loss: 0.001887080340020475\t| f1 score: 0.998435972629521\n",
            "epoch: 27\t| Cnt: 161\t| Loss: 0.0021743090663221666\t| f1 score: 0.9992179863147606\n",
            "epoch: 27\t| Cnt: 201\t| Loss: 0.00713287831076741\t| f1 score: 0.9937438905180841\n",
            "epoch: 27\t| Cnt: 241\t| Loss: 0.004147777615435189\t| f1 score: 0.996871945259042\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9121060118753093\n",
            "\n",
            "epoch: 28\t| Cnt: 1\t| Loss: 0.0004790918901562691\t| f1 score: 1.0\n",
            "epoch: 28\t| Cnt: 41\t| Loss: 0.005814403117619804\t| f1 score: 0.9953079178885631\n",
            "epoch: 28\t| Cnt: 81\t| Loss: 0.004467885446138098\t| f1 score: 0.9913947767523432\n",
            "epoch: 28\t| Cnt: 121\t| Loss: 0.004101104238361586\t| f1 score: 0.9945213041228221\n",
            "epoch: 28\t| Cnt: 161\t| Loss: 0.00795409639395075\t| f1 score: 0.9921752630671037\n",
            "epoch: 28\t| Cnt: 201\t| Loss: 0.003962075954768806\t| f1 score: 0.9929618768328445\n",
            "epoch: 28\t| Cnt: 241\t| Loss: 0.0059071782143291784\t| f1 score: 0.9921752630671037\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9182520081305227\n",
            "\n",
            "epoch: 29\t| Cnt: 1\t| Loss: 0.000762811629101634\t| f1 score: 1.0\n",
            "epoch: 29\t| Cnt: 41\t| Loss: 0.008553456147637917\t| f1 score: 0.9913932493818642\n",
            "epoch: 29\t| Cnt: 81\t| Loss: 0.005949424417485716\t| f1 score: 0.9945074132393377\n",
            "epoch: 29\t| Cnt: 121\t| Loss: 0.00567231191234896\t| f1 score: 0.9960853314933011\n",
            "epoch: 29\t| Cnt: 161\t| Loss: 0.0054991099514154484\t| f1 score: 0.9945213041228221\n",
            "epoch: 29\t| Cnt: 201\t| Loss: 0.0049717378187779104\t| f1 score: 0.9945213041228221\n",
            "epoch: 29\t| Cnt: 241\t| Loss: 0.0070759512702352366\t| f1 score: 0.9945259042033235\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.08\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8783161502465662\n",
            "\n",
            "\n",
            "\n",
            "Generating Inputs for fold 1\n",
            "========================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\t| Cnt: 1\t| Loss: 0.18460054695606232\t| f1 score: 0.36374269005847953\n",
            "epoch: 0\t| Cnt: 41\t| Loss: 0.1614008743315935\t| f1 score: 0.6122888931047934\n",
            "epoch: 0\t| Cnt: 81\t| Loss: 0.11993546094745397\t| f1 score: 0.7688326021676427\n",
            "epoch: 0\t| Cnt: 121\t| Loss: 0.10903937732800842\t| f1 score: 0.8167547689052752\n",
            "epoch: 0\t| Cnt: 161\t| Loss: 0.10552119398489594\t| f1 score: 0.805626262832242\n",
            "epoch: 0\t| Cnt: 201\t| Loss: 0.0872740475460887\t| f1 score: 0.8419461986559211\n",
            "epoch: 0\t| Cnt: 241\t| Loss: 0.09282863065600395\t| f1 score: 0.8452035383159018\n",
            "\n",
            "Average training loss: 0.11\n",
            "Average training score: 0.79\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.55\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.5454259745719146\n",
            "\n",
            "epoch: 1\t| Cnt: 1\t| Loss: 0.12095083296298981\t| f1 score: 0.8435972629521017\n",
            "epoch: 1\t| Cnt: 41\t| Loss: 0.07760655945166946\t| f1 score: 0.8661396756884703\n",
            "epoch: 1\t| Cnt: 81\t| Loss: 0.06483376952819526\t| f1 score: 0.8954991362567182\n",
            "epoch: 1\t| Cnt: 121\t| Loss: 0.05872737970203161\t| f1 score: 0.915244910640898\n",
            "epoch: 1\t| Cnt: 161\t| Loss: 0.057773901894688603\t| f1 score: 0.9088139244599649\n",
            "epoch: 1\t| Cnt: 201\t| Loss: 0.0596824792213738\t| f1 score: 0.9029205392505872\n",
            "epoch: 1\t| Cnt: 241\t| Loss: 0.046401268290355804\t| f1 score: 0.9238856507100431\n",
            "\n",
            "Average training loss: 0.06\n",
            "Average training score: 0.91\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.21\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7222721006149442\n",
            "\n",
            "epoch: 2\t| Cnt: 1\t| Loss: 0.02683442085981369\t| f1 score: 0.9375\n",
            "epoch: 2\t| Cnt: 41\t| Loss: 0.04545375313609838\t| f1 score: 0.933917847901643\n",
            "epoch: 2\t| Cnt: 81\t| Loss: 0.04256841158494353\t| f1 score: 0.9404020468705904\n",
            "epoch: 2\t| Cnt: 121\t| Loss: 0.042695833113975824\t| f1 score: 0.9427387971233256\n",
            "epoch: 2\t| Cnt: 161\t| Loss: 0.038540853350423274\t| f1 score: 0.9412363521267206\n",
            "epoch: 2\t| Cnt: 201\t| Loss: 0.03610589921008796\t| f1 score: 0.9488947809339319\n",
            "epoch: 2\t| Cnt: 241\t| Loss: 0.03420075750909746\t| f1 score: 0.9584794741412594\n",
            "\n",
            "Average training loss: 0.04\n",
            "Average training score: 0.95\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.23\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7171544768550888\n",
            "\n",
            "epoch: 3\t| Cnt: 1\t| Loss: 0.022221896797418594\t| f1 score: 0.9687194525904204\n",
            "epoch: 3\t| Cnt: 41\t| Loss: 0.03782830678392202\t| f1 score: 0.9442970813565591\n",
            "epoch: 3\t| Cnt: 81\t| Loss: 0.03763833725824952\t| f1 score: 0.9497687905133064\n",
            "epoch: 3\t| Cnt: 121\t| Loss: 0.030332482024095952\t| f1 score: 0.9568904620111436\n",
            "epoch: 3\t| Cnt: 161\t| Loss: 0.03630289101274684\t| f1 score: 0.9513211247961257\n",
            "epoch: 3\t| Cnt: 201\t| Loss: 0.0406123150489293\t| f1 score: 0.9322971721047606\n",
            "epoch: 3\t| Cnt: 241\t| Loss: 0.030417296674568207\t| f1 score: 0.960754257706386\n",
            "\n",
            "Average training loss: 0.04\n",
            "Average training score: 0.95\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.19\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7347363645431371\n",
            "\n",
            "epoch: 4\t| Cnt: 1\t| Loss: 0.010615427047014236\t| f1 score: 1.0\n",
            "epoch: 4\t| Cnt: 41\t| Loss: 0.026583580079022794\t| f1 score: 0.9662168932822397\n",
            "epoch: 4\t| Cnt: 81\t| Loss: 0.024497497384436427\t| f1 score: 0.9718245069288713\n",
            "epoch: 4\t| Cnt: 121\t| Loss: 0.02559370887465775\t| f1 score: 0.9725771935075983\n",
            "epoch: 4\t| Cnt: 161\t| Loss: 0.020716536440886557\t| f1 score: 0.9757160843910828\n",
            "epoch: 4\t| Cnt: 201\t| Loss: 0.023215274477843197\t| f1 score: 0.9717159738385529\n",
            "epoch: 4\t| Cnt: 241\t| Loss: 0.021761813171906397\t| f1 score: 0.975732939373545\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.97\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.18\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7785122563360616\n",
            "\n",
            "epoch: 5\t| Cnt: 1\t| Loss: 0.005713111720979214\t| f1 score: 1.0\n",
            "epoch: 5\t| Cnt: 41\t| Loss: 0.02582343070534989\t| f1 score: 0.9679036930021276\n",
            "epoch: 5\t| Cnt: 81\t| Loss: 0.026138411986175926\t| f1 score: 0.9678527115796264\n",
            "epoch: 5\t| Cnt: 121\t| Loss: 0.023109780956292524\t| f1 score: 0.9717937430938601\n",
            "epoch: 5\t| Cnt: 161\t| Loss: 0.02569580889539793\t| f1 score: 0.9701802796404234\n",
            "epoch: 5\t| Cnt: 201\t| Loss: 0.01988870750647038\t| f1 score: 0.9765319166522914\n",
            "epoch: 5\t| Cnt: 241\t| Loss: 0.02470943907974288\t| f1 score: 0.9702588256078041\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.97\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.14\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.793521550350776\n",
            "\n",
            "epoch: 6\t| Cnt: 1\t| Loss: 0.04155377298593521\t| f1 score: 0.9375\n",
            "epoch: 6\t| Cnt: 41\t| Loss: 0.023143210681155324\t| f1 score: 0.9694584295696235\n",
            "epoch: 6\t| Cnt: 81\t| Loss: 0.018688011658377947\t| f1 score: 0.9780139410316323\n",
            "epoch: 6\t| Cnt: 121\t| Loss: 0.02247410761192441\t| f1 score: 0.9764796977543166\n",
            "epoch: 6\t| Cnt: 161\t| Loss: 0.024339205812430008\t| f1 score: 0.9710040566180969\n",
            "epoch: 6\t| Cnt: 201\t| Loss: 0.015091065276646987\t| f1 score: 0.9804327849174861\n",
            "epoch: 6\t| Cnt: 241\t| Loss: 0.021688536513829605\t| f1 score: 0.976528843942269\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.10\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8564156324580607\n",
            "\n",
            "epoch: 7\t| Cnt: 1\t| Loss: 0.005008196923881769\t| f1 score: 1.0\n",
            "epoch: 7\t| Cnt: 41\t| Loss: 0.019884274597279726\t| f1 score: 0.9757391574665057\n",
            "epoch: 7\t| Cnt: 81\t| Loss: 0.02419265571224969\t| f1 score: 0.9694769205336093\n",
            "epoch: 7\t| Cnt: 121\t| Loss: 0.021544074936537073\t| f1 score: 0.9773123849979874\n",
            "epoch: 7\t| Cnt: 161\t| Loss: 0.016870469821151347\t| f1 score: 0.9819891394974413\n",
            "epoch: 7\t| Cnt: 201\t| Loss: 0.017286902698106132\t| f1 score: 0.9780713256078041\n",
            "epoch: 7\t| Cnt: 241\t| Loss: 0.017161323205800726\t| f1 score: 0.9773032028060491\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8862654311729523\n",
            "\n",
            "epoch: 8\t| Cnt: 1\t| Loss: 0.01552809402346611\t| f1 score: 1.0\n",
            "epoch: 8\t| Cnt: 41\t| Loss: 0.017016941047040747\t| f1 score: 0.9812086711517451\n",
            "epoch: 8\t| Cnt: 81\t| Loss: 0.02138619023608044\t| f1 score: 0.973365443254863\n",
            "epoch: 8\t| Cnt: 121\t| Loss: 0.017992467439034952\t| f1 score: 0.9773001300960267\n",
            "epoch: 8\t| Cnt: 161\t| Loss: 0.015372839412884786\t| f1 score: 0.9804404577080099\n",
            "epoch: 8\t| Cnt: 201\t| Loss: 0.015301853755954654\t| f1 score: 0.9819906848369847\n",
            "epoch: 8\t| Cnt: 241\t| Loss: 0.012708093065884895\t| f1 score: 0.9851340671899258\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.09\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8788956124435869\n",
            "\n",
            "epoch: 9\t| Cnt: 1\t| Loss: 0.009531819261610508\t| f1 score: 1.0\n",
            "epoch: 9\t| Cnt: 41\t| Loss: 0.01600890804838855\t| f1 score: 0.985909953424185\n",
            "epoch: 9\t| Cnt: 81\t| Loss: 0.015085207068477758\t| f1 score: 0.9811854894652775\n",
            "epoch: 9\t| Cnt: 121\t| Loss: 0.013430845754919573\t| f1 score: 0.9843597262952102\n",
            "epoch: 9\t| Cnt: 161\t| Loss: 0.017971500812564045\t| f1 score: 0.9788825577885113\n",
            "epoch: 9\t| Cnt: 201\t| Loss: 0.016091794171370567\t| f1 score: 0.9804266574665057\n",
            "epoch: 9\t| Cnt: 241\t| Loss: 0.01852166973403655\t| f1 score: 0.9757033365643423\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9155450875895086\n",
            "\n",
            "epoch: 10\t| Cnt: 1\t| Loss: 0.03798401355743408\t| f1 score: 0.9372549019607843\n",
            "epoch: 10\t| Cnt: 41\t| Loss: 0.017033489802270197\t| f1 score: 0.9796399530587845\n",
            "epoch: 10\t| Cnt: 81\t| Loss: 0.011669037124374882\t| f1 score: 0.9882713220918866\n",
            "epoch: 10\t| Cnt: 121\t| Loss: 0.017676529317395762\t| f1 score: 0.9804280941950043\n",
            "epoch: 10\t| Cnt: 161\t| Loss: 0.013192771474132314\t| f1 score: 0.9851401946409062\n",
            "epoch: 10\t| Cnt: 201\t| Loss: 0.009212166178622283\t| f1 score: 0.9890426082456443\n",
            "epoch: 10\t| Cnt: 241\t| Loss: 0.013863998430315405\t| f1 score: 0.9859176082456443\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8996422816892229\n",
            "\n",
            "epoch: 11\t| Cnt: 1\t| Loss: 0.0013902741484344006\t| f1 score: 1.0\n",
            "epoch: 11\t| Cnt: 41\t| Loss: 0.013028304310864769\t| f1 score: 0.9851325398194468\n",
            "epoch: 11\t| Cnt: 81\t| Loss: 0.017174085014266892\t| f1 score: 0.9788748849979875\n",
            "epoch: 11\t| Cnt: 121\t| Loss: 0.013032539197592997\t| f1 score: 0.9866919671094244\n",
            "epoch: 11\t| Cnt: 161\t| Loss: 0.013889173121424393\t| f1 score: 0.9843367258927032\n",
            "epoch: 11\t| Cnt: 201\t| Loss: 0.009826702342252247\t| f1 score: 0.9898307493818642\n",
            "epoch: 11\t| Cnt: 241\t| Loss: 0.012450401109526865\t| f1 score: 0.9851325398194468\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.09\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8760149843948727\n",
            "\n",
            "epoch: 12\t| Cnt: 1\t| Loss: 0.027097482234239578\t| f1 score: 0.9372549019607843\n",
            "epoch: 12\t| Cnt: 41\t| Loss: 0.01634645703015849\t| f1 score: 0.9812209260537059\n",
            "epoch: 12\t| Cnt: 81\t| Loss: 0.012087168663856573\t| f1 score: 0.9874831809556668\n",
            "epoch: 12\t| Cnt: 121\t| Loss: 0.015211149732931518\t| f1 score: 0.9843413259732046\n",
            "epoch: 12\t| Cnt: 161\t| Loss: 0.008917873472091742\t| f1 score: 0.9882467036769202\n",
            "epoch: 12\t| Cnt: 201\t| Loss: 0.013753897298010997\t| f1 score: 0.9835592216459847\n",
            "epoch: 12\t| Cnt: 241\t| Loss: 0.011752583004999905\t| f1 score: 0.987475508165143\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9155450875895086\n",
            "\n",
            "epoch: 13\t| Cnt: 1\t| Loss: 0.009473444893956184\t| f1 score: 0.9687194525904204\n",
            "epoch: 13\t| Cnt: 41\t| Loss: 0.006288659902929794\t| f1 score: 0.9945213041228221\n",
            "epoch: 13\t| Cnt: 81\t| Loss: 0.013612500758608804\t| f1 score: 0.9859222083261457\n",
            "epoch: 13\t| Cnt: 121\t| Loss: 0.007518028050253633\t| f1 score: 0.9929618768328445\n",
            "epoch: 13\t| Cnt: 161\t| Loss: 0.011716802608862053\t| f1 score: 0.9859222083261457\n",
            "epoch: 13\t| Cnt: 201\t| Loss: 0.009490855294279755\t| f1 score: 0.9882697947214076\n",
            "epoch: 13\t| Cnt: 241\t| Loss: 0.011490693905216176\t| f1 score: 0.9882559944799034\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8923412906241377\n",
            "\n",
            "epoch: 14\t| Cnt: 1\t| Loss: 0.0013453853316605091\t| f1 score: 1.0\n",
            "epoch: 14\t| Cnt: 41\t| Loss: 0.009483675271621906\t| f1 score: 0.9906173631476051\n",
            "epoch: 14\t| Cnt: 81\t| Loss: 0.012515669537242502\t| f1 score: 0.9866965671899258\n",
            "epoch: 14\t| Cnt: 121\t| Loss: 0.006293706243741326\t| f1 score: 0.9937438905180841\n",
            "epoch: 14\t| Cnt: 161\t| Loss: 0.007207215309608728\t| f1 score: 0.9906066356161233\n",
            "epoch: 14\t| Cnt: 201\t| Loss: 0.0051248178504465615\t| f1 score: 0.9937454178885631\n",
            "epoch: 14\t| Cnt: 241\t| Loss: 0.009362778509967029\t| f1 score: 0.9882713220918866\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.08\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8867655241387737\n",
            "\n",
            "epoch: 15\t| Cnt: 1\t| Loss: 0.0011847332352772355\t| f1 score: 1.0\n",
            "epoch: 15\t| Cnt: 41\t| Loss: 0.007717118307482451\t| f1 score: 0.9898353494623656\n",
            "epoch: 15\t| Cnt: 81\t| Loss: 0.008583285677013918\t| f1 score: 0.9898246219308838\n",
            "epoch: 15\t| Cnt: 121\t| Loss: 0.007109790355025325\t| f1 score: 0.9906081629866023\n",
            "epoch: 15\t| Cnt: 161\t| Loss: 0.010187954358116258\t| f1 score: 0.9882667220113852\n",
            "epoch: 15\t| Cnt: 201\t| Loss: 0.007649341215437744\t| f1 score: 0.9913932493818642\n",
            "epoch: 15\t| Cnt: 241\t| Loss: 0.010746524868591224\t| f1 score: 0.989054863147605\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9195513792299739\n",
            "\n",
            "epoch: 16\t| Cnt: 1\t| Loss: 0.0006469282670877874\t| f1 score: 1.0\n",
            "epoch: 16\t| Cnt: 41\t| Loss: 0.011609993057209066\t| f1 score: 0.9898292220113852\n",
            "epoch: 16\t| Cnt: 81\t| Loss: 0.00945462826784933\t| f1 score: 0.9898292220113852\n",
            "epoch: 16\t| Cnt: 121\t| Loss: 0.010009700646332931\t| f1 score: 0.9898307493818642\n",
            "epoch: 16\t| Cnt: 161\t| Loss: 0.007190611750411335\t| f1 score: 0.9906112356966247\n",
            "epoch: 16\t| Cnt: 201\t| Loss: 0.004249595911824144\t| f1 score: 0.9945274315738025\n",
            "epoch: 16\t| Cnt: 241\t| Loss: 0.008869946449704003\t| f1 score: 0.9906173631476051\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9110484467889666\n",
            "\n",
            "epoch: 17\t| Cnt: 1\t| Loss: 0.02718372456729412\t| f1 score: 0.9687194525904204\n",
            "epoch: 17\t| Cnt: 41\t| Loss: 0.009816724671691191\t| f1 score: 0.9882575218503824\n",
            "epoch: 17\t| Cnt: 81\t| Loss: 0.010198419625521638\t| f1 score: 0.985911480794664\n",
            "epoch: 17\t| Cnt: 121\t| Loss: 0.006386350069078617\t| f1 score: 0.9913932493818642\n",
            "epoch: 17\t| Cnt: 161\t| Loss: 0.006593415506358724\t| f1 score: 0.9921798631476051\n",
            "epoch: 17\t| Cnt: 201\t| Loss: 0.009790635900571942\t| f1 score: 0.9906035629061009\n",
            "epoch: 17\t| Cnt: 241\t| Loss: 0.007419440387457144\t| f1 score: 0.9921752630671037\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9406551239432679\n",
            "\n",
            "epoch: 18\t| Cnt: 1\t| Loss: 0.003368513658642769\t| f1 score: 1.0\n",
            "epoch: 18\t| Cnt: 41\t| Loss: 0.007633943885593908\t| f1 score: 0.9937392904375827\n",
            "epoch: 18\t| Cnt: 81\t| Loss: 0.011067295941757038\t| f1 score: 0.9866750035159175\n",
            "epoch: 18\t| Cnt: 121\t| Loss: 0.005967586397309788\t| f1 score: 0.9953033178080617\n",
            "epoch: 18\t| Cnt: 161\t| Loss: 0.00665995197778102\t| f1 score: 0.9921752630671037\n",
            "epoch: 18\t| Cnt: 201\t| Loss: 0.009421191608998925\t| f1 score: 0.9898261493013628\n",
            "epoch: 18\t| Cnt: 241\t| Loss: 0.007474293427367229\t| f1 score: 0.9921798631476051\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.917253755799097\n",
            "\n",
            "epoch: 19\t| Cnt: 1\t| Loss: 0.0026969965547323227\t| f1 score: 1.0\n",
            "epoch: 19\t| Cnt: 41\t| Loss: 0.008994255394645734\t| f1 score: 0.9913932493818642\n",
            "epoch: 19\t| Cnt: 81\t| Loss: 0.004813239684153814\t| f1 score: 0.9937392904375827\n",
            "epoch: 19\t| Cnt: 121\t| Loss: 0.009845144508290105\t| f1 score: 0.9906112356966247\n",
            "epoch: 19\t| Cnt: 161\t| Loss: 0.005675081403751392\t| f1 score: 0.9913978494623656\n",
            "epoch: 19\t| Cnt: 201\t| Loss: 0.009375144190562424\t| f1 score: 0.9898338220918866\n",
            "epoch: 19\t| Cnt: 241\t| Loss: 0.007652797536866274\t| f1 score: 0.9921798631476051\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9509455935111103\n",
            "\n",
            "epoch: 20\t| Cnt: 1\t| Loss: 0.0030082683078944683\t| f1 score: 1.0\n",
            "epoch: 20\t| Cnt: 41\t| Loss: 0.006882753563695587\t| f1 score: 0.9890472083261457\n",
            "epoch: 20\t| Cnt: 81\t| Loss: 0.007292731087363791\t| f1 score: 0.9929572767523431\n",
            "epoch: 20\t| Cnt: 121\t| Loss: 0.009754792477178854\t| f1 score: 0.9898153311279007\n",
            "epoch: 20\t| Cnt: 161\t| Loss: 0.008916499646147713\t| f1 score: 0.9874785808751654\n",
            "epoch: 20\t| Cnt: 201\t| Loss: 0.00435559565667063\t| f1 score: 0.9953033178080617\n",
            "epoch: 20\t| Cnt: 241\t| Loss: 0.010315021911810617\t| f1 score: 0.9882559944799034\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9044619059798233\n",
            "\n",
            "epoch: 21\t| Cnt: 1\t| Loss: 0.004025604575872421\t| f1 score: 1.0\n",
            "epoch: 21\t| Cnt: 41\t| Loss: 0.009966244231327437\t| f1 score: 0.9882667220113852\n",
            "epoch: 21\t| Cnt: 81\t| Loss: 0.008121398936782497\t| f1 score: 0.9929618768328445\n",
            "epoch: 21\t| Cnt: 121\t| Loss: 0.009230353951716097\t| f1 score: 0.9921813905180841\n",
            "epoch: 21\t| Cnt: 161\t| Loss: 0.00713693408324616\t| f1 score: 0.9906127630671037\n",
            "epoch: 21\t| Cnt: 201\t| Loss: 0.006115650170249865\t| f1 score: 0.9913932493818642\n",
            "epoch: 21\t| Cnt: 241\t| Loss: 0.009752174574532545\t| f1 score: 0.9906066356161233\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9476837375449085\n",
            "\n",
            "epoch: 22\t| Cnt: 1\t| Loss: 0.0011273855343461037\t| f1 score: 1.0\n",
            "epoch: 22\t| Cnt: 41\t| Loss: 0.0074714597867568955\t| f1 score: 0.9929618768328445\n",
            "epoch: 22\t| Cnt: 81\t| Loss: 0.00608646592736477\t| f1 score: 0.9945259042033235\n",
            "epoch: 22\t| Cnt: 121\t| Loss: 0.004477061973011587\t| f1 score: 0.9937438905180841\n",
            "epoch: 22\t| Cnt: 161\t| Loss: 0.004973961020004936\t| f1 score: 0.9945259042033235\n",
            "epoch: 22\t| Cnt: 201\t| Loss: 0.004448025672172662\t| f1 score: 0.9960899315738025\n",
            "epoch: 22\t| Cnt: 241\t| Loss: 0.01032860058330698\t| f1 score: 0.9898246219308838\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9242144419916456\n",
            "\n",
            "epoch: 23\t| Cnt: 1\t| Loss: 0.025427348911762238\t| f1 score: 0.9687194525904204\n",
            "epoch: 23\t| Cnt: 41\t| Loss: 0.007913521806767677\t| f1 score: 0.9898246219308838\n",
            "epoch: 23\t| Cnt: 81\t| Loss: 0.004741648151684786\t| f1 score: 0.9960914589442815\n",
            "epoch: 23\t| Cnt: 121\t| Loss: 0.004703309888282092\t| f1 score: 0.9953079178885631\n",
            "epoch: 23\t| Cnt: 161\t| Loss: 0.008968977482436458\t| f1 score: 0.9906112356966247\n",
            "epoch: 23\t| Cnt: 201\t| Loss: 0.007475773942132946\t| f1 score: 0.9905973448131402\n",
            "epoch: 23\t| Cnt: 241\t| Loss: 0.0042744668418890795\t| f1 score: 0.9953079178885631\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9616778201680322\n",
            "\n",
            "epoch: 24\t| Cnt: 1\t| Loss: 0.005264869891107082\t| f1 score: 1.0\n",
            "epoch: 24\t| Cnt: 41\t| Loss: 0.00470571967161959\t| f1 score: 0.9937392904375827\n",
            "epoch: 24\t| Cnt: 81\t| Loss: 0.005398965120184585\t| f1 score: 0.9921752630671037\n",
            "epoch: 24\t| Cnt: 121\t| Loss: 0.0036372224800288676\t| f1 score: 0.9960899315738025\n",
            "epoch: 24\t| Cnt: 161\t| Loss: 0.00685286639854894\t| f1 score: 0.9929618768328445\n",
            "epoch: 24\t| Cnt: 201\t| Loss: 0.0034314463962800803\t| f1 score: 0.996871945259042\n",
            "epoch: 24\t| Cnt: 241\t| Loss: 0.006078000253182836\t| f1 score: 0.9921813905180841\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9630519088453486\n",
            "\n",
            "epoch: 25\t| Cnt: 1\t| Loss: 0.0005486100562848151\t| f1 score: 1.0\n",
            "epoch: 25\t| Cnt: 41\t| Loss: 0.007021601087035379\t| f1 score: 0.9937438905180841\n",
            "epoch: 25\t| Cnt: 81\t| Loss: 0.007342180915293284\t| f1 score: 0.9929618768328445\n",
            "epoch: 25\t| Cnt: 121\t| Loss: 0.005675950584554812\t| f1 score: 0.9937438905180841\n",
            "epoch: 25\t| Cnt: 161\t| Loss: 0.005259769456461072\t| f1 score: 0.9953079178885631\n",
            "epoch: 25\t| Cnt: 201\t| Loss: 0.006877285342488904\t| f1 score: 0.9921521720226163\n",
            "epoch: 25\t| Cnt: 241\t| Loss: 0.006148852108890423\t| f1 score: 0.9929572767523431\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9406551239432679\n",
            "\n",
            "epoch: 26\t| Cnt: 1\t| Loss: 0.02345474250614643\t| f1 score: 0.9687194525904204\n",
            "epoch: 26\t| Cnt: 41\t| Loss: 0.008114735173876397\t| f1 score: 0.9921798631476051\n",
            "epoch: 26\t| Cnt: 81\t| Loss: 0.004491832383791916\t| f1 score: 0.9945213041228221\n",
            "epoch: 26\t| Cnt: 121\t| Loss: 0.005108906727400608\t| f1 score: 0.9937438905180841\n",
            "epoch: 26\t| Cnt: 161\t| Loss: 0.0033190603768161963\t| f1 score: 0.9976539589442815\n",
            "epoch: 26\t| Cnt: 201\t| Loss: 0.0040437089912302325\t| f1 score: 0.996871945259042\n",
            "epoch: 26\t| Cnt: 241\t| Loss: 0.006603866974182892\t| f1 score: 0.9945259042033235\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9575995772986197\n",
            "\n",
            "epoch: 27\t| Cnt: 1\t| Loss: 0.005028173327445984\t| f1 score: 1.0\n",
            "epoch: 27\t| Cnt: 41\t| Loss: 0.004033326129138004\t| f1 score: 0.996871945259042\n",
            "epoch: 27\t| Cnt: 81\t| Loss: 0.0038006736460374667\t| f1 score: 0.9945213041228221\n",
            "epoch: 27\t| Cnt: 121\t| Loss: 0.00277401608072978\t| f1 score: 0.996871945259042\n",
            "epoch: 27\t| Cnt: 161\t| Loss: 0.004353074682876467\t| f1 score: 0.9953079178885631\n",
            "epoch: 27\t| Cnt: 201\t| Loss: 0.0017582398555532563\t| f1 score: 0.998435972629521\n",
            "epoch: 27\t| Cnt: 241\t| Loss: 0.003934370174101786\t| f1 score: 0.9929572767523431\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9686233209996777\n",
            "\n",
            "epoch: 28\t| Cnt: 1\t| Loss: 0.0020489152520895004\t| f1 score: 1.0\n",
            "epoch: 28\t| Cnt: 41\t| Loss: 0.005043448122887639\t| f1 score: 0.9945213041228221\n",
            "epoch: 28\t| Cnt: 81\t| Loss: 0.0037199294842139353\t| f1 score: 0.9960899315738025\n",
            "epoch: 28\t| Cnt: 121\t| Loss: 0.00454359716604813\t| f1 score: 0.996871945259042\n",
            "epoch: 28\t| Cnt: 161\t| Loss: 0.0034529119002399966\t| f1 score: 0.9960853314933011\n",
            "epoch: 28\t| Cnt: 201\t| Loss: 0.0015439765196788358\t| f1 score: 0.998435972629521\n",
            "epoch: 28\t| Cnt: 241\t| Loss: 0.0007938399990962353\t| f1 score: 1.0\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9555848381650927\n",
            "\n",
            "epoch: 29\t| Cnt: 1\t| Loss: 0.02287028357386589\t| f1 score: 0.9687194525904204\n",
            "epoch: 29\t| Cnt: 41\t| Loss: 0.007626440433523385\t| f1 score: 0.9929526766718417\n",
            "epoch: 29\t| Cnt: 81\t| Loss: 0.006563693614225485\t| f1 score: 0.9921798631476051\n",
            "epoch: 29\t| Cnt: 121\t| Loss: 0.004331409237056505\t| f1 score: 0.9945213041228221\n",
            "epoch: 29\t| Cnt: 161\t| Loss: 0.007728517327632289\t| f1 score: 0.9906112356966247\n",
            "epoch: 29\t| Cnt: 201\t| Loss: 0.004825118668668438\t| f1 score: 0.9945259042033235\n",
            "epoch: 29\t| Cnt: 241\t| Loss: 0.0038211196162592385\t| f1 score: 0.9953094452590421\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9616778201680322\n",
            "\n",
            "\n",
            "\n",
            "Generating Inputs for fold 2\n",
            "========================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\t| Cnt: 1\t| Loss: 0.17651398479938507\t| f1 score: 0.46843853820598\n",
            "epoch: 0\t| Cnt: 41\t| Loss: 0.15888127349317074\t| f1 score: 0.6111065317907896\n",
            "epoch: 0\t| Cnt: 81\t| Loss: 0.11560458382591605\t| f1 score: 0.7884348498698973\n",
            "epoch: 0\t| Cnt: 121\t| Loss: 0.10954265352338552\t| f1 score: 0.8061509304994565\n",
            "epoch: 0\t| Cnt: 161\t| Loss: 0.09927565800026059\t| f1 score: 0.83382790380128\n",
            "epoch: 0\t| Cnt: 201\t| Loss: 0.08846799042075873\t| f1 score: 0.8493115573841706\n",
            "epoch: 0\t| Cnt: 241\t| Loss: 0.08766758721321821\t| f1 score: 0.8472932433877641\n",
            "\n",
            "Average training loss: 0.11\n",
            "Average training score: 0.80\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.22\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.6958293979938452\n",
            "\n",
            "epoch: 1\t| Cnt: 1\t| Loss: 0.11676933616399765\t| f1 score: 0.8117647058823529\n",
            "epoch: 1\t| Cnt: 41\t| Loss: 0.07673048069700598\t| f1 score: 0.8688872972821237\n",
            "epoch: 1\t| Cnt: 81\t| Loss: 0.08268177211284637\t| f1 score: 0.859087832429163\n",
            "epoch: 1\t| Cnt: 121\t| Loss: 0.07241997844539583\t| f1 score: 0.8857324415603631\n",
            "epoch: 1\t| Cnt: 161\t| Loss: 0.07002714388072491\t| f1 score: 0.8905410697240242\n",
            "epoch: 1\t| Cnt: 201\t| Loss: 0.07170511269941926\t| f1 score: 0.8913719970439569\n",
            "epoch: 1\t| Cnt: 241\t| Loss: 0.055116329621523616\t| f1 score: 0.9159869780336353\n",
            "\n",
            "Average training loss: 0.07\n",
            "Average training score: 0.89\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.36\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.6165877569540277\n",
            "\n",
            "epoch: 2\t| Cnt: 1\t| Loss: 0.05160112306475639\t| f1 score: 0.9054187192118226\n",
            "epoch: 2\t| Cnt: 41\t| Loss: 0.05674332077614963\t| f1 score: 0.9117761589653262\n",
            "epoch: 2\t| Cnt: 81\t| Loss: 0.047227897495031354\t| f1 score: 0.9294228374853498\n",
            "epoch: 2\t| Cnt: 121\t| Loss: 0.04467706466093659\t| f1 score: 0.9363935916431132\n",
            "epoch: 2\t| Cnt: 161\t| Loss: 0.04805415109731257\t| f1 score: 0.9292154150123156\n",
            "epoch: 2\t| Cnt: 201\t| Loss: 0.04024808981921524\t| f1 score: 0.9450397626775793\n",
            "epoch: 2\t| Cnt: 241\t| Loss: 0.04004582886118442\t| f1 score: 0.9402071965546905\n",
            "\n",
            "Average training loss: 0.05\n",
            "Average training score: 0.93\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.28\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.6785983963180037\n",
            "\n",
            "epoch: 3\t| Cnt: 1\t| Loss: 0.03921278938651085\t| f1 score: 0.9687194525904204\n",
            "epoch: 3\t| Cnt: 41\t| Loss: 0.038591473875567314\t| f1 score: 0.9442796428073368\n",
            "epoch: 3\t| Cnt: 81\t| Loss: 0.0352938239229843\t| f1 score: 0.9529469051499658\n",
            "epoch: 3\t| Cnt: 121\t| Loss: 0.029797777975909413\t| f1 score: 0.9623833244744961\n",
            "epoch: 3\t| Cnt: 161\t| Loss: 0.03078237804584205\t| f1 score: 0.959980098095631\n",
            "epoch: 3\t| Cnt: 201\t| Loss: 0.03036793149076402\t| f1 score: 0.9631715562526963\n",
            "epoch: 3\t| Cnt: 241\t| Loss: 0.028798924409784377\t| f1 score: 0.9686425066664345\n",
            "\n",
            "Average training loss: 0.03\n",
            "Average training score: 0.96\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.29\n",
            "Validation took: 0:00:16\n",
            "\n",
            "valid score: 0.6921989551308236\n",
            "\n",
            "epoch: 4\t| Cnt: 1\t| Loss: 0.003826336469501257\t| f1 score: 1.0\n",
            "epoch: 4\t| Cnt: 41\t| Loss: 0.03348756410414353\t| f1 score: 0.9560468117792842\n",
            "epoch: 4\t| Cnt: 81\t| Loss: 0.032185083837248385\t| f1 score: 0.9568766438005749\n",
            "epoch: 4\t| Cnt: 121\t| Loss: 0.0268026341102086\t| f1 score: 0.9663456844715842\n",
            "epoch: 4\t| Cnt: 161\t| Loss: 0.027166658337228\t| f1 score: 0.9671000250008994\n",
            "epoch: 4\t| Cnt: 201\t| Loss: 0.027192373108118773\t| f1 score: 0.9616260198462033\n",
            "epoch: 4\t| Cnt: 241\t| Loss: 0.02516538180061616\t| f1 score: 0.9733576798223588\n",
            "\n",
            "Average training loss: 0.03\n",
            "Average training score: 0.96\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.23\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7328382335914388\n",
            "\n",
            "epoch: 5\t| Cnt: 1\t| Loss: 0.03470476344227791\t| f1 score: 0.9372549019607843\n",
            "epoch: 5\t| Cnt: 41\t| Loss: 0.029750788887031376\t| f1 score: 0.9560760664784336\n",
            "epoch: 5\t| Cnt: 81\t| Loss: 0.023755233129486443\t| f1 score: 0.9710285843910829\n",
            "epoch: 5\t| Cnt: 121\t| Loss: 0.023635492264293134\t| f1 score: 0.9671108431743616\n",
            "epoch: 5\t| Cnt: 161\t| Loss: 0.02093882387271151\t| f1 score: 0.978091343942269\n",
            "epoch: 5\t| Cnt: 201\t| Loss: 0.025175328261684626\t| f1 score: 0.9709978385251361\n",
            "epoch: 5\t| Cnt: 241\t| Loss: 0.018921239319024608\t| f1 score: 0.9772894025645449\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.97\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.15\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.795231067449417\n",
            "\n",
            "epoch: 6\t| Cnt: 1\t| Loss: 0.05894509702920914\t| f1 score: 0.9372549019607843\n",
            "epoch: 6\t| Cnt: 41\t| Loss: 0.02267684577673208\t| f1 score: 0.9702389158843839\n",
            "epoch: 6\t| Cnt: 81\t| Loss: 0.018874394247541205\t| f1 score: 0.973345040606663\n",
            "epoch: 6\t| Cnt: 121\t| Loss: 0.019606537831714378\t| f1 score: 0.9725880116810603\n",
            "epoch: 6\t| Cnt: 161\t| Loss: 0.017625023715663702\t| f1 score: 0.9780851985222242\n",
            "epoch: 6\t| Cnt: 201\t| Loss: 0.02178416418901179\t| f1 score: 0.9764904252857984\n",
            "epoch: 6\t| Cnt: 241\t| Loss: 0.0179320250172168\t| f1 score: 0.976510352978283\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.97\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.13\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8138974436485154\n",
            "\n",
            "epoch: 7\t| Cnt: 1\t| Loss: 0.007530242670327425\t| f1 score: 1.0\n",
            "epoch: 7\t| Cnt: 41\t| Loss: 0.020434322557412087\t| f1 score: 0.9772708029895142\n",
            "epoch: 7\t| Cnt: 81\t| Loss: 0.019677515170769766\t| f1 score: 0.9749478529782831\n",
            "epoch: 7\t| Cnt: 121\t| Loss: 0.01659775141160935\t| f1 score: 0.9788748849979875\n",
            "epoch: 7\t| Cnt: 161\t| Loss: 0.019119289057562126\t| f1 score: 0.9780404711308126\n",
            "epoch: 7\t| Cnt: 201\t| Loss: 0.019191990373656154\t| f1 score: 0.9749478529782831\n",
            "epoch: 7\t| Cnt: 241\t| Loss: 0.018959639873355628\t| f1 score: 0.9749078163093532\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.09\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.856949545925102\n",
            "\n",
            "epoch: 8\t| Cnt: 1\t| Loss: 0.04391083866357803\t| f1 score: 0.9375\n",
            "epoch: 8\t| Cnt: 41\t| Loss: 0.02112606390437577\t| f1 score: 0.9756879362794433\n",
            "epoch: 8\t| Cnt: 81\t| Loss: 0.01800792583380826\t| f1 score: 0.9819998670289231\n",
            "epoch: 8\t| Cnt: 121\t| Loss: 0.016564698587171734\t| f1 score: 0.9820075398194469\n",
            "epoch: 8\t| Cnt: 161\t| Loss: 0.01569940188783221\t| f1 score: 0.9819998849979875\n",
            "epoch: 8\t| Cnt: 201\t| Loss: 0.013325967630953528\t| f1 score: 0.9843413259732046\n",
            "epoch: 8\t| Cnt: 241\t| Loss: 0.014818267864757217\t| f1 score: 0.9819968122879651\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.09\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8613709605736133\n",
            "\n",
            "epoch: 9\t| Cnt: 1\t| Loss: 0.03537449240684509\t| f1 score: 0.9687194525904204\n",
            "epoch: 9\t| Cnt: 41\t| Loss: 0.01903032630798407\t| f1 score: 0.9788748849979875\n",
            "epoch: 9\t| Cnt: 81\t| Loss: 0.016163999433047138\t| f1 score: 0.9835546215654833\n",
            "epoch: 9\t| Cnt: 121\t| Loss: 0.016369586536893622\t| f1 score: 0.9827649350897201\n",
            "epoch: 9\t| Cnt: 161\t| Loss: 0.010469845929765142\t| f1 score: 0.9890441356161233\n",
            "epoch: 9\t| Cnt: 201\t| Loss: 0.013021141910576262\t| f1 score: 0.9843320351702214\n",
            "epoch: 9\t| Cnt: 241\t| Loss: 0.018019752425607292\t| f1 score: 0.9772923666635226\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.13\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8259290686449805\n",
            "\n",
            "epoch: 10\t| Cnt: 1\t| Loss: 0.0033641927875578403\t| f1 score: 1.0\n",
            "epoch: 10\t| Cnt: 41\t| Loss: 0.01386593958886806\t| f1 score: 0.984347453424185\n",
            "epoch: 10\t| Cnt: 81\t| Loss: 0.016804773441981523\t| f1 score: 0.9780867438617676\n",
            "epoch: 10\t| Cnt: 121\t| Loss: 0.010669237072579562\t| f1 score: 0.9874831809556668\n",
            "epoch: 10\t| Cnt: 161\t| Loss: 0.011818956144270486\t| f1 score: 0.985123339658444\n",
            "epoch: 10\t| Cnt: 201\t| Loss: 0.014975906303152441\t| f1 score: 0.9765149530587844\n",
            "epoch: 10\t| Cnt: 241\t| Loss: 0.012342683676979504\t| f1 score: 0.9859191535851878\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8912396474661238\n",
            "\n",
            "epoch: 11\t| Cnt: 1\t| Loss: 0.0022427039220929146\t| f1 score: 1.0\n",
            "epoch: 11\t| Cnt: 41\t| Loss: 0.013383847381919622\t| f1 score: 0.9843535808751653\n",
            "epoch: 11\t| Cnt: 81\t| Loss: 0.014230661252804566\t| f1 score: 0.9835623670289231\n",
            "epoch: 11\t| Cnt: 121\t| Loss: 0.012557404456310905\t| f1 score: 0.9827726985222242\n",
            "epoch: 11\t| Cnt: 161\t| Loss: 0.01098772376863053\t| f1 score: 0.9898292220113852\n",
            "epoch: 11\t| Cnt: 201\t| Loss: 0.01163383549428545\t| f1 score: 0.9843427627017032\n",
            "epoch: 11\t| Cnt: 241\t| Loss: 0.009785222564823925\t| f1 score: 0.9866934944799034\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.12\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8322238426174928\n",
            "\n",
            "epoch: 12\t| Cnt: 1\t| Loss: 0.003802623599767685\t| f1 score: 1.0\n",
            "epoch: 12\t| Cnt: 41\t| Loss: 0.01288742141041439\t| f1 score: 0.9827849534241849\n",
            "epoch: 12\t| Cnt: 81\t| Loss: 0.01044758130738046\t| f1 score: 0.9882421035964188\n",
            "epoch: 12\t| Cnt: 121\t| Loss: 0.016878678018110806\t| f1 score: 0.9773046215654834\n",
            "epoch: 12\t| Cnt: 161\t| Loss: 0.010665557254105807\t| f1 score: 0.9859222083261457\n",
            "epoch: 12\t| Cnt: 201\t| Loss: 0.014705623441841453\t| f1 score: 0.9843089441257341\n",
            "epoch: 12\t| Cnt: 241\t| Loss: 0.011132762966735755\t| f1 score: 0.9874862356966247\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8987775307458514\n",
            "\n",
            "epoch: 13\t| Cnt: 1\t| Loss: 0.005950215272605419\t| f1 score: 1.0\n",
            "epoch: 13\t| Cnt: 41\t| Loss: 0.01318485951051116\t| f1 score: 0.9835684944799035\n",
            "epoch: 13\t| Cnt: 81\t| Loss: 0.009998760194866918\t| f1 score: 0.985123339658444\n",
            "epoch: 13\t| Cnt: 121\t| Loss: 0.008106271909491624\t| f1 score: 0.9921752630671037\n",
            "epoch: 13\t| Cnt: 161\t| Loss: 0.006285321201721672\t| f1 score: 0.9929618768328445\n",
            "epoch: 13\t| Cnt: 201\t| Loss: 0.00984484035288915\t| f1 score: 0.9866826763064414\n",
            "epoch: 13\t| Cnt: 241\t| Loss: 0.008035947311145718\t| f1 score: 0.9906112356966247\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8987775307458514\n",
            "\n",
            "epoch: 14\t| Cnt: 1\t| Loss: 0.0341481976211071\t| f1 score: 0.9372549019607843\n",
            "epoch: 14\t| Cnt: 41\t| Loss: 0.009808011920540594\t| f1 score: 0.9906158357771261\n",
            "epoch: 14\t| Cnt: 81\t| Loss: 0.0057132988978992215\t| f1 score: 0.9945259042033235\n",
            "epoch: 14\t| Cnt: 121\t| Loss: 0.012828808921767632\t| f1 score: 0.9851417399804496\n",
            "epoch: 14\t| Cnt: 161\t| Loss: 0.014539025016711093\t| f1 score: 0.9820106125294693\n",
            "epoch: 14\t| Cnt: 201\t| Loss: 0.01187507574504707\t| f1 score: 0.9866965671899258\n",
            "epoch: 14\t| Cnt: 241\t| Loss: 0.008906894465326332\t| f1 score: 0.9874831809556668\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9235492326833277\n",
            "\n",
            "epoch: 15\t| Cnt: 1\t| Loss: 0.05111870914697647\t| f1 score: 0.9687194525904204\n",
            "epoch: 15\t| Cnt: 41\t| Loss: 0.009740645794954617\t| f1 score: 0.9874692900721822\n",
            "epoch: 15\t| Cnt: 81\t| Loss: 0.0105456749064615\t| f1 score: 0.98667807622594\n",
            "epoch: 15\t| Cnt: 121\t| Loss: 0.01001500235433923\t| f1 score: 0.9890333174426612\n",
            "epoch: 15\t| Cnt: 161\t| Loss: 0.01220309636555612\t| f1 score: 0.9835761672704273\n",
            "epoch: 15\t| Cnt: 201\t| Loss: 0.009429430500313174\t| f1 score: 0.9890518084066471\n",
            "epoch: 15\t| Cnt: 241\t| Loss: 0.008489902048313524\t| f1 score: 0.9874847083261458\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8942250072490623\n",
            "\n",
            "epoch: 16\t| Cnt: 1\t| Loss: 0.003245897591114044\t| f1 score: 1.0\n",
            "epoch: 16\t| Cnt: 41\t| Loss: 0.005549523685476743\t| f1 score: 0.9921706629866023\n",
            "epoch: 16\t| Cnt: 81\t| Loss: 0.008751539881632197\t| f1 score: 0.9921813905180841\n",
            "epoch: 16\t| Cnt: 121\t| Loss: 0.007719636365072802\t| f1 score: 0.9890518084066471\n",
            "epoch: 16\t| Cnt: 161\t| Loss: 0.010177999005827587\t| f1 score: 0.9890487356966247\n",
            "epoch: 16\t| Cnt: 201\t| Loss: 0.004560071483138017\t| f1 score: 0.9937438905180841\n",
            "epoch: 16\t| Cnt: 241\t| Loss: 0.006095106026623398\t| f1 score: 0.9953033178080617\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9511752373905538\n",
            "\n",
            "epoch: 17\t| Cnt: 1\t| Loss: 0.05196073651313782\t| f1 score: 0.9687194525904204\n",
            "epoch: 17\t| Cnt: 41\t| Loss: 0.009951333995559253\t| f1 score: 0.9882605945604048\n",
            "epoch: 17\t| Cnt: 81\t| Loss: 0.007706900162156671\t| f1 score: 0.9937392904375827\n",
            "epoch: 17\t| Cnt: 121\t| Loss: 0.007906465519045013\t| f1 score: 0.9913840492208614\n",
            "epoch: 17\t| Cnt: 161\t| Loss: 0.006159061886864947\t| f1 score: 0.9921706629866023\n",
            "epoch: 17\t| Cnt: 201\t| Loss: 0.004826035027508624\t| f1 score: 0.9953079178885631\n",
            "epoch: 17\t| Cnt: 241\t| Loss: 0.0064487154406378975\t| f1 score: 0.9945259042033235\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9298768740177531\n",
            "\n",
            "epoch: 18\t| Cnt: 1\t| Loss: 0.00038578739622607827\t| f1 score: 1.0\n",
            "epoch: 18\t| Cnt: 41\t| Loss: 0.009680699481396004\t| f1 score: 0.9898338220918866\n",
            "epoch: 18\t| Cnt: 81\t| Loss: 0.008771374271600508\t| f1 score: 0.9913886493013628\n",
            "epoch: 18\t| Cnt: 121\t| Loss: 0.010166667921293993\t| f1 score: 0.9890472083261457\n",
            "epoch: 18\t| Cnt: 161\t| Loss: 0.01133771398308454\t| f1 score: 0.9874785808751654\n",
            "epoch: 18\t| Cnt: 201\t| Loss: 0.010707907282630913\t| f1 score: 0.9898215492208614\n",
            "epoch: 18\t| Cnt: 241\t| Loss: 0.0050382997760607395\t| f1 score: 0.9953079178885631\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9406005085880464\n",
            "\n",
            "epoch: 19\t| Cnt: 1\t| Loss: 0.0012058799620717764\t| f1 score: 1.0\n",
            "epoch: 19\t| Cnt: 41\t| Loss: 0.004795724990253802\t| f1 score: 0.9960899315738025\n",
            "epoch: 19\t| Cnt: 81\t| Loss: 0.0058906765400024595\t| f1 score: 0.9921752630671037\n",
            "epoch: 19\t| Cnt: 121\t| Loss: 0.008528223945904755\t| f1 score: 0.9906158357771261\n",
            "epoch: 19\t| Cnt: 161\t| Loss: 0.005766043199400883\t| f1 score: 0.9937392904375827\n",
            "epoch: 19\t| Cnt: 201\t| Loss: 0.0072098824864951895\t| f1 score: 0.9906066356161233\n",
            "epoch: 19\t| Cnt: 241\t| Loss: 0.005709311952523421\t| f1 score: 0.9937392904375827\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9595738158558338\n",
            "\n",
            "epoch: 20\t| Cnt: 1\t| Loss: 0.04342716187238693\t| f1 score: 0.9687194525904204\n",
            "epoch: 20\t| Cnt: 41\t| Loss: 0.0058729328848130535\t| f1 score: 0.9937438905180841\n",
            "epoch: 20\t| Cnt: 81\t| Loss: 0.0049732834202586675\t| f1 score: 0.9945259042033235\n",
            "epoch: 20\t| Cnt: 121\t| Loss: 0.009214038336358499\t| f1 score: 0.990618890518084\n",
            "epoch: 20\t| Cnt: 161\t| Loss: 0.010501640475558816\t| f1 score: 0.9906066356161233\n",
            "epoch: 20\t| Cnt: 201\t| Loss: 0.012828981844359077\t| f1 score: 0.9867011672704272\n",
            "epoch: 20\t| Cnt: 241\t| Loss: 0.009528339204553048\t| f1 score: 0.9874847083261458\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9304604194619024\n",
            "\n",
            "epoch: 21\t| Cnt: 1\t| Loss: 0.0003527483786456287\t| f1 score: 1.0\n",
            "epoch: 21\t| Cnt: 41\t| Loss: 0.005560871353372932\t| f1 score: 0.9937392904375827\n",
            "epoch: 21\t| Cnt: 81\t| Loss: 0.005805487641919171\t| f1 score: 0.9921752630671037\n",
            "epoch: 21\t| Cnt: 121\t| Loss: 0.007262829894898459\t| f1 score: 0.9913978494623656\n",
            "epoch: 21\t| Cnt: 161\t| Loss: 0.0072240799163409974\t| f1 score: 0.9913932493818642\n",
            "epoch: 21\t| Cnt: 201\t| Loss: 0.0077546548411191905\t| f1 score: 0.9913993768328446\n",
            "epoch: 21\t| Cnt: 241\t| Loss: 0.004819726696587168\t| f1 score: 0.9953079178885631\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:20\n",
            "\n",
            "valid score: 0.9511752373905538\n",
            "\n",
            "epoch: 22\t| Cnt: 1\t| Loss: 0.025152914226055145\t| f1 score: 0.9687194525904204\n",
            "epoch: 22\t| Cnt: 41\t| Loss: 0.004564368410501629\t| f1 score: 0.9945259042033235\n",
            "epoch: 22\t| Cnt: 81\t| Loss: 0.006660861965065124\t| f1 score: 0.9921752630671037\n",
            "epoch: 22\t| Cnt: 121\t| Loss: 0.003284005161913228\t| f1 score: 0.996871945259042\n",
            "epoch: 22\t| Cnt: 161\t| Loss: 0.004094718222040683\t| f1 score: 0.9960914589442815\n",
            "epoch: 22\t| Cnt: 201\t| Loss: 0.007137465388950659\t| f1 score: 0.992182917888563\n",
            "epoch: 22\t| Cnt: 241\t| Loss: 0.007709073780279141\t| f1 score: 0.9898353494623656\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.08\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.881090845769313\n",
            "\n",
            "epoch: 23\t| Cnt: 1\t| Loss: 0.005536860320717096\t| f1 score: 1.0\n",
            "epoch: 23\t| Cnt: 41\t| Loss: 0.006930931136594154\t| f1 score: 0.9921752630671037\n",
            "epoch: 23\t| Cnt: 81\t| Loss: 0.0064856056953431105\t| f1 score: 0.9921798631476051\n",
            "epoch: 23\t| Cnt: 121\t| Loss: 0.005055749227904016\t| f1 score: 0.9953033178080617\n",
            "epoch: 23\t| Cnt: 161\t| Loss: 0.0013671859545866028\t| f1 score: 0.9992179863147606\n",
            "epoch: 23\t| Cnt: 201\t| Loss: 0.0025793962686293526\t| f1 score: 0.9976539589442815\n",
            "epoch: 23\t| Cnt: 241\t| Loss: 0.0015869820461375638\t| f1 score: 0.9992179863147606\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:16\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9709913014935172\n",
            "\n",
            "epoch: 24\t| Cnt: 1\t| Loss: 0.0006116690346971154\t| f1 score: 1.0\n",
            "epoch: 24\t| Cnt: 41\t| Loss: 0.006746646568717552\t| f1 score: 0.9929588041228221\n",
            "epoch: 24\t| Cnt: 81\t| Loss: 0.003997558468108764\t| f1 score: 0.9976539589442815\n",
            "epoch: 24\t| Cnt: 121\t| Loss: 0.005372942496614996\t| f1 score: 0.9945167040423207\n",
            "epoch: 24\t| Cnt: 161\t| Loss: 0.0018214419596915832\t| f1 score: 0.9976539589442815\n",
            "epoch: 24\t| Cnt: 201\t| Loss: 0.004326186762045836\t| f1 score: 0.9953033178080617\n",
            "epoch: 24\t| Cnt: 241\t| Loss: 0.004676286554968101\t| f1 score: 0.9953094452590421\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.960231534060471\n",
            "\n",
            "epoch: 25\t| Cnt: 1\t| Loss: 0.00028108959668315947\t| f1 score: 1.0\n",
            "epoch: 25\t| Cnt: 41\t| Loss: 0.005313560469949153\t| f1 score: 0.9945167040423207\n",
            "epoch: 25\t| Cnt: 81\t| Loss: 0.006072193682848592\t| f1 score: 0.9929618768328445\n",
            "epoch: 25\t| Cnt: 121\t| Loss: 0.005694096541265026\t| f1 score: 0.9921813905180841\n",
            "epoch: 25\t| Cnt: 201\t| Loss: 0.001997648333053803\t| f1 score: 0.998435972629521\n",
            "epoch: 25\t| Cnt: 241\t| Loss: 0.0050069799817720195\t| f1 score: 0.9953079178885631\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9765438379191365\n",
            "\n",
            "epoch: 26\t| Cnt: 1\t| Loss: 0.0005424353876151145\t| f1 score: 1.0\n",
            "epoch: 26\t| Cnt: 41\t| Loss: 0.005080736073796288\t| f1 score: 0.9945259042033235\n",
            "epoch: 26\t| Cnt: 81\t| Loss: 0.0038583553472562927\t| f1 score: 0.9953033178080617\n",
            "epoch: 26\t| Cnt: 121\t| Loss: 0.0030540363499312662\t| f1 score: 0.996871945259042\n",
            "epoch: 26\t| Cnt: 161\t| Loss: 0.003941047800981323\t| f1 score: 0.9953094452590421\n",
            "epoch: 26\t| Cnt: 201\t| Loss: 0.0056773414289637\t| f1 score: 0.9953079178885631\n",
            "epoch: 26\t| Cnt: 241\t| Loss: 0.0030766465006308863\t| f1 score: 0.996871945259042\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9622149273271874\n",
            "\n",
            "epoch: 27\t| Cnt: 1\t| Loss: 0.0015730127925053239\t| f1 score: 1.0\n",
            "epoch: 27\t| Cnt: 41\t| Loss: 0.00531313526116719\t| f1 score: 0.9953079178885631\n",
            "epoch: 27\t| Cnt: 81\t| Loss: 0.006320170010076254\t| f1 score: 0.9906127630671037\n",
            "epoch: 27\t| Cnt: 121\t| Loss: 0.004105106649876689\t| f1 score: 0.9953079178885631\n",
            "epoch: 27\t| Cnt: 161\t| Loss: 0.0030772216221521377\t| f1 score: 0.9953079178885631\n",
            "epoch: 27\t| Cnt: 201\t| Loss: 0.0044615943097596755\t| f1 score: 0.9953094452590421\n",
            "epoch: 27\t| Cnt: 241\t| Loss: 0.0075874477657635\t| f1 score: 0.9945259042033235\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9550168607240568\n",
            "\n",
            "epoch: 28\t| Cnt: 1\t| Loss: 0.0002783596282824874\t| f1 score: 1.0\n",
            "epoch: 28\t| Cnt: 41\t| Loss: 0.00518316277921258\t| f1 score: 0.996871945259042\n",
            "epoch: 28\t| Cnt: 81\t| Loss: 0.0024728067357500548\t| f1 score: 0.9976493588637801\n",
            "epoch: 28\t| Cnt: 121\t| Loss: 0.004967661311093252\t| f1 score: 0.9953079178885631\n",
            "epoch: 28\t| Cnt: 161\t| Loss: 0.004411273082223488\t| f1 score: 0.9953079178885631\n",
            "epoch: 28\t| Cnt: 201\t| Loss: 0.0020923250733176245\t| f1 score: 0.9976493588637801\n",
            "epoch: 28\t| Cnt: 241\t| Loss: 0.002283446923320298\t| f1 score: 0.998435972629521\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9758432727355872\n",
            "\n",
            "epoch: 29\t| Cnt: 1\t| Loss: 0.0003849176282528788\t| f1 score: 1.0\n",
            "epoch: 29\t| Cnt: 41\t| Loss: 0.0008405797590967268\t| f1 score: 1.0\n",
            "epoch: 29\t| Cnt: 81\t| Loss: 0.004148411817004672\t| f1 score: 0.9953033178080617\n",
            "epoch: 29\t| Cnt: 121\t| Loss: 0.005353577411005972\t| f1 score: 0.9945259042033235\n",
            "epoch: 29\t| Cnt: 161\t| Loss: 0.004293449817487272\t| f1 score: 0.9945259042033235\n",
            "epoch: 29\t| Cnt: 201\t| Loss: 0.00279045831921394\t| f1 score: 0.9953033178080617\n",
            "epoch: 29\t| Cnt: 241\t| Loss: 0.005078295141356648\t| f1 score: 0.9945074132393377\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.01\n",
            "Validation took: 0:00:17\n",
            "\n",
            "** ** * Saving fine - tuned model ** ** * \n",
            "valid score: 0.9836542271068276\n",
            "\n",
            "\n",
            "\n",
            "Generating Inputs for fold 3\n",
            "========================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\t| Cnt: 1\t| Loss: 0.17926818132400513\t| f1 score: 0.4009852216748768\n",
            "epoch: 0\t| Cnt: 41\t| Loss: 0.15585429407656193\t| f1 score: 0.6317161125194313\n",
            "epoch: 0\t| Cnt: 81\t| Loss: 0.11846734285354614\t| f1 score: 0.771126183305467\n",
            "epoch: 0\t| Cnt: 121\t| Loss: 0.10950720477849245\t| f1 score: 0.8084993325656906\n",
            "epoch: 0\t| Cnt: 161\t| Loss: 0.0968978582881391\t| f1 score: 0.8298425149389196\n",
            "epoch: 0\t| Cnt: 201\t| Loss: 0.08875387636944651\t| f1 score: 0.8577110560813448\n",
            "epoch: 0\t| Cnt: 241\t| Loss: 0.0745837333612144\t| f1 score: 0.8768352292429504\n",
            "\n",
            "Average training loss: 0.10\n",
            "Average training score: 0.80\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.42\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.5976587356680898\n",
            "\n",
            "epoch: 1\t| Cnt: 1\t| Loss: 0.12984232604503632\t| f1 score: 0.7757757757757757\n",
            "epoch: 1\t| Cnt: 41\t| Loss: 0.07029291009530425\t| f1 score: 0.8894778785804128\n",
            "epoch: 1\t| Cnt: 81\t| Loss: 0.059599747369065884\t| f1 score: 0.8994848488153139\n",
            "epoch: 1\t| Cnt: 121\t| Loss: 0.05501357764005661\t| f1 score: 0.9173100378464589\n",
            "epoch: 1\t| Cnt: 161\t| Loss: 0.0555284399073571\t| f1 score: 0.9172513491022822\n",
            "epoch: 1\t| Cnt: 201\t| Loss: 0.05016949381679296\t| f1 score: 0.9229359047963774\n",
            "epoch: 1\t| Cnt: 241\t| Loss: 0.047965494357049464\t| f1 score: 0.9278381864678323\n",
            "\n",
            "Average training loss: 0.06\n",
            "Average training score: 0.92\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.19\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7475882940154068\n",
            "\n",
            "epoch: 2\t| Cnt: 1\t| Loss: 0.04788195341825485\t| f1 score: 0.9054187192118226\n",
            "epoch: 2\t| Cnt: 41\t| Loss: 0.03940372510114685\t| f1 score: 0.9427698369265798\n",
            "epoch: 2\t| Cnt: 81\t| Loss: 0.03498989045619964\t| f1 score: 0.952061610645638\n",
            "epoch: 2\t| Cnt: 121\t| Loss: 0.03627625710796565\t| f1 score: 0.9521479096366022\n",
            "epoch: 2\t| Cnt: 161\t| Loss: 0.035778416553512216\t| f1 score: 0.9560699210583887\n",
            "epoch: 2\t| Cnt: 201\t| Loss: 0.03484505006344989\t| f1 score: 0.9521433199650214\n",
            "epoch: 2\t| Cnt: 241\t| Loss: 0.03118883753195405\t| f1 score: 0.9577405698349721\n",
            "\n",
            "Average training loss: 0.04\n",
            "Average training score: 0.95\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.24\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.730666917407329\n",
            "\n",
            "epoch: 3\t| Cnt: 1\t| Loss: 0.03722342476248741\t| f1 score: 0.9372549019607843\n",
            "epoch: 3\t| Cnt: 41\t| Loss: 0.029566845495719463\t| f1 score: 0.9623602334300088\n",
            "epoch: 3\t| Cnt: 81\t| Loss: 0.029322656616568566\t| f1 score: 0.9607915515407296\n",
            "epoch: 3\t| Cnt: 121\t| Loss: 0.024570644553750753\t| f1 score: 0.9709836719389614\n",
            "epoch: 3\t| Cnt: 161\t| Loss: 0.025163221097318455\t| f1 score: 0.9693933901719923\n",
            "epoch: 3\t| Cnt: 201\t| Loss: 0.02784342788509093\t| f1 score: 0.9616197837841781\n",
            "epoch: 3\t| Cnt: 241\t| Loss: 0.022126181225758046\t| f1 score: 0.9718182528977817\n",
            "\n",
            "Average training loss: 0.03\n",
            "Average training score: 0.97\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.27\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7265954316356411\n",
            "\n",
            "epoch: 4\t| Cnt: 1\t| Loss: 0.054699160158634186\t| f1 score: 0.9054187192118226\n",
            "epoch: 4\t| Cnt: 41\t| Loss: 0.027089686930412426\t| f1 score: 0.9647646935075983\n",
            "epoch: 4\t| Cnt: 81\t| Loss: 0.02841668054461479\t| f1 score: 0.9647094740414115\n",
            "epoch: 4\t| Cnt: 121\t| Loss: 0.02713376609608531\t| f1 score: 0.96152510510811\n",
            "epoch: 4\t| Cnt: 161\t| Loss: 0.03313248956110328\t| f1 score: 0.9561226149120788\n",
            "epoch: 4\t| Cnt: 201\t| Loss: 0.02858999780146405\t| f1 score: 0.9645816390104958\n",
            "epoch: 4\t| Cnt: 241\t| Loss: 0.021710179024375977\t| f1 score: 0.9733638072733392\n",
            "\n",
            "Average training loss: 0.03\n",
            "Average training score: 0.97\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.15\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8010907716891027\n",
            "\n",
            "epoch: 5\t| Cnt: 1\t| Loss: 0.009396201930940151\t| f1 score: 1.0\n",
            "epoch: 5\t| Cnt: 41\t| Loss: 0.019204752671066673\t| f1 score: 0.9749371254468013\n",
            "epoch: 5\t| Cnt: 81\t| Loss: 0.02727512050187215\t| f1 score: 0.9631265531585946\n",
            "epoch: 5\t| Cnt: 121\t| Loss: 0.018234944343566893\t| f1 score: 0.9757191391320408\n",
            "epoch: 5\t| Cnt: 161\t| Loss: 0.021575525775551795\t| f1 score: 0.9726080479845898\n",
            "epoch: 5\t| Cnt: 201\t| Loss: 0.01776300321216695\t| f1 score: 0.9804250214849819\n",
            "epoch: 5\t| Cnt: 241\t| Loss: 0.020807930955197663\t| f1 score: 0.9804312575470071\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.97\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.15\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.808163938326929\n",
            "\n",
            "epoch: 6\t| Cnt: 1\t| Loss: 0.022675693035125732\t| f1 score: 0.9687194525904204\n",
            "epoch: 6\t| Cnt: 41\t| Loss: 0.016897423681803046\t| f1 score: 0.9812039804292635\n",
            "epoch: 6\t| Cnt: 81\t| Loss: 0.023541256948374212\t| f1 score: 0.965560706687367\n",
            "epoch: 6\t| Cnt: 121\t| Loss: 0.019445514198741874\t| f1 score: 0.9788471032310184\n",
            "epoch: 6\t| Cnt: 161\t| Loss: 0.01701601061504334\t| f1 score: 0.9812255261342073\n",
            "epoch: 6\t| Cnt: 201\t| Loss: 0.01648707608692348\t| f1 score: 0.9803801090328605\n",
            "epoch: 6\t| Cnt: 241\t| Loss: 0.019070824212394654\t| f1 score: 0.9757330300155254\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.14\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8182332373508844\n",
            "\n",
            "epoch: 7\t| Cnt: 1\t| Loss: 0.0024195914156734943\t| f1 score: 1.0\n",
            "epoch: 7\t| Cnt: 41\t| Loss: 0.020383003423921763\t| f1 score: 0.9741350934270969\n",
            "epoch: 7\t| Cnt: 81\t| Loss: 0.018152937956620006\t| f1 score: 0.9772955300155253\n",
            "epoch: 7\t| Cnt: 121\t| Loss: 0.014476125553483144\t| f1 score: 0.9843320351702214\n",
            "epoch: 7\t| Cnt: 161\t| Loss: 0.009584256410016678\t| f1 score: 0.9898353494623656\n",
            "epoch: 7\t| Cnt: 201\t| Loss: 0.018243954490753823\t| f1 score: 0.9788779577080099\n",
            "epoch: 7\t| Cnt: 241\t| Loss: 0.017552972910925745\t| f1 score: 0.9804265488554609\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.10\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.848997775833725\n",
            "\n",
            "epoch: 8\t| Cnt: 1\t| Loss: 0.00457106065005064\t| f1 score: 1.0\n",
            "epoch: 8\t| Cnt: 41\t| Loss: 0.019402553464169615\t| f1 score: 0.9804311489359623\n",
            "epoch: 8\t| Cnt: 81\t| Loss: 0.015718952217139304\t| f1 score: 0.9804188940340015\n",
            "epoch: 8\t| Cnt: 121\t| Loss: 0.01957453736104071\t| f1 score: 0.9772847118420632\n",
            "epoch: 8\t| Cnt: 161\t| Loss: 0.013522807264234871\t| f1 score: 0.9867011672704272\n",
            "epoch: 8\t| Cnt: 201\t| Loss: 0.019996717365575022\t| f1 score: 0.9765089162497844\n",
            "epoch: 8\t| Cnt: 241\t| Loss: 0.017917756567476316\t| f1 score: 0.9780821437812662\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.18\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7897419239639826\n",
            "\n",
            "epoch: 9\t| Cnt: 1\t| Loss: 0.003737706458196044\t| f1 score: 1.0\n",
            "epoch: 9\t| Cnt: 41\t| Loss: 0.009899621875956655\t| f1 score: 0.9867011672704272\n",
            "epoch: 9\t| Cnt: 81\t| Loss: 0.019679392541002018\t| f1 score: 0.9725941571011052\n",
            "epoch: 9\t| Cnt: 121\t| Loss: 0.013962631658068858\t| f1 score: 0.9827588076387397\n",
            "epoch: 9\t| Cnt: 161\t| Loss: 0.015040875590057113\t| f1 score: 0.9820090671899259\n",
            "epoch: 9\t| Cnt: 201\t| Loss: 0.011464386901934631\t| f1 score: 0.9866965671899258\n",
            "epoch: 9\t| Cnt: 241\t| Loss: 0.018961843830766156\t| f1 score: 0.9772970573860043\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.08\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8766596628282706\n",
            "\n",
            "epoch: 10\t| Cnt: 1\t| Loss: 0.020050350576639175\t| f1 score: 0.9687194525904204\n",
            "epoch: 10\t| Cnt: 41\t| Loss: 0.010775722452672198\t| f1 score: 0.9882697947214076\n",
            "epoch: 10\t| Cnt: 81\t| Loss: 0.01093745666439645\t| f1 score: 0.9874692900721822\n",
            "epoch: 10\t| Cnt: 121\t| Loss: 0.016579028783598914\t| f1 score: 0.9827649350897201\n",
            "epoch: 10\t| Cnt: 161\t| Loss: 0.014713348404620774\t| f1 score: 0.9827926262147088\n",
            "epoch: 10\t| Cnt: 201\t| Loss: 0.01416275852243416\t| f1 score: 0.9843551262147088\n",
            "epoch: 10\t| Cnt: 241\t| Loss: 0.012789306425838731\t| f1 score: 0.985124867028923\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.892639325200147\n",
            "\n",
            "epoch: 11\t| Cnt: 1\t| Loss: 0.005635935813188553\t| f1 score: 1.0\n",
            "epoch: 11\t| Cnt: 41\t| Loss: 0.009092294992296957\t| f1 score: 0.9913762857883572\n",
            "epoch: 11\t| Cnt: 81\t| Loss: 0.01704047473613173\t| f1 score: 0.9804158213239791\n",
            "epoch: 11\t| Cnt: 121\t| Loss: 0.011688498624425846\t| f1 score: 0.9858960625407004\n",
            "epoch: 11\t| Cnt: 161\t| Loss: 0.012883696175413207\t| f1 score: 0.9835454214044805\n",
            "epoch: 11\t| Cnt: 201\t| Loss: 0.014378314666100778\t| f1 score: 0.9804188940340015\n",
            "epoch: 11\t| Cnt: 241\t| Loss: 0.010281427277368494\t| f1 score: 0.9906127630671037\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.916740076324069\n",
            "\n",
            "epoch: 12\t| Cnt: 1\t| Loss: 0.009138944558799267\t| f1 score: 0.9687194525904204\n",
            "epoch: 12\t| Cnt: 41\t| Loss: 0.01336148563568713\t| f1 score: 0.984345926053706\n",
            "epoch: 12\t| Cnt: 81\t| Loss: 0.00875922488339711\t| f1 score: 0.9874847083261458\n",
            "epoch: 12\t| Cnt: 121\t| Loss: 0.011060390758211724\t| f1 score: 0.9890426082456443\n",
            "epoch: 12\t| Cnt: 161\t| Loss: 0.011276963372074534\t| f1 score: 0.9898353494623656\n",
            "epoch: 12\t| Cnt: 201\t| Loss: 0.012085798956104555\t| f1 score: 0.9851294671094244\n",
            "epoch: 12\t| Cnt: 241\t| Loss: 0.007597899084794335\t| f1 score: 0.9890487356966247\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8887763982877745\n",
            "\n",
            "epoch: 13\t| Cnt: 1\t| Loss: 0.00141667271964252\t| f1 score: 1.0\n",
            "epoch: 13\t| Cnt: 41\t| Loss: 0.009578101031365804\t| f1 score: 0.9882605945604048\n",
            "epoch: 13\t| Cnt: 81\t| Loss: 0.014599640884262044\t| f1 score: 0.9866934944799034\n",
            "epoch: 13\t| Cnt: 121\t| Loss: 0.01144480990478769\t| f1 score: 0.9874723448131402\n",
            "epoch: 13\t| Cnt: 161\t| Loss: 0.007894170423969626\t| f1 score: 0.9929618768328445\n",
            "epoch: 13\t| Cnt: 201\t| Loss: 0.012389692233409733\t| f1 score: 0.9859021899916808\n",
            "epoch: 13\t| Cnt: 241\t| Loss: 0.006368909258162603\t| f1 score: 0.9945167040423207\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "epoch: 14\t| Cnt: 41\t| Loss: 0.010546577301283833\t| f1 score: 0.9890472083261457\n",
            "epoch: 14\t| Cnt: 81\t| Loss: 0.006335573043907061\t| f1 score: 0.9929572767523431\n",
            "epoch: 14\t| Cnt: 121\t| Loss: 0.008118059518164956\t| f1 score: 0.9913947767523432\n",
            "epoch: 14\t| Cnt: 161\t| Loss: 0.008760006865486503\t| f1 score: 0.9913793584983797\n",
            "epoch: 14\t| Cnt: 201\t| Loss: 0.01228760951780714\t| f1 score: 0.9851340671899258\n",
            "epoch: 14\t| Cnt: 241\t| Loss: 0.011688895438419422\t| f1 score: 0.9882697947214076\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.06\n",
            "Validation took: 0:00:16\n",
            "\n",
            "valid score: 0.9149309484043604\n",
            "\n",
            "epoch: 15\t| Cnt: 1\t| Loss: 0.0018757542129606009\t| f1 score: 1.0\n",
            "epoch: 15\t| Cnt: 41\t| Loss: 0.008261185683659278\t| f1 score: 0.9913978494623656\n",
            "epoch: 15\t| Cnt: 81\t| Loss: 0.004911687565618194\t| f1 score: 0.9953079178885631\n",
            "epoch: 15\t| Cnt: 121\t| Loss: 0.008168487505463418\t| f1 score: 0.9929588041228221\n",
            "epoch: 15\t| Cnt: 161\t| Loss: 0.008686473097623094\t| f1 score: 0.9906127630671037\n",
            "epoch: 15\t| Cnt: 201\t| Loss: 0.007787238229502691\t| f1 score: 0.9906112356966247\n",
            "epoch: 15\t| Cnt: 241\t| Loss: 0.004805233461229364\t| f1 score: 0.9937438905180841\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9441631035067076\n",
            "\n",
            "epoch: 16\t| Cnt: 1\t| Loss: 0.00121320690959692\t| f1 score: 1.0\n",
            "epoch: 16\t| Cnt: 41\t| Loss: 0.005348291875270661\t| f1 score: 0.9953079178885631\n",
            "epoch: 16\t| Cnt: 81\t| Loss: 0.006656344806833659\t| f1 score: 0.9937454178885631\n",
            "epoch: 16\t| Cnt: 121\t| Loss: 0.013788046660192777\t| f1 score: 0.9866996219308838\n",
            "epoch: 16\t| Cnt: 161\t| Loss: 0.011074702531914227\t| f1 score: 0.9890441356161233\n",
            "epoch: 16\t| Cnt: 201\t| Loss: 0.012559539443464019\t| f1 score: 0.9858868623796976\n",
            "epoch: 16\t| Cnt: 241\t| Loss: 0.010591589182149619\t| f1 score: 0.9890333174426612\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9211001395656793\n",
            "\n",
            "epoch: 17\t| Cnt: 1\t| Loss: 0.010384170338511467\t| f1 score: 0.9687194525904204\n",
            "epoch: 17\t| Cnt: 41\t| Loss: 0.0052913052044459615\t| f1 score: 0.9945259042033235\n",
            "epoch: 17\t| Cnt: 81\t| Loss: 0.010067443519074005\t| f1 score: 0.9898292220113852\n",
            "epoch: 17\t| Cnt: 121\t| Loss: 0.0051174255095247645\t| f1 score: 0.9945213041228221\n",
            "epoch: 17\t| Cnt: 161\t| Loss: 0.012363731441291747\t| f1 score: 0.9866980945604048\n",
            "epoch: 17\t| Cnt: 201\t| Loss: 0.009578976022748976\t| f1 score: 0.9906158357771261\n",
            "epoch: 17\t| Cnt: 241\t| Loss: 0.01261232626857236\t| f1 score: 0.9851155762259399\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8980597707037716\n",
            "\n",
            "epoch: 18\t| Cnt: 1\t| Loss: 0.0007655874360352755\t| f1 score: 1.0\n",
            "epoch: 18\t| Cnt: 41\t| Loss: 0.01415670891510672\t| f1 score: 0.9859206809556668\n",
            "epoch: 18\t| Cnt: 81\t| Loss: 0.006087307406414766\t| f1 score: 0.9929588041228221\n",
            "epoch: 18\t| Cnt: 121\t| Loss: 0.00684152971371077\t| f1 score: 0.9929618768328445\n",
            "epoch: 18\t| Cnt: 161\t| Loss: 0.005240938073256984\t| f1 score: 0.9929618768328445\n",
            "epoch: 18\t| Cnt: 201\t| Loss: 0.009233637699799147\t| f1 score: 0.9890349354551204\n",
            "epoch: 18\t| Cnt: 241\t| Loss: 0.009119819402258145\t| f1 score: 0.9898353494623656\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:48\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9061785331078348\n",
            "\n",
            "epoch: 19\t| Cnt: 1\t| Loss: 0.041856300085783005\t| f1 score: 0.9687194525904204\n",
            "epoch: 19\t| Cnt: 41\t| Loss: 0.008033330999751342\t| f1 score: 0.9913886493013628\n",
            "epoch: 19\t| Cnt: 81\t| Loss: 0.004721682814124506\t| f1 score: 0.9953079178885631\n",
            "epoch: 19\t| Cnt: 121\t| Loss: 0.006851988640846685\t| f1 score: 0.9921798631476051\n",
            "epoch: 19\t| Cnt: 161\t| Loss: 0.005227346842730185\t| f1 score: 0.9945274315738025\n",
            "epoch: 19\t| Cnt: 201\t| Loss: 0.006754860173532507\t| f1 score: 0.9906050902765798\n",
            "epoch: 19\t| Cnt: 241\t| Loss: 0.008674490584235172\t| f1 score: 0.9898292220113852\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9335145159321794\n",
            "\n",
            "epoch: 20\t| Cnt: 1\t| Loss: 0.002130052074790001\t| f1 score: 1.0\n",
            "epoch: 20\t| Cnt: 41\t| Loss: 0.008071926890261238\t| f1 score: 0.9890533357771261\n",
            "epoch: 20\t| Cnt: 81\t| Loss: 0.007028231468575541\t| f1 score: 0.9921767904375827\n",
            "epoch: 20\t| Cnt: 121\t| Loss: 0.0022392445738660172\t| f1 score: 0.9968673451785406\n",
            "epoch: 20\t| Cnt: 161\t| Loss: 0.009111862543068127\t| f1 score: 0.9913947767523432\n",
            "epoch: 20\t| Cnt: 201\t| Loss: 0.009664441995846573\t| f1 score: 0.9906112356966247\n",
            "epoch: 20\t| Cnt: 241\t| Loss: 0.004648728777829092\t| f1 score: 0.9960899315738025\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9283587424227955\n",
            "\n",
            "epoch: 21\t| Cnt: 1\t| Loss: 0.0010188375599682331\t| f1 score: 1.0\n",
            "epoch: 21\t| Cnt: 41\t| Loss: 0.008093072974588722\t| f1 score: 0.9921706629866023\n",
            "epoch: 21\t| Cnt: 81\t| Loss: 0.0053827684532734565\t| f1 score: 0.9921752630671037\n",
            "epoch: 21\t| Cnt: 121\t| Loss: 0.004607881110132439\t| f1 score: 0.9945259042033235\n",
            "epoch: 21\t| Cnt: 161\t| Loss: 0.005586439302715007\t| f1 score: 0.9960914589442815\n",
            "epoch: 21\t| Cnt: 201\t| Loss: 0.007577155688341009\t| f1 score: 0.9921752630671037\n",
            "epoch: 21\t| Cnt: 241\t| Loss: 0.007242481123830658\t| f1 score: 0.9929618768328445\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9211001395656793\n",
            "\n",
            "epoch: 22\t| Cnt: 1\t| Loss: 0.004267352167516947\t| f1 score: 1.0\n",
            "epoch: 22\t| Cnt: 41\t| Loss: 0.004844589396816446\t| f1 score: 0.9960899315738025\n",
            "epoch: 22\t| Cnt: 81\t| Loss: 0.004976571477891411\t| f1 score: 0.9929618768328445\n",
            "epoch: 22\t| Cnt: 121\t| Loss: 0.006904907336138422\t| f1 score: 0.9937438905180841\n",
            "epoch: 22\t| Cnt: 161\t| Loss: 0.013102982233976945\t| f1 score: 0.9874785808751654\n",
            "epoch: 22\t| Cnt: 201\t| Loss: 0.0061379049948300235\t| f1 score: 0.9945259042033235\n",
            "epoch: 22\t| Cnt: 241\t| Loss: 0.006668952901964076\t| f1 score: 0.9937438905180841\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9370131635595386\n",
            "\n",
            "epoch: 23\t| Cnt: 1\t| Loss: 0.0005560736171901226\t| f1 score: 1.0\n",
            "epoch: 23\t| Cnt: 41\t| Loss: 0.002747477735101711\t| f1 score: 0.996871945259042\n",
            "epoch: 23\t| Cnt: 81\t| Loss: 0.005384086485719308\t| f1 score: 0.9953079178885631\n",
            "epoch: 23\t| Cnt: 121\t| Loss: 0.004934340663749026\t| f1 score: 0.9929618768328445\n",
            "epoch: 23\t| Cnt: 161\t| Loss: 0.008911342907958896\t| f1 score: 0.9898292220113852\n",
            "epoch: 23\t| Cnt: 201\t| Loss: 0.005676252667035442\t| f1 score: 0.9937438905180841\n",
            "epoch: 23\t| Cnt: 241\t| Loss: 0.009369376655013185\t| f1 score: 0.9913978494623656\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9578279405987438\n",
            "\n",
            "epoch: 24\t| Cnt: 1\t| Loss: 0.03681308031082153\t| f1 score: 0.9687194525904204\n",
            "epoch: 24\t| Cnt: 41\t| Loss: 0.0065606218588072805\t| f1 score: 0.9929572767523431\n",
            "epoch: 24\t| Cnt: 81\t| Loss: 0.003338905593409436\t| f1 score: 0.9960899315738025\n",
            "epoch: 24\t| Cnt: 121\t| Loss: 0.006352566181158181\t| f1 score: 0.9945259042033235\n",
            "epoch: 24\t| Cnt: 161\t| Loss: 0.0077835320618760305\t| f1 score: 0.9929572767523431\n",
            "epoch: 24\t| Cnt: 201\t| Loss: 0.007312214767443948\t| f1 score: 0.9898338220918866\n",
            "epoch: 24\t| Cnt: 241\t| Loss: 0.006315090358111774\t| f1 score: 0.9929526766718417\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9465929324299827\n",
            "\n",
            "epoch: 25\t| Cnt: 1\t| Loss: 0.0005508704925887287\t| f1 score: 1.0\n",
            "epoch: 25\t| Cnt: 41\t| Loss: 0.002930311679665465\t| f1 score: 0.9976539589442815\n",
            "epoch: 25\t| Cnt: 81\t| Loss: 0.0058727201409055855\t| f1 score: 0.9945167040423207\n",
            "epoch: 25\t| Cnt: 121\t| Loss: 0.004762332223617704\t| f1 score: 0.9960899315738025\n",
            "epoch: 25\t| Cnt: 161\t| Loss: 0.0025257109911763108\t| f1 score: 0.9976539589442815\n",
            "epoch: 25\t| Cnt: 201\t| Loss: 0.004614953269629041\t| f1 score: 0.9968673451785406\n",
            "epoch: 25\t| Cnt: 241\t| Loss: 0.005087663465383229\t| f1 score: 0.9953033178080617\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9484309437371474\n",
            "\n",
            "epoch: 26\t| Cnt: 1\t| Loss: 0.000770108075812459\t| f1 score: 1.0\n",
            "epoch: 26\t| Cnt: 41\t| Loss: 0.003970293476595543\t| f1 score: 0.9960899315738025\n",
            "epoch: 26\t| Cnt: 81\t| Loss: 0.002662657316977857\t| f1 score: 0.996871945259042\n",
            "epoch: 26\t| Cnt: 121\t| Loss: 0.007267914750264027\t| f1 score: 0.9921767904375827\n",
            "epoch: 26\t| Cnt: 161\t| Loss: 0.004971313297573943\t| f1 score: 0.9937346903570813\n",
            "epoch: 26\t| Cnt: 201\t| Loss: 0.003506247088080272\t| f1 score: 0.9976539589442815\n",
            "epoch: 26\t| Cnt: 241\t| Loss: 0.003511092952612671\t| f1 score: 0.9976539589442815\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9675852172962565\n",
            "\n",
            "epoch: 27\t| Cnt: 1\t| Loss: 0.00183086225297302\t| f1 score: 1.0\n",
            "epoch: 27\t| Cnt: 41\t| Loss: 0.0038598687293415423\t| f1 score: 0.9960914589442815\n",
            "epoch: 27\t| Cnt: 81\t| Loss: 0.0035194433090509846\t| f1 score: 0.9953079178885631\n",
            "epoch: 27\t| Cnt: 121\t| Loss: 0.004183272895170375\t| f1 score: 0.9953079178885631\n",
            "epoch: 27\t| Cnt: 161\t| Loss: 0.007177176012919517\t| f1 score: 0.9921798631476051\n",
            "epoch: 27\t| Cnt: 201\t| Loss: 0.002943922735721571\t| f1 score: 0.9976539589442815\n",
            "epoch: 27\t| Cnt: 241\t| Loss: 0.004607070433121407\t| f1 score: 0.9953094452590421\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:16\n",
            "\n",
            "valid score: 0.9702508152623117\n",
            "\n",
            "epoch: 28\t| Cnt: 1\t| Loss: 0.001137942192144692\t| f1 score: 1.0\n",
            "epoch: 28\t| Cnt: 41\t| Loss: 0.0016037569355830783\t| f1 score: 0.9976539589442815\n",
            "epoch: 28\t| Cnt: 81\t| Loss: 0.002026944063436531\t| f1 score: 0.996871945259042\n",
            "epoch: 28\t| Cnt: 121\t| Loss: 0.002713482475519413\t| f1 score: 0.9960899315738025\n",
            "epoch: 28\t| Cnt: 161\t| Loss: 0.007511488669479149\t| f1 score: 0.9945213041228221\n",
            "epoch: 28\t| Cnt: 201\t| Loss: 0.005158388413474313\t| f1 score: 0.9953033178080617\n",
            "epoch: 28\t| Cnt: 241\t| Loss: 0.003065888817218365\t| f1 score: 0.9960899315738025\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:16\n",
            "\n",
            "valid score: 0.9756654018056747\n",
            "\n",
            "epoch: 29\t| Cnt: 1\t| Loss: 0.00575973279774189\t| f1 score: 0.9687194525904204\n",
            "epoch: 29\t| Cnt: 41\t| Loss: 0.0029335011269722598\t| f1 score: 0.996871945259042\n",
            "epoch: 29\t| Cnt: 81\t| Loss: 0.0027635371749056502\t| f1 score: 0.9976539589442815\n",
            "epoch: 29\t| Cnt: 121\t| Loss: 0.004111929136706749\t| f1 score: 0.9960899315738025\n",
            "epoch: 29\t| Cnt: 161\t| Loss: 0.00411004537527333\t| f1 score: 0.9960914589442815\n",
            "epoch: 29\t| Cnt: 201\t| Loss: 0.0030893021419615254\t| f1 score: 0.996871945259042\n",
            "epoch: 29\t| Cnt: 241\t| Loss: 0.0025911098382493947\t| f1 score: 0.996871945259042\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.972944058270411\n",
            "\n",
            "\n",
            "\n",
            "Generating Inputs for fold 4\n",
            "========================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\t| Cnt: 1\t| Loss: 0.16859598457813263\t| f1 score: 0.6532019704433498\n",
            "epoch: 0\t| Cnt: 41\t| Loss: 0.15945880003273488\t| f1 score: 0.6334720014368387\n",
            "epoch: 0\t| Cnt: 81\t| Loss: 0.11878691464662552\t| f1 score: 0.7800438785072534\n",
            "epoch: 0\t| Cnt: 121\t| Loss: 0.10137451840564608\t| f1 score: 0.8162094710565653\n",
            "epoch: 0\t| Cnt: 161\t| Loss: 0.09981902819126845\t| f1 score: 0.8348490938233482\n",
            "epoch: 0\t| Cnt: 201\t| Loss: 0.09747067606076598\t| f1 score: 0.8299643141968034\n",
            "epoch: 0\t| Cnt: 241\t| Loss: 0.09397750645875931\t| f1 score: 0.8345394822754209\n",
            "Validation Loss: 0.35\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.6279541169582401\n",
            "\n",
            "epoch: 1\t| Cnt: 1\t| Loss: 0.08592928946018219\t| f1 score: 0.8745098039215686\n",
            "epoch: 1\t| Cnt: 41\t| Loss: 0.07225548941642046\t| f1 score: 0.8819098793850129\n",
            "epoch: 1\t| Cnt: 81\t| Loss: 0.07050918005406856\t| f1 score: 0.8808479438961083\n",
            "epoch: 1\t| Cnt: 121\t| Loss: 0.06258681304752826\t| f1 score: 0.9009827604670118\n",
            "epoch: 1\t| Cnt: 161\t| Loss: 0.05171742797829211\t| f1 score: 0.9159866663928161\n",
            "epoch: 1\t| Cnt: 201\t| Loss: 0.05468303561210632\t| f1 score: 0.9158937706669255\n",
            "epoch: 1\t| Cnt: 241\t| Loss: 0.05226602884940803\t| f1 score: 0.9214058721627996\n",
            "\n",
            "Average training loss: 0.06\n",
            "Average training score: 0.90\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.36\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.6399317699598249\n",
            "\n",
            "epoch: 2\t| Cnt: 1\t| Loss: 0.03469894081354141\t| f1 score: 0.9687194525904204\n",
            "epoch: 2\t| Cnt: 41\t| Loss: 0.04778643948957324\t| f1 score: 0.9269876784199684\n",
            "epoch: 2\t| Cnt: 81\t| Loss: 0.042644756566733125\t| f1 score: 0.9332419306559693\n",
            "epoch: 2\t| Cnt: 121\t| Loss: 0.04422622362617403\t| f1 score: 0.9364270879037899\n",
            "epoch: 2\t| Cnt: 161\t| Loss: 0.03864650335162878\t| f1 score: 0.945873255017954\n",
            "epoch: 2\t| Cnt: 201\t| Loss: 0.0300346254138276\t| f1 score: 0.9576742787695522\n",
            "epoch: 2\t| Cnt: 241\t| Loss: 0.03814534035045654\t| f1 score: 0.9505853114344781\n",
            "\n",
            "Average training loss: 0.04\n",
            "Average training score: 0.94\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.27\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.6876038587470626\n",
            "\n",
            "epoch: 3\t| Cnt: 1\t| Loss: 0.029225699603557587\t| f1 score: 0.9687194525904204\n",
            "epoch: 3\t| Cnt: 41\t| Loss: 0.03219079448608682\t| f1 score: 0.9536545703999739\n",
            "epoch: 3\t| Cnt: 81\t| Loss: 0.032638961216434836\t| f1 score: 0.9584718193198001\n",
            "epoch: 3\t| Cnt: 121\t| Loss: 0.03464324045926333\t| f1 score: 0.954477854187315\n",
            "epoch: 3\t| Cnt: 161\t| Loss: 0.03388798389933072\t| f1 score: 0.9496686730462208\n",
            "epoch: 3\t| Cnt: 201\t| Loss: 0.025341472774744033\t| f1 score: 0.9631992473776851\n",
            "epoch: 3\t| Cnt: 241\t| Loss: 0.02495434262091294\t| f1 score: 0.967885292680122\n",
            "\n",
            "Average training loss: 0.03\n",
            "Average training score: 0.96\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.18\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7681603615212202\n",
            "\n",
            "epoch: 4\t| Cnt: 1\t| Loss: 0.022211868315935135\t| f1 score: 0.9687194525904204\n",
            "epoch: 4\t| Cnt: 41\t| Loss: 0.022236582811456174\t| f1 score: 0.9726203028865505\n",
            "epoch: 4\t| Cnt: 81\t| Loss: 0.02872285253251903\t| f1 score: 0.9645350005789506\n",
            "epoch: 4\t| Cnt: 121\t| Loss: 0.03200235496042296\t| f1 score: 0.9544405059146726\n",
            "epoch: 4\t| Cnt: 161\t| Loss: 0.030394470668397844\t| f1 score: 0.9599214178222922\n",
            "epoch: 4\t| Cnt: 201\t| Loss: 0.02406650279299356\t| f1 score: 0.967892856859601\n",
            "epoch: 4\t| Cnt: 241\t| Loss: 0.029472357517806812\t| f1 score: 0.9615673836022427\n",
            "\n",
            "Average training loss: 0.03\n",
            "Average training score: 0.96\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.11\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8154661198787128\n",
            "\n",
            "epoch: 5\t| Cnt: 1\t| Loss: 0.03098883293569088\t| f1 score: 0.9687194525904204\n",
            "epoch: 5\t| Cnt: 41\t| Loss: 0.030606968054780737\t| f1 score: 0.9599675353296002\n",
            "epoch: 5\t| Cnt: 81\t| Loss: 0.025294425821630283\t| f1 score: 0.9671385342993503\n",
            "epoch: 5\t| Cnt: 121\t| Loss: 0.024238202464766802\t| f1 score: 0.9671000250008994\n",
            "epoch: 5\t| Cnt: 161\t| Loss: 0.02151792438235134\t| f1 score: 0.9733250222721981\n",
            "epoch: 5\t| Cnt: 201\t| Loss: 0.021304104977753015\t| f1 score: 0.9757191391320408\n",
            "epoch: 5\t| Cnt: 241\t| Loss: 0.022505295323207976\t| f1 score: 0.9741535843910828\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.97\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.18\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7910563089930569\n",
            "\n",
            "epoch: 6\t| Cnt: 1\t| Loss: 0.022238796576857567\t| f1 score: 0.9687194525904204\n",
            "epoch: 6\t| Cnt: 41\t| Loss: 0.027984914754051717\t| f1 score: 0.9702265523713784\n",
            "epoch: 6\t| Cnt: 81\t| Loss: 0.020524398487759755\t| f1 score: 0.9718168341383475\n",
            "epoch: 6\t| Cnt: 121\t| Loss: 0.02169611743884161\t| f1 score: 0.9733638979153195\n",
            "epoch: 6\t| Cnt: 161\t| Loss: 0.019605731044430287\t| f1 score: 0.9780852164912887\n",
            "epoch: 6\t| Cnt: 201\t| Loss: 0.017854685703059658\t| f1 score: 0.9773047301765281\n",
            "epoch: 6\t| Cnt: 241\t| Loss: 0.019913725642254576\t| f1 score: 0.9788517033115198\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.10\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8514650159444757\n",
            "\n",
            "epoch: 7\t| Cnt: 1\t| Loss: 0.005899163894355297\t| f1 score: 1.0\n",
            "epoch: 7\t| Cnt: 41\t| Loss: 0.01951799656962976\t| f1 score: 0.9749078163093532\n",
            "epoch: 7\t| Cnt: 81\t| Loss: 0.01732601445692126\t| f1 score: 0.9780636528172802\n",
            "epoch: 7\t| Cnt: 121\t| Loss: 0.017383162456098944\t| f1 score: 0.9812040710712437\n",
            "epoch: 7\t| Cnt: 161\t| Loss: 0.012203648500144482\t| f1 score: 0.9827941535851877\n",
            "epoch: 7\t| Cnt: 201\t| Loss: 0.01758700541977305\t| f1 score: 0.9773047301765281\n",
            "epoch: 7\t| Cnt: 241\t| Loss: 0.016737662273226307\t| f1 score: 0.9796492438617677\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.09\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8482807031388468\n",
            "\n",
            "epoch: 8\t| Cnt: 1\t| Loss: 0.008036413230001926\t| f1 score: 1.0\n",
            "epoch: 8\t| Cnt: 41\t| Loss: 0.01889897795044817\t| f1 score: 0.9796460805097649\n",
            "epoch: 8\t| Cnt: 81\t| Loss: 0.01644269020180218\t| f1 score: 0.9796322802682607\n",
            "epoch: 8\t| Cnt: 121\t| Loss: 0.01663877893006429\t| f1 score: 0.9780682528977817\n",
            "epoch: 8\t| Cnt: 161\t| Loss: 0.01473707459808793\t| f1 score: 0.9804281848369847\n",
            "epoch: 8\t| Cnt: 201\t| Loss: 0.015570127847604453\t| f1 score: 0.9843520535046864\n",
            "epoch: 8\t| Cnt: 241\t| Loss: 0.022888927356689237\t| f1 score: 0.9717691246788938\n",
            "\n",
            "Average training loss: 0.02\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.14\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8075194565206592\n",
            "\n",
            "epoch: 9\t| Cnt: 1\t| Loss: 0.002290019067004323\t| f1 score: 1.0\n",
            "epoch: 9\t| Cnt: 41\t| Loss: 0.013036842067958788\t| f1 score: 0.9843566535851878\n",
            "epoch: 9\t| Cnt: 81\t| Loss: 0.013549741811584682\t| f1 score: 0.9843055050710412\n",
            "epoch: 9\t| Cnt: 121\t| Loss: 0.015483244886854663\t| f1 score: 0.978091343942269\n",
            "epoch: 9\t| Cnt: 161\t| Loss: 0.011801658652257175\t| f1 score: 0.9866734761454385\n",
            "epoch: 9\t| Cnt: 201\t| Loss: 0.011671436074539087\t| f1 score: 0.9843366352507228\n",
            "epoch: 9\t| Cnt: 241\t| Loss: 0.01323189271352021\t| f1 score: 0.9835515488554609\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.10\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8567429105977151\n",
            "\n",
            "epoch: 10\t| Cnt: 1\t| Loss: 0.006835979875177145\t| f1 score: 1.0\n",
            "epoch: 10\t| Cnt: 41\t| Loss: 0.015576453803805634\t| f1 score: 0.9796414804292635\n",
            "epoch: 10\t| Cnt: 81\t| Loss: 0.016657016889075747\t| f1 score: 0.9827834260537059\n",
            "epoch: 10\t| Cnt: 121\t| Loss: 0.011799605858686845\t| f1 score: 0.9843505261342074\n",
            "epoch: 10\t| Cnt: 161\t| Loss: 0.015166550644789823\t| f1 score: 0.9820044850784889\n",
            "epoch: 10\t| Cnt: 201\t| Loss: 0.015430993726477027\t| f1 score: 0.9835700398194469\n",
            "epoch: 10\t| Cnt: 241\t| Loss: 0.010476421104976907\t| f1 score: 0.9874847083261458\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.98\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.09\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8672702375540134\n",
            "\n",
            "epoch: 11\t| Cnt: 1\t| Loss: 0.004416967276483774\t| f1 score: 1.0\n",
            "epoch: 11\t| Cnt: 41\t| Loss: 0.013812707923352718\t| f1 score: 0.9859130081651429\n",
            "epoch: 11\t| Cnt: 81\t| Loss: 0.008041708270320668\t| f1 score: 0.9913947767523432\n",
            "epoch: 11\t| Cnt: 121\t| Loss: 0.010654084339330438\t| f1 score: 0.9874831809556668\n",
            "epoch: 11\t| Cnt: 161\t| Loss: 0.011199394703726284\t| f1 score: 0.9835700398194469\n",
            "epoch: 11\t| Cnt: 201\t| Loss: 0.01571205494401511\t| f1 score: 0.9812224534241849\n",
            "epoch: 11\t| Cnt: 241\t| Loss: 0.007808282933547161\t| f1 score: 0.9906158357771261\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.08\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8694380776300534\n",
            "\n",
            "epoch: 12\t| Cnt: 1\t| Loss: 0.010980095714330673\t| f1 score: 1.0\n",
            "epoch: 12\t| Cnt: 41\t| Loss: 0.01228182050108444\t| f1 score: 0.9859145535046864\n",
            "epoch: 12\t| Cnt: 81\t| Loss: 0.010300664429087192\t| f1 score: 0.9866965671899258\n",
            "epoch: 12\t| Cnt: 121\t| Loss: 0.01198048688675044\t| f1 score: 0.9859206809556668\n",
            "epoch: 12\t| Cnt: 161\t| Loss: 0.00768290159467142\t| f1 score: 0.9898307493818642\n",
            "epoch: 12\t| Cnt: 201\t| Loss: 0.011037670643418096\t| f1 score: 0.9890380081651429\n",
            "epoch: 12\t| Cnt: 241\t| Loss: 0.012743473312002606\t| f1 score: 0.987473980794664\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.07\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8796936297403325\n",
            "\n",
            "epoch: 13\t| Cnt: 1\t| Loss: 0.0008199014700949192\t| f1 score: 1.0\n",
            "epoch: 13\t| Cnt: 41\t| Loss: 0.007791309598542284\t| f1 score: 0.9921798631476051\n",
            "epoch: 13\t| Cnt: 81\t| Loss: 0.005598556375480257\t| f1 score: 0.9953079178885631\n",
            "epoch: 13\t| Cnt: 121\t| Loss: 0.01345252772589447\t| f1 score: 0.9843367258927032\n",
            "epoch: 13\t| Cnt: 161\t| Loss: 0.011422753747319802\t| f1 score: 0.985123339658444\n",
            "epoch: 13\t| Cnt: 201\t| Loss: 0.01606890337425284\t| f1 score: 0.9827680077997425\n",
            "epoch: 13\t| Cnt: 241\t| Loss: 0.014684747143473943\t| f1 score: 0.9796492438617677\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9216448446554375\n",
            "\n",
            "epoch: 14\t| Cnt: 1\t| Loss: 0.00696165394037962\t| f1 score: 1.0\n",
            "epoch: 14\t| Cnt: 41\t| Loss: 0.009156475083727855\t| f1 score: 0.9906127630671037\n",
            "epoch: 14\t| Cnt: 81\t| Loss: 0.00869128387857927\t| f1 score: 0.9898246219308838\n",
            "epoch: 14\t| Cnt: 121\t| Loss: 0.009037145302863791\t| f1 score: 0.9913886493013628\n",
            "epoch: 14\t| Cnt: 161\t| Loss: 0.012626747140893712\t| f1 score: 0.9874831809556668\n",
            "epoch: 14\t| Cnt: 201\t| Loss: 0.009757282253121956\t| f1 score: 0.9906112356966247\n",
            "epoch: 14\t| Cnt: 241\t| Loss: 0.013004970105248504\t| f1 score: 0.9859145535046864\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.08\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.8646968300789295\n",
            "\n",
            "epoch: 15\t| Cnt: 1\t| Loss: 0.004082023166120052\t| f1 score: 1.0\n",
            "epoch: 15\t| Cnt: 41\t| Loss: 0.010614965748391113\t| f1 score: 0.9882621219308838\n",
            "epoch: 15\t| Cnt: 81\t| Loss: 0.009542888401483651\t| f1 score: 0.9890518084066471\n",
            "epoch: 15\t| Cnt: 121\t| Loss: 0.011378776704077609\t| f1 score: 0.9843335625407004\n",
            "epoch: 15\t| Cnt: 161\t| Loss: 0.00965276427596109\t| f1 score: 0.9874847083261458\n",
            "epoch: 15\t| Cnt: 201\t| Loss: 0.013333699540817178\t| f1 score: 0.9851340671899258\n",
            "epoch: 15\t| Cnt: 241\t| Loss: 0.006573294990812428\t| f1 score: 0.9921813905180841\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:16\n",
            "\n",
            "valid score: 0.9403999190720259\n",
            "\n",
            "epoch: 16\t| Cnt: 1\t| Loss: 0.004686354659497738\t| f1 score: 1.0\n",
            "epoch: 16\t| Cnt: 41\t| Loss: 0.008937498291197698\t| f1 score: 0.9913901766718418\n",
            "epoch: 16\t| Cnt: 81\t| Loss: 0.005183506540197414\t| f1 score: 0.9953079178885631\n",
            "epoch: 16\t| Cnt: 121\t| Loss: 0.008842357638059184\t| f1 score: 0.9882467036769202\n",
            "epoch: 16\t| Cnt: 161\t| Loss: 0.007917744229052915\t| f1 score: 0.9898292220113852\n",
            "epoch: 16\t| Cnt: 201\t| Loss: 0.0069811214227229355\t| f1 score: 0.9921644269245771\n",
            "epoch: 16\t| Cnt: 241\t| Loss: 0.007697189386817627\t| f1 score: 0.9898246219308838\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9282988484480945\n",
            "\n",
            "epoch: 17\t| Cnt: 1\t| Loss: 0.0032758070155978203\t| f1 score: 1.0\n",
            "epoch: 17\t| Cnt: 41\t| Loss: 0.009849925253365654\t| f1 score: 0.9890380081651429\n",
            "epoch: 17\t| Cnt: 81\t| Loss: 0.0076064180422690695\t| f1 score: 0.9906127630671037\n",
            "epoch: 17\t| Cnt: 121\t| Loss: 0.01042436129791895\t| f1 score: 0.9874801082456444\n",
            "epoch: 17\t| Cnt: 161\t| Loss: 0.011390866519650444\t| f1 score: 0.9882651946409062\n",
            "epoch: 17\t| Cnt: 201\t| Loss: 0.009845148862950737\t| f1 score: 0.9898307493818642\n",
            "epoch: 17\t| Cnt: 241\t| Loss: 0.009684849169570953\t| f1 score: 0.9906158357771261\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.05\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.91199801373831\n",
            "\n",
            "epoch: 18\t| Cnt: 1\t| Loss: 0.0008527415338903666\t| f1 score: 1.0\n",
            "epoch: 18\t| Cnt: 41\t| Loss: 0.00783693098128424\t| f1 score: 0.9898322767523432\n",
            "epoch: 18\t| Cnt: 81\t| Loss: 0.008418335733585991\t| f1 score: 0.9890487356966247\n",
            "epoch: 18\t| Cnt: 121\t| Loss: 0.008736323201446794\t| f1 score: 0.9906081629866023\n",
            "epoch: 18\t| Cnt: 161\t| Loss: 0.0037457904385519215\t| f1 score: 0.9953079178885631\n",
            "epoch: 18\t| Cnt: 201\t| Loss: 0.006105736547760898\t| f1 score: 0.9913978494623656\n",
            "epoch: 18\t| Cnt: 241\t| Loss: 0.008061393426032737\t| f1 score: 0.9913978494623656\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9415840546076795\n",
            "\n",
            "epoch: 19\t| Cnt: 1\t| Loss: 0.0032839151099324226\t| f1 score: 1.0\n",
            "epoch: 19\t| Cnt: 41\t| Loss: 0.009401845635875362\t| f1 score: 0.9882667220113852\n",
            "epoch: 19\t| Cnt: 81\t| Loss: 0.010152310201374349\t| f1 score: 0.9859206809556668\n",
            "epoch: 19\t| Cnt: 121\t| Loss: 0.008160764210333581\t| f1 score: 0.9921798631476051\n",
            "epoch: 19\t| Cnt: 161\t| Loss: 0.010027117464051116\t| f1 score: 0.9867042220113852\n",
            "epoch: 19\t| Cnt: 201\t| Loss: 0.006245277701236773\t| f1 score: 0.9921813905180841\n",
            "epoch: 19\t| Cnt: 241\t| Loss: 0.007894262655463535\t| f1 score: 0.9921798631476051\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9380485161399379\n",
            "\n",
            "epoch: 20\t| Cnt: 1\t| Loss: 0.003616729751229286\t| f1 score: 1.0\n",
            "epoch: 20\t| Cnt: 41\t| Loss: 0.008285096781764877\t| f1 score: 0.9937392904375827\n",
            "epoch: 20\t| Cnt: 81\t| Loss: 0.007104940857971087\t| f1 score: 0.9906158357771261\n",
            "epoch: 20\t| Cnt: 121\t| Loss: 0.006105958549596835\t| f1 score: 0.9929618768328445\n",
            "epoch: 20\t| Cnt: 161\t| Loss: 0.00331234771583695\t| f1 score: 0.996871945259042\n",
            "epoch: 20\t| Cnt: 201\t| Loss: 0.008244477161497343\t| f1 score: 0.9913840492208614\n",
            "epoch: 20\t| Cnt: 241\t| Loss: 0.003928851294040215\t| f1 score: 0.996871945259042\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9494213501995603\n",
            "\n",
            "epoch: 21\t| Cnt: 1\t| Loss: 0.0009675782639533281\t| f1 score: 1.0\n",
            "epoch: 21\t| Cnt: 41\t| Loss: 0.00584076052364253\t| f1 score: 0.9937392904375827\n",
            "epoch: 21\t| Cnt: 81\t| Loss: 0.006640794373379322\t| f1 score: 0.9937392904375827\n",
            "epoch: 21\t| Cnt: 121\t| Loss: 0.004508196659298846\t| f1 score: 0.9937438905180841\n",
            "epoch: 21\t| Cnt: 161\t| Loss: 0.007752787225763313\t| f1 score: 0.9874785808751654\n",
            "epoch: 21\t| Cnt: 201\t| Loss: 0.008171578431210946\t| f1 score: 0.9890241172816584\n",
            "epoch: 21\t| Cnt: 241\t| Loss: 0.003805725771235302\t| f1 score: 0.9960899315738025\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.03\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9386342716547146\n",
            "\n",
            "epoch: 22\t| Cnt: 1\t| Loss: 0.0009891643421724439\t| f1 score: 1.0\n",
            "epoch: 22\t| Cnt: 41\t| Loss: 0.005640199357003439\t| f1 score: 0.9937438905180841\n",
            "epoch: 22\t| Cnt: 81\t| Loss: 0.004799601599370362\t| f1 score: 0.9921752630671037\n",
            "epoch: 22\t| Cnt: 121\t| Loss: 0.005531595825596014\t| f1 score: 0.9937438905180841\n",
            "epoch: 22\t| Cnt: 161\t| Loss: 0.005882030706561636\t| f1 score: 0.9937438905180841\n",
            "epoch: 22\t| Cnt: 201\t| Loss: 0.006778950657462701\t| f1 score: 0.9913932493818642\n",
            "epoch: 22\t| Cnt: 241\t| Loss: 0.00766657251988363\t| f1 score: 0.9906066356161233\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.20\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.7843229549964418\n",
            "\n",
            "epoch: 23\t| Cnt: 1\t| Loss: 0.004920420236885548\t| f1 score: 1.0\n",
            "epoch: 23\t| Cnt: 41\t| Loss: 0.009599496058945079\t| f1 score: 0.9882651946409062\n",
            "epoch: 23\t| Cnt: 81\t| Loss: 0.007429880300696823\t| f1 score: 0.9913932493818642\n",
            "epoch: 23\t| Cnt: 121\t| Loss: 0.0034533164460299305\t| f1 score: 0.996871945259042\n",
            "epoch: 23\t| Cnt: 161\t| Loss: 0.005195449552775244\t| f1 score: 0.9953079178885631\n",
            "epoch: 23\t| Cnt: 201\t| Loss: 0.006636670542502543\t| f1 score: 0.9937454178885631\n",
            "epoch: 23\t| Cnt: 241\t| Loss: 0.006724536791443825\t| f1 score: 0.9921706629866023\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.04\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.934562949301249\n",
            "\n",
            "epoch: 24\t| Cnt: 1\t| Loss: 0.012082459405064583\t| f1 score: 0.9687194525904204\n",
            "epoch: 24\t| Cnt: 41\t| Loss: 0.0038992471705569186\t| f1 score: 0.9953033178080617\n",
            "epoch: 24\t| Cnt: 81\t| Loss: 0.00478005483164452\t| f1 score: 0.9953033178080617\n",
            "epoch: 24\t| Cnt: 121\t| Loss: 0.0050402453030983455\t| f1 score: 0.9945259042033235\n",
            "epoch: 24\t| Cnt: 161\t| Loss: 0.007764501323981677\t| f1 score: 0.9913993768328446\n",
            "epoch: 24\t| Cnt: 201\t| Loss: 0.0043579097393376285\t| f1 score: 0.9953079178885631\n",
            "epoch: 24\t| Cnt: 241\t| Loss: 0.00661035623998032\t| f1 score: 0.9937346903570813\n",
            "\n",
            "Average training loss: 0.01\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9632661714109723\n",
            "\n",
            "epoch: 25\t| Cnt: 1\t| Loss: 0.0014707837253808975\t| f1 score: 1.0\n",
            "epoch: 25\t| Cnt: 41\t| Loss: 0.005482542291065329\t| f1 score: 0.9937438905180841\n",
            "epoch: 25\t| Cnt: 81\t| Loss: 0.005417372174269986\t| f1 score: 0.9937454178885631\n",
            "epoch: 25\t| Cnt: 121\t| Loss: 0.0031285685141483554\t| f1 score: 0.9953079178885631\n",
            "epoch: 25\t| Cnt: 161\t| Loss: 0.005344135902851122\t| f1 score: 0.9945259042033235\n",
            "epoch: 25\t| Cnt: 201\t| Loss: 0.0031329941844887798\t| f1 score: 0.9960899315738025\n",
            "epoch: 25\t| Cnt: 241\t| Loss: 0.003932180710035027\t| f1 score: 0.9953079178885631\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9594150156723216\n",
            "\n",
            "epoch: 26\t| Cnt: 1\t| Loss: 0.027380816638469696\t| f1 score: 0.9687194525904204\n",
            "epoch: 26\t| Cnt: 41\t| Loss: 0.005239352345597581\t| f1 score: 0.9953079178885631\n",
            "epoch: 26\t| Cnt: 81\t| Loss: 0.0034499032961321065\t| f1 score: 0.9976539589442815\n",
            "epoch: 26\t| Cnt: 121\t| Loss: 0.005948621063726023\t| f1 score: 0.9937438905180841\n",
            "epoch: 26\t| Cnt: 161\t| Loss: 0.003917645268666092\t| f1 score: 0.9937454178885631\n",
            "epoch: 26\t| Cnt: 201\t| Loss: 0.004863567104621325\t| f1 score: 0.9937469452590421\n",
            "epoch: 26\t| Cnt: 241\t| Loss: 0.0014713582531840075\t| f1 score: 0.998435972629521\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:50\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9691532004166057\n",
            "\n",
            "epoch: 27\t| Cnt: 1\t| Loss: 0.0005449402378872037\t| f1 score: 1.0\n",
            "epoch: 27\t| Cnt: 41\t| Loss: 0.0029841197436326185\t| f1 score: 0.9968673451785406\n",
            "epoch: 27\t| Cnt: 81\t| Loss: 0.002510572337268968\t| f1 score: 0.9976539589442815\n",
            "epoch: 27\t| Cnt: 121\t| Loss: 0.007125861956592416\t| f1 score: 0.9913932493818642\n",
            "epoch: 27\t| Cnt: 161\t| Loss: 0.00634951680785889\t| f1 score: 0.9929572767523431\n",
            "epoch: 27\t| Cnt: 201\t| Loss: 0.0028704591506539144\t| f1 score: 0.996871945259042\n",
            "epoch: 27\t| Cnt: 241\t| Loss: 0.0048017225304647585\t| f1 score: 0.9945213041228221\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.02\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9658660705788922\n",
            "\n",
            "epoch: 28\t| Cnt: 1\t| Loss: 0.00039021248812787235\t| f1 score: 1.0\n",
            "epoch: 28\t| Cnt: 41\t| Loss: 0.004121534645310021\t| f1 score: 0.9953079178885631\n",
            "epoch: 28\t| Cnt: 81\t| Loss: 0.004355389075499261\t| f1 score: 0.9953079178885631\n",
            "epoch: 28\t| Cnt: 121\t| Loss: 0.004972542836549109\t| f1 score: 0.9929618768328445\n",
            "epoch: 28\t| Cnt: 161\t| Loss: 0.001834118058832246\t| f1 score: 0.9976539589442815\n",
            "epoch: 28\t| Cnt: 201\t| Loss: 0.008030125014556688\t| f1 score: 0.9906127630671037\n",
            "epoch: 28\t| Cnt: 241\t| Loss: 0.0029557877123806975\t| f1 score: 0.9960899315738025\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 0.99\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.01\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.9785843238462191\n",
            "\n",
            "epoch: 29\t| Cnt: 1\t| Loss: 0.0007987745339050889\t| f1 score: 1.0\n",
            "epoch: 29\t| Cnt: 41\t| Loss: 0.004618870160993538\t| f1 score: 0.9937438905180841\n",
            "epoch: 29\t| Cnt: 81\t| Loss: 0.0031708151336715673\t| f1 score: 0.9960853314933011\n",
            "epoch: 29\t| Cnt: 121\t| Loss: 0.0038784663391197684\t| f1 score: 0.9960899315738025\n",
            "epoch: 29\t| Cnt: 161\t| Loss: 0.003697509687481215\t| f1 score: 0.9960899315738025\n",
            "epoch: 29\t| Cnt: 201\t| Loss: 0.0031702194464742206\t| f1 score: 0.9953079178885631\n",
            "epoch: 29\t| Cnt: 241\t| Loss: 0.00344714277634921\t| f1 score: 0.9953094452590421\n",
            "\n",
            "Average training loss: 0.00\n",
            "Average training score: 1.00\n",
            "Training epoch took: 0:00:49\n",
            "\n",
            "Running Validation...\n",
            "Validation Loss: 0.01\n",
            "Validation took: 0:00:17\n",
            "\n",
            "valid score: 0.974500698796267\n",
            "\n",
            "\n",
            "Training complete!\n",
            "Total training took 2:44:31 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "if __name__==\"__main__\":\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "\n",
        "    # Let's set a seed value to make this reproducible\n",
        "    set_seed()\n",
        "    train_skf = pd.concat([train, valid])\n",
        "\n",
        "    train_f1_list, train_loss_list = [], []\n",
        "    valid_f1_list, valid_f1_list_tot, valid_loss_list, valid_roc_list = [], [], [], []\n",
        "    best_pre = 0.0\n",
        "    a = 0\n",
        "    n = 5\n",
        "    kf = KFold(n_splits=n)\n",
        "    train_results, valid_results, valid_results_tot, train_loss, valid_loss, valid_results_roc, training_stats_list  = [], [], [], [], [], [], []\n",
        "\n",
        "\n",
        "    for train_idx, cross_val_idx in kf.split(train_skf):\n",
        "\n",
        "        print(\"\",end=\"\\n\\n\")\n",
        "        print(f\"Generating Inputs for fold {a}\")\n",
        "        print(\"==\"*20)\n",
        "\n",
        "        train_df = train_skf.iloc[train_idx]\n",
        "        train_df.index = range(train_df.shape[0])\n",
        "        train_df.patid = range(train_df.shape[0])\n",
        "\n",
        "        cv_df = train_skf.iloc[cross_val_idx]\n",
        "        cv_df.index = range(cv_df.shape[0])\n",
        "        cv_df.patid = range(cv_df.shape[0])\n",
        "\n",
        "\n",
        "        X_tr = train_df['inputs_quantiles_cleaned']\n",
        "        y_tr = train_df['label']\n",
        "\n",
        "        Dset = FinetuneDataset(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=train_df, max_len=global_params['max_len_seq'], code='inputs_quantiles_cleaned', delay ='delays' )\n",
        "        hp_generator = {'batch_size': global_params['batch_size'], 'balanced': 'balanced', 'shuffle':True}\n",
        "        train_data = DataLoader(dataset=Dset, batch_size=global_params['batch_size'],  sampler = StratifiedSampler(X_tr, y_tr, batch_size=global_params['batch_size']) , **kwargs)\n",
        "\n",
        "\n",
        "        valid_Dset = FinetuneDataset(token2idx=tokenVocab, label2idx=labelVocab, mod2idx=modalitiesVocab, age2idx=ageVocab, del2idx=delayVocab, dataframe=cv_df, max_len=global_params['max_len_seq'], code='inputs_quantiles_cleaned', delay ='delays')\n",
        "        valid_data = DataLoader(dataset= Dset, batch_size=global_params['batch_size'],  shuffle = True, **kwargs)\n",
        "\n",
        "        model, optim = define_model(best_config)\n",
        "\n",
        "        for e in range(200):\n",
        "\n",
        "            valid_f1, train_f1, valid_loss, train_loss, valid_roc, training_stats =  training(e, train_data, valid_data)\n",
        "\n",
        "            train_f1_list.append(np.mean(train_f1))\n",
        "            train_loss_list.append(np.mean(train_loss))\n",
        "            valid_f1_list.append(np.mean(valid_f1))\n",
        "            valid_roc_list.append(np.mean(valid_roc))\n",
        "            valid_loss_list.append(np.mean(valid_loss))\n",
        "\n",
        "            mean_f1 = np.mean(valid_f1)\n",
        "\n",
        "            if mean_f1 > best_pre:\n",
        "                # Save a trained model\n",
        "                print(\"** ** * Saving fine - tuned model ** ** * \")\n",
        "                model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "                output_model_file = os.path.join(global_params['output_dir'],global_params['best_name'])\n",
        "                create_folder(global_params['output_dir'])\n",
        "\n",
        "                torch.save(model_to_save.state_dict(), output_model_file)\n",
        "                best_pre = mean_f1\n",
        "            print('valid score: {}'.format(np.mean(valid_f1)))\n",
        "\n",
        "\n",
        "            print()\n",
        "\n",
        "        a+=1\n",
        "\n",
        "    train_results.append(train_f1)\n",
        "    valid_results.append(valid_f1)\n",
        "    train_loss.append(train_loss)\n",
        "    valid_loss.append(valid_loss)\n",
        "    valid_results_roc.append(valid_roc)\n",
        "    training_stats_list.append(training_stats)\n",
        "\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(end-start)))\n",
        "\n",
        "# age_ids, input_ids, mod_ids, del_ids, posi_ids, segment_ids, attMask, targets, _ = batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641fe13b-5d5b-4978-b52b-40cf7f540e3a",
      "metadata": {
        "id": "641fe13b-5d5b-4978-b52b-40cf7f540e3a"
      },
      "source": [
        "#### Evaluate model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ba8c9e1-53a8-4acf-b09f-24c5334a0126",
      "metadata": {
        "id": "2ba8c9e1-53a8-4acf-b09f-24c5334a0126"
      },
      "source": [
        "1. Plot model history  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11d7733-29a1-4f23-a1ae-80e716260850",
      "metadata": {
        "id": "c11d7733-29a1-4f23-a1ae-80e716260850"
      },
      "outputs": [],
      "source": [
        "df_stats = display_training_stats(training_stats)\n",
        "df_stats.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcb6c3d6-aa7d-4cf9-93e2-d2b611f63e29",
      "metadata": {
        "id": "bcb6c3d6-aa7d-4cf9-93e2-d2b611f63e29"
      },
      "outputs": [],
      "source": [
        "plot_history(training_stats, 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfa8b36c-c824-42f2-83f4-6db21ea055c1",
      "metadata": {
        "id": "bfa8b36c-c824-42f2-83f4-6db21ea055c1"
      },
      "source": [
        "2. Display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aa72689-99fe-4e39-a9d0-edc9cf82de94",
      "metadata": {
        "id": "6aa72689-99fe-4e39-a9d0-edc9cf82de94",
        "outputId": "c8b51970-00e1-474b-ce6c-dfa146b3399c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting labels for 4,545 test sequences...\n",
            "Validation Loss: 0.27\n",
            "Validation took: 0:00:09\n",
            "\n",
            "Test f1 score = 0.7349955368785289 and Test roc = 0.7656285894785205\n"
          ]
        }
      ],
      "source": [
        "# Prediction on test set ## 2nd run , cv and cleaned\n",
        "\n",
        "print('Predicting labels for {:,} test sequences...'.format(len(test)))\n",
        "f1, roc, loss, test_time = evaluation(testload)\n",
        "print('Test f1 score = {} and Test roc = {}'.format(np.mean(f1), np.mean(roc)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}